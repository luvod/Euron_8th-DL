{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **TF-IDF란?**🔍\n","\n","- TF-IDF는 문서 집합 내에서 특정 단어가 얼마나 중요한지를 평가하는 통계적 측정 도구입니다.\n","이 값은 두 가지 요소의 곱으로 계산됩니다:\n","\n","> TF (Term Frequency) – 특정 단어가 해당 문서에서 얼마나 자주 등장하는지\n","\n","> IDF (Inverse Document Frequency) – 해당 단어가 전체 문서 집합에서 얼마나 희귀한지\n","\n","- 예를 들어, \"this\", \"what\", \"if\" 같은 단어는 모든 문서에 흔하게 등장하므로 TF가 높아도 IDF가 낮아져 TF-IDF 값이 낮습니다.\n","반면, \"Bug\" 같은 단어가 특정 문서에만 자주 등장하면 높은 TF-IDF 점수를 갖고, 해당 문서의 주요 주제를 나타낼 수 있습니다 (예: 신뢰성 관련 문서).\n","\n","- 수식으로 표현된 TF-IDF 계산법: *TF-IDF(𝑡,𝑑)=TF(𝑡,𝑑)×IDF(𝑡)*\n","\n","\n","\n","**Scikit-learn 라이브러리에 내장된 TF-IDF 알고리즘을 사용하여, 1987년부터 2019년까지 NeurIPS 학회에서 발표된 논문들로부터 상위 10개 키워드를 추출할 해봅시다** 😀"],"metadata":{"id":"ubuPsL3gfN2m"}},{"cell_type":"markdown","source":["### **데이터 불러오기**\n","\n","- 아래 셀을 실행시켜주세요"],"metadata":{"id":"4ML81JvIi9W1"}},{"cell_type":"code","source":["# 구글 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vlnqNL5Tgkl_","outputId":"c6c712aa-facc-4c91-bb74-58faf9110799","executionInfo":{"status":"ok","timestamp":1747637900597,"user_tz":-540,"elapsed":22932,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0KgEJl0fEXy","outputId":"b0a03f6e-6d4d-4352-eac9-9efc64a7a776","executionInfo":{"status":"ok","timestamp":1747637922952,"user_tz":-540,"elapsed":22365,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/euron/All_English_Stopwords.txt\n","/content/drive/MyDrive/euron/kaggle_authors.csv\n","/content/drive/MyDrive/euron/kaggle_papers.csv\n","/content/drive/MyDrive/euron/Week10_복습과제_이름.ipynb\n"]}],"source":["# 데이터 파일 이름 print\n","import pandas as pd\n","import os\n","for dirname, _, filenames in os.walk('/content/drive/MyDrive/euron'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","source":["# Constants\n","# 위의 print된 내용에 따라 아래 path를 수정해주세요\n","PUNCTUATION = \"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"\n","TOP_K_KEYWORDS = 10\n","STOPWORD_PATH = \"/content/drive/MyDrive/euron/All_English_Stopwords.txt\"\n","PAPERS_PATH = \"/content/drive/MyDrive/euron/kaggle_papers.csv\""],"metadata":{"id":"1lthMPFSiYlU","executionInfo":{"status":"ok","timestamp":1747637922961,"user_tz":-540,"elapsed":11,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 필요한 라이브러리 임포트\n","import re, os, string\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"metadata":{"id":"Ze__Jve-hsRT","executionInfo":{"status":"ok","timestamp":1747637923862,"user_tz":-540,"elapsed":902,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### **키워드 추출을 위한 함수 정의** ⚓"],"metadata":{"id":"pLuzfjwhlriq"}},{"cell_type":"markdown","source":["#### **get stopwords list 함수 정의**\n","- 주어진 파일에서 불용어 목록을 읽어와 공백 제거 및 중복 제거 후 리스트 형태로 반환하는 함수입니다\n","\n","- 아래 빈칸을 완성해주세요"],"metadata":{"id":"x9qCUZt3jfsD"}},{"cell_type":"code","source":["def get_stopwords_list(stop_file_path):\n","    \"\"\"load stop words \"\"\"\n","     # 지정한 경로의 파일을 UTF-8 인코딩으로 읽기 모드 열기\n","    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n","        # 파일의 모든 줄을 리스트로 읽어오기\n","        stopwords = f.readlines()\n","        # 각 줄에서 양쪽 공백을 제거하고 set으로 중복 제거하기\n","        stop_set = set(word.strip() for word in stopwords)\n","        # frozenset으로 다시 중복 제거하고 리스트로 변환 후 반환하기\n","        return list(frozenset(stop_set))"],"metadata":{"id":"UGdGzedShsD5","executionInfo":{"status":"ok","timestamp":1747637923883,"user_tz":-540,"elapsed":8,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["#### **clean text 함수 정의**\n","-  텍스트 데이터를 소문자로 변환, 문장부호 제거, 공백 정리하여 모델 학습이나 분석에 적합한 형태로 정제(cleaning) 함수입니다\n","\n","- 아래 빈칸을 완성해주세요"],"metadata":{"id":"AGuodw_8kKsb"}},{"cell_type":"code","source":["def clean_text(text):\n","    # 모든 문자를 소문자로 변환하기\n","    text = text.lower()\n","    # 문장부호 제거하기 (PUNCTUATION에 정의된 모든 기호 제거)\n","    text = text.translate(str.maketrans('','',string.punctuation))\n","    # 공백 문자 및 줄바꿈을 하나의 공백으로 치환\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text"],"metadata":{"id":"UOzIfyZJiHHw","executionInfo":{"status":"ok","timestamp":1747637923962,"user_tz":-540,"elapsed":68,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#### **sort coo 함수 정의**\n","- 희소행령 (coo_matrix)를 TF-IDF 점수가 높은 단어부터 정렬하는 함수입니다.\n","- 아래 빈칸을 완성해주세요"],"metadata":{"id":"uuYdnNP7lJBh"}},{"cell_type":"code","source":["def sort_coo(coo_matrix):\n","    # (단어 인덱스, 해당 인덱스의 TF-IDF 값) 튜플 생성하기\n","    tuples = list(zip(coo_matrix.col, coo_matrix.data))\n","    # TF-IDF 점수 기준으로 내림차순 정렬 (점수 같을 경우 인덱스 기준으로)\n","    return sorted(tuples, key=lambda x: (-x[1], x[0]))"],"metadata":{"id":"dEC7TY7QlJaw","executionInfo":{"status":"ok","timestamp":1747637923986,"user_tz":-540,"elapsed":10,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["#### **extract topn from vector 함수 정의**\n","- TF-IDF 벡터에서 상위 n개의 단어와 점수를  {단어: 점수} 형태로 추출하는 함수입니다.\n","- 아래 빈칸을 완성해주세요"],"metadata":{"id":"YXsLePFIkiWQ"}},{"cell_type":"code","source":["# TF-IDF 벡터에서 상위 topn개의 단어와 점수를 추출하기\n","def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n","    # 상위 topn 개 항목만 사용하기\n","    sorted_items = sorted_items[:topn]\n","\n","    score_vals = [] # TF-IDF 점수 저장용 리스트\n","    feature_vals = [] # 단어 저장용 리스트\n","\n","    # (단어 인덱스, TF-IDF 점수)로부터 단어와 점수를 추출하기\n","    for idx, score in sorted_items:\n","        score_vals.append(round(score, 3))  # 점수 반올림하여 저장\n","        feature_vals.append(feature_names[idx]) # 인덱스로 단어 찾아 저장\n","\n","    # 단어: 점수 형태의 딕셔너리 생성하기\n","    results= {}\n","    for idx in range(len(feature_vals)):\n","        results[feature_vals[idx]] = score_vals[idx]\n","\n","    return results"],"metadata":{"id":"i0ADvuKIiQzB","executionInfo":{"status":"ok","timestamp":1747637924010,"user_tz":-540,"elapsed":13,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["#### **get keywords 함수 정의**\n","- 문서 하나에서 TF-IDF 기반으로 가장 중요한 단어 K개를 추출하는 함수입니다.\n","- 아래 빈칸을 완성해주세요"],"metadata":{"id":"2AGwrrYrl5cO"}},{"cell_type":"code","source":["def get_keywords(vectorizer, feature_names, doc):\n","    \"\"\"Return top k keywords from a doc using TF-IDF method\"\"\"\n","\n","    # 주어진 문서에 대해 TF-IDF 벡터 생성하기\n","    tf_idf_vector = vectorizer.transform([doc])\n","\n","    # TF-IDF 점수를 기준으로 내림차순 정렬하기\n","    sorted_items=sort_coo(tf_idf_vector.tocoo())\n","\n","    # 상위 TOP_K_KEYWORDS 개 단어와 점수 추출하기\n","    keywords=extract_topn_from_vector(feature_names, sorted_items, topn=TOP_K_KEYWORDS)\n","    # 키워드(단어)만 리스트로 반환하기\n","    return list(keywords.keys())"],"metadata":{"id":"ofUaC1p4iS33","executionInfo":{"status":"ok","timestamp":1747637924084,"user_tz":-540,"elapsed":60,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### **데이터에 적용하기** 🌻\n","- 우리의 데이터에 적용해봅시다!\n","- 아래 셀을 실행시켜주세요"],"metadata":{"id":"CTpm_l6hmQO5"}},{"cell_type":"code","source":["data = pd.read_csv(PAPERS_PATH)\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"JwuXL7NciUpR","outputId":"fe50cfb4-1a7e-4d4a-d4ef-062dbe635b87","executionInfo":{"status":"ok","timestamp":1747637935589,"user_tz":-540,"elapsed":11488,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   source_id  year                                              title  \\\n","0         27  1987                         Bit-Serial Neural Networks   \n","1         63  1987                        Connectivity Versus Entropy   \n","2         60  1987        The Hopfield Model with Multi-Level Neurons   \n","3         59  1987                               How Neural Nets Work   \n","4         69  1987  Spatial Organization of Neural Networks: A Pro...   \n","\n","  abstract                                          full_text  \n","0      NaN  573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...  \n","1      NaN  1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...  \n","2      NaN  278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...  \n","3      NaN  442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...  \n","4      NaN  740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...  "],"text/html":["\n","  <div id=\"df-23d01a20-39df-4e32-84ed-77e8bf97cc02\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_id</th>\n","      <th>year</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>full_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>27</td>\n","      <td>1987</td>\n","      <td>Bit-Serial Neural Networks</td>\n","      <td>NaN</td>\n","      <td>573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>63</td>\n","      <td>1987</td>\n","      <td>Connectivity Versus Entropy</td>\n","      <td>NaN</td>\n","      <td>1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>60</td>\n","      <td>1987</td>\n","      <td>The Hopfield Model with Multi-Level Neurons</td>\n","      <td>NaN</td>\n","      <td>278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>59</td>\n","      <td>1987</td>\n","      <td>How Neural Nets Work</td>\n","      <td>NaN</td>\n","      <td>442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>69</td>\n","      <td>1987</td>\n","      <td>Spatial Organization of Neural Networks: A Pro...</td>\n","      <td>NaN</td>\n","      <td>740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23d01a20-39df-4e32-84ed-77e8bf97cc02')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-23d01a20-39df-4e32-84ed-77e8bf97cc02 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-23d01a20-39df-4e32-84ed-77e8bf97cc02');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-7d52240f-0980-4b3f-98e7-7f68e37b219c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d52240f-0980-4b3f-98e7-7f68e37b219c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-7d52240f-0980-4b3f-98e7-7f68e37b219c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 9680,\n  \"fields\": [\n    {\n      \"column\": \"source_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1825,\n        \"min\": 1,\n        \"max\": 9406,\n        \"num_unique_values\": 4522,\n        \"samples\": [\n          5676,\n          2528,\n          5716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1987,\n        \"max\": 2019,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          2018,\n          2002,\n          2013\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9680,\n        \"samples\": [\n          \"Label Embedding Trees for Large Multi-Class Tasks\",\n          \"Catastrophic Interference in Human Motor Learning\",\n          \"Provably Correct Automatic Sub-Differentiation for Qualified Programs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6361,\n        \"samples\": [\n          \"We introduce algorithmic assurance, the problem of testing whether\\nmachine learning algorithms are conforming to their intended design\\ngoal. We address this problem by proposing an efficient framework\\nfor algorithmic testing. To provide assurance, we need to efficiently\\ndiscover scenarios where an algorithm decision deviates maximally\\nfrom its intended gold standard. We mathematically formulate this\\ntask as an optimisation problem of an expensive, black-box function.\\nWe use an active learning approach based on Bayesian optimisation\\nto solve this optimisation problem. We extend this framework to algorithms\\nwith vector-valued outputs by making appropriate modification in Bayesian\\noptimisation via the EXP3 algorithm. We theoretically analyse our\\nmethods for convergence. Using two real-world applications, we demonstrate\\nthe efficiency of our methods. The significance of our problem formulation\\nand initial solutions is that it will serve as the foundation in assuring\\nhumans about machines making complex decisions.\",\n          \"Hamiltonian Monte Carlo (HMC) is a widely deployed method to sample from high-dimensional  distributions in  Statistics and Machine learning. HMC is known to run very efficiently in practice and its popular second-order ``leapfrog\\\" implementation has long been conjectured to run in $d^{1/4}$ gradient evaluations. Here we show that this conjecture is true when sampling from strongly log-concave target distributions that satisfy a weak third-order regularity property associated with the input data.  Our regularity condition is weaker than the Lipschitz Hessian property and allows us to show faster convergence bounds for a much larger class of distributions than would be possible with the usual Lipschitz Hessian constant alone.  Important distributions that satisfy our regularity condition include posterior distributions used in Bayesian logistic regression for which the data satisfies an ``incoherence\\\" property. Our result compares favorably with the best available bounds for the class of strongly log-concave distributions, which grow like $d^{{1}/{2}}$ gradient evaluations with the dimension. Moreover, our simulations on synthetic data suggest that, when our regularity condition is satisfied, leapfrog HMC performs better than its competitors -- both in terms of accuracy and in terms of the number of gradient evaluations it requires.\",\n          \"Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems. However, only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account. In this paper, we show that it is possible to design efficient inference algorithms for a conditional random field using features that depend on long consecutive label sequences (high-order features), as long as the number of distinct label sequences in the features used is small. This leads to efficient learning algorithms for these conditional random fields. We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9673,\n        \"samples\": [\n          \"Nonparametric Multi-group Membership Model\\n\\nfor Dynamic Networks\\n\\nMyunghwan Kim\\nStanford University\\nStanford, CA 94305\\n\\nJure Leskovec\\n\\nStanford University\\nStanford, CA 94305\\n\\nmykim@stanford.edu\\n\\njure@cs.stanford.edu\\n\\nRelational data\\u2014like graphs, networks, and matrices\\u2014is often dynamic, where the relational struc-\\nture evolves over time. A fundamental problem in the analysis of time-varying network data is to\\nextract a summary of the common structure and the dynamics of the underlying relations between\\nthe entities. Here we build on the intuition that changes in the network structure are driven by dy-\\nnamics at the level of groups of nodes. We propose a nonparametric multi-group membership model\\nfor dynamic networks. Our model contains three main components: We model the birth and death of\\nindividual groups with respect to the dynamics of the network structure via a distance dependent In-\\ndian Buffet Process. We capture the evolution of individual node group memberships via a Factorial\\nHidden Markov model. And, we explain the dynamics of the network structure by explicitly mod-\\neling the connectivity structure of groups. We demonstrate our model\\u2019s capability of identifying the\\ndynamics of latent groups in a number of different types of network data. Experimental results show\\nthat our model provides improved predictive performance over existing dynamic network models on\\nfuture network forecasting and missing link prediction.\\n\\n1 Introduction\\n\\nStatistical analysis of social networks and other relational data is becoming an increasingly impor-\\ntant problem as the scope and availability of network data increases. Network data\\u2014such as the\\nfriendships in a social network\\u2014is often dynamic in a sense that relations between entities rise and\\ndecay over time. A fundamental problem in the analysis of such dynamic network data is to extract\\na summary of the common structure and the dynamics of the underlying relations between entities.\\n\\nAccurate models of structure and dynamics of network data have many applications. They allow us\\nto predict missing relationships [20, 21, 23], recommend potential new relations [2], identify clusters\\nand groups of nodes [1, 29], forecast future links [4, 9, 11, 24], and even predict group growth and\\nlongevity [15].\\n\\nHere we present a new approach to modeling network dynamics by considering time-evolving inter-\\nactions between groups of nodes as well as the arrival and departure dynamics of individual nodes\\nto these groups. We develop a dynamic network model, Dynamic Multi-group Membership Graph\\nModel, that identi\\ufb01es the birth and death of individual groups as well as the dynamics of node join-\\ning and leaving groups in order to explain changes in the underlying network linking structure. Our\\nnonparametric model considers an in\\ufb01nite number of latent groups, where each node can belong to\\nmultiple groups simultaneously. We capture the evolution of individual node group memberships\\nvia a Factorial Hidden Markov model. However, in contrast to recent works on dynamic network\\nmodeling [4, 5, 11, 12, 14], we explicitly model the birth and death dynamics of individual groups\\nby using a distance-dependent Indian Buffet Process [7]. Under our model only active/alive groups\\nin\\ufb02uence relationships in a network at a given time. Further innovation of our approach is that we\\nnot only model relations between the members of the same group but also account for links between\\nmembers and non-members. By explicitly modeling group lifespan and group connectivity structure\\nwe achieve greater modeling \\ufb02exibility, which leads to improved performance on link prediction and\\nnetwork forecasting tasks as well as to increased interpretability of obtained results.\\n\\n1\\n\\n\\fThe rest of the paper is organized as follows: Section 2 provides the background and Section 3\\npresents our generative model and motivates its parametrization. We discuss related work in Sec-\\ntion 4 and present model inference procedure in Section 5. Last, in Section 6 we provide experi-\\nmental results as well as analysis of the social network from the movie, The Lord of the Rings.\\n\\n2 Models of Dynamic Networks\\n\\nFirst, we describe general components of modern dynamic network models [4, 5, 11, 14]. In the\\nnext section we will then describe our own model and point out the differences to the previous work.\\n\\nDynamic networks are generally conceptualized as discrete time series of graphs on a \\ufb01xed set of\\nnodes N . Dynamic network Y is represented as a time series of adjacency matrices Y (t) for each\\ntime t = 1, 2, \\u00b7 \\u00b7 \\u00b7 , T . In this work, we limit our focus to unweighted directed as well as undirected\\nnetworks. So, each Y (t) is a N \\u00d7 N binary matrix where Y (t)\\nij = 1 if a link from node i to j exists\\nat time t and Y (t)\\n\\nij = 0 otherwise.\\n\\nEach node i of the network is associated with a number of latent binary features that govern the\\ninteraction dynamics with other nodes of the network. We denote the binary value of feature k of\\nnode i at time t by z(t)\\nik \\u2208 {0, 1}. Such latent features can be viewed as assigning nodes to multi-\\nple overlapping, latent clusters or groups [1, 21]. In our work, we interpret these latent features as\\nmemberships to latent groups such as social communities of people with the same interests or hob-\\nbies. We allow each node to belong to multiple groups simultaneously. We model each node-group\\nmembership using a separate Bernoulli random variable [17, 22, 29]. This is in contrast to mixed-\\nmembership models where the distribution over individual node\\u2019s group memberships is modeled\\nusing a multinomial distribution [1, 5, 12]. The advantage of our multiple-membership approach\\nis as follows. Mixed-membership models (i.e., multinomial distribution over group memberships)\\nessentially assume that by increasing the amount of node\\u2019s membership to some group k, the same\\nnode\\u2019s membership to some other group k\\u2032 has to decrease (due to the condition that the probabilities\\nnormalize to 1). On the other hand, multiple-membership models do not suffer from this assumption\\nand allow nodes to truely belong to multiple groups. Furthermore, we consider a nonparametric\\nmodel of groups which does not restrict the number of latent groups ahead of time. Hence, our\\nmodel adaptively learns the appropriate number of latent groups for a given network at a given time.\\n\\nIn dynamic network models, one also speci\\ufb01es a process by which nodes dynamically join and leave\\ngroups. We assume that each node i can join or leave a given group k according to a Markov model.\\nHowever, since each node can join multiple groups independently, we naturally consider factorial\\nhidden Markov models (FHMM) [8], where latent group membership of each node independently\\nevolves over time. To be concrete, each membership z(t)\\nik evolves through a 2-by-2 Markov transition\\nprobability matrix Q(t)\\n= r), where\\nr, s \\u2208 {0 = non-member, 1 = member}.\\n\\nk [r, s] corresponds to P (z(t)\\n\\nk where each entry Q(t)\\n\\nik = s|z(t\\u22121)\\n\\nik\\n\\nNow, given node group memberships z(t)\\nik at time t one also needs to specify the process of link\\ngeneration. Links of the network realize according to a link function f (\\u00b7). A link from node i to\\nnode j at time t occurs with probability determined by the link function f (z(t)\\nj\\u00b7 ). In our model,\\nwe develop a link function that not only accounts for links between group members but also models\\nlinks between the members and non-members of a given group.\\n\\ni\\u00b7 , z(t)\\n\\n3 Dynamic Multi-group Membership Graph Model\\n\\nNext we shall describe our Dynamic Multi-group Membership Graph Model (DMMG) and point out\\nthe differences with the previous work. In our model, we pay close attention to the three processes\\ngoverning network dynamics: (1) birth and death dynamics of individual groups, (2) evolution of\\nmemberships of nodes to groups, and (3) the structure of network interactions between group mem-\\nbers as well as non-members. We now proceed by describing each of them in turn.\\n\\nModel of active groups. Links of the network are in\\ufb02uenced not only by nodes changing member-\\nships to groups but also by the birth and death of groups themselves. New groups can be born and\\nold ones can die. However, without explicitly modeling group birth and death there exists ambiguity\\n\\n2\\n\\n\\fbetween group membership change and the birth/death of groups. For example, consider two dis-\\njoint groups k and l such that their lifetimes and members do not overlap. In other words, group l is\\nborn after group k dies out. However, if group birth and death dynamics is not explicitly modeled,\\nthen the model could interpret that the two groups correspond to a single latent group where all the\\nmembers of k leave the group before the members of l join the group. To resolve this ambiguity we\\ndevise an explicit model of birth/death dynamics of groups by introducing a notion of active groups.\\n\\nUnder our model, a group can be in one of two states: it can be either active (alive) or inactive (not\\nyet born or dead). However, once a group becomes inactive, it can never be active again. That is,\\nonce a group dies, it can never be alive again. To ensure coherence of group\\u2019s state over time, we\\nbuild on the idea of distance-dependent Indian Buffet Processes (dd-IBP) [7]. The IBP is named\\nafter a metaphorical process that gives rise to a probability distribution, where customers enter an\\nIndian Buffet restaurant and sample some subset of an in\\ufb01nitely long sequence of dishes. In the\\ncontext of networks, nodes usually correspond to \\u2018customers\\u2019 and latent features/groups correspond\\nto \\u2018dishes\\u2019. However, we apply dd-IBP in a different way. We regard each time step t as a \\u2018customer\\u2019\\nthat samples a set of active groups Kt. So, at the \\ufb01rst time step t = 1, we have P oisson(\\u03bb) number\\nof groups that are initially active, i.e., |K1| \\u223c P oisson(\\u03bb). To account for death of groups we\\nthen consider that each active group at time t \\u2212 1 can become inactive at the next time step t with\\nprobability \\u03b3. On the other hand, P oisson(\\u03b3\\u03bb) new groups are also born at time t. Thus, at each\\ntime currently active groups can die, while new ones can also be born. The hyperparameter \\u03b3\\ncontrols for how often new groups are born and how often old ones die. For instance, there will be\\nalmost no newborn or dead groups if \\u03b3 \\u2248 1, while there would be no temporal group coherence and\\npractically all the groups would die between consecutive time steps if \\u03b3 = 0.\\n\\nFigure 1(a) gives an example of the above process. Black circles indicate active groups and white\\ncircles denote inactive (not yet born or dead) groups. Groups 1 and 3 exist at t = 1 and Group 2\\nis born at t = 2. At t = 3, Group 3 dies but Group 4 is born. Without our group activity model,\\nGroup 3 could have been reused with a completely new set of members and Group 4 would have\\nnever been born. Our model can distinguish these two disjoint groups.\\n\\nFormally, we denote the number of active groups at time t by Kt = |Kt|. We also denote the state\\n(active/inactive) of group k at time t by W (t)\\nk = 1{k \\u2208 Kt}. For convenience, we also de\\ufb01ne a set\\nof newly active groups at time t be K+\\n\\nt = |K+\\nt |.\\nPutting it all together we can now fully describe the process of group birth/death as follows:\\n\\nk = 0 \\u2200t\\u2032 < t} and K +\\n\\nk = 1, W (t\\u2032)\\n\\nt = {k|W (t)\\n\\nfor t = 1\\nfor t > 1\\n\\nK +\\n\\nP oisson (\\u03b3\\u03bb) ,\\n\\nt \\u223c(cid:26)P oisson (\\u03bb) ,\\nk \\u223c\\uf8f1\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3\\n\\nBernoulli(1 \\u2212 \\u03b3)\\n1,\\n0,\\n\\nW (t)\\n\\nk\\n\\n= 1\\nt\\u2032=1 K +\\n\\nif W (t\\u22121)\\n\\nif Pt\\u22121\\n\\notherwise .\\n\\nt\\u2032 < k \\u2264Pt\\n\\nt\\u2032=1 K +\\n\\nt\\u2032\\n\\n(1)\\n\\nNote that under this model an in\\ufb01nite number of active groups can exist. This means our model au-\\ntomatically determines the right number of active groups and each node can belong to many groups\\nsimultaneously. We now proceed by describing the model of node group membership dynamics.\\n\\nDynamics of node group memberships. We capture the dynamics of nodes joining and leaving\\ngroups by assuming that latent node group memberships form a Markov chain. In this framework,\\nnode memberships to active groups evolve through time according to Markov dynamics:\\n\\nP (z(t)\\n\\nik |z(t\\u22121)\\n\\nik\\n\\n) = Qk =(cid:18) 1 \\u2212 ak\\n\\nbk\\n\\nak\\n\\n1 \\u2212 bk (cid:19) ,\\n\\nwhere matrix Qk[r, s] denotes a Markov transition from state r to state s, which can be a \\ufb01xed\\nparameter, group speci\\ufb01c, or otherwise domain dependent as long as it de\\ufb01nes a Markov transition\\nmatrix. Thus, the transition of node\\u2019s i membership to active group k can be de\\ufb01ned as follows:\\n\\nak, bk \\u223c Beta(\\u03b1, \\u03b2), z(t)\\n\\nik \\u223c W (t)\\n\\nk\\n\\n\\u00b7 Bernoulli(cid:18)a\\n\\n(t\\u22121)\\nik\\n\\n1\\u2212z\\nk\\n\\n(1 \\u2212 bk)z\\n\\n(t\\u22121)\\n\\nik (cid:19) .\\n\\n(2)\\n\\nTypically, \\u03b2 > \\u03b1, which ensures that group\\u2019s memberships are not too volatile over time.\\n\\n3\\n\\n\\f(a) Group activity model\\n\\n(b) Link function model\\n\\nFigure 1: (a) Birth and death of groups: Black circles represent active and white circles represent inactive\\n(unborn or dead) groups. A dead group can never become active again.\\ndenotes\\nbinary node group memberships. Entries of link af\\ufb01nity matrix \\u0398k denotes linking parameters between all 4\\ncombinations of members (z(t)\\nij , individual\\naf\\ufb01nities \\u0398k[z(t)\\n\\ni = 0). To obtain link probability p(t)\\n\\ni = 1) and non-members (z(t)\\n\\n] are combined using a logistic function g(\\u00b7)\\n\\n(b) Link function: z(t)\\n\\n, z(t)\\n\\ni\\n\\nj\\n\\nj\\n\\n.\\n\\nRelationship between node group memberships and links of the network. Last, we describe the\\npart of the model that establishes the connection between node\\u2019s memberships to groups and the\\nlinks of the network. We achieve this by de\\ufb01ning a link function f (i, j), which for given a pair of\\nnodes i, j determines their interaction probability p(t)\\n\\nij based on their group memberships.\\n\\nWe build on the Multiplicative Attribute Graph model [16, 18], where each group k is associated\\nwith a link af\\ufb01nity matrix \\u0398k \\u2208 R2\\u00d72. Each of the four entries of the link af\\ufb01nity matrix captures\\nthe tendency of linking between group\\u2019s members, members and non-members, as well as non-\\nmembers themselves. While traditionally link af\\ufb01nities were considered to be probabilities, we\\nrelax this assumption by allowing af\\ufb01nities to be arbitrary real numbers and then combine them\\nthrough a logistic function to obtain a \\ufb01nal link probability.\\n\\nThe model is illustrated in Figure 1(b). Given group memberships z(t)\\njk of nodes i and j at\\ntime t the binary indicators \\u201cselect\\u201d an entry \\u0398k[z(t)\\njk ] of matrix \\u0398k. This way linking tendency\\nfrom node i to node j is re\\ufb02ected based on their membership to group k. We then determine the\\noverall link probability p(t)\\n\\nij by combining the link af\\ufb01nities via a logistic function g(\\u00b7)1. Thus,\\n\\nik and z(t)\\n\\nik , z(t)\\n\\nij = f (z(t)\\np(t)\\n\\ni\\u00b7 , z(t)\\n\\nj\\u00b7 ) = g \\u01ebt +\\n\\n\\u0398k[z(t)\\n\\nik , z(t)\\n\\njk ]! , Yij \\u223c Bernoulli(p(t)\\n\\nij )\\n\\n(3)\\n\\n\\u221e\\n\\nXk=1\\n\\nwhere \\u01ebt is a density parameter that re\\ufb02ects the varying link density of network over time.\\n\\nNote that due to potentially in\\ufb01nite number of groups the sum of an in\\ufb01nite number of link af\\ufb01nities\\nmay not be tractable. To resolve this, we notice that for a given \\u0398k subtracting \\u0398k[0, 0] from all its\\nentries and then adding this value to \\u01ebt does not change the overall linking probability p(t)\\nij . Thus, we\\ncan set \\u0398k[0, 0] = 0 and then only a \\ufb01nite number of af\\ufb01nities selected by z(t)\\nik have to be considered.\\nFor all other entries of \\u0398k we use N (0, \\u03bd2) as a prior distribution.\\n\\nTo sum up, Figure 2 illustrates the three components of the DMMG in a plate notation. Group\\u2019s\\nstate W (t)\\nik is de\\ufb01ned as\\nthe FHMM over active groups. Then, the link between nodes i and j is determined based on the\\ngroups they belong to and the corresponding group link af\\ufb01nity matrices \\u0398.\\n\\nis determined by the dd-IBP process and each node-group membership z(t)\\n\\nk\\n\\n4 Related Work\\n\\nClassically, non-Bayesian approaches such as exponential random graph models [10, 27] have been\\nused to study dynamic networks. On the other hand, in the Bayesian approaches to dynamic network\\nanalysis latent variable models have been most widely used. These approaches differ by the struc-\\nture of the latent space that they assume. For example, euclidean space models [13, 24] place nodes\\n\\n1g(x) = exp(x)/(1 + exp(x))\\n\\n4\\n\\n\\fFigure 2: Dynamic Multi-group Membership Graph Model. Network Y depends on each node\\u2019s group mem-\\nberships Z and active groups W . Links of Y appear via link af\\ufb01nities \\u0398.\\n\\nin a low dimensional Euclidean space and the network evolution is then modeled as a regression\\nproblem of node\\u2019s future latent location. In contrast, our model uses HMMs, where latent vari-\\nables stochastically depend on the state at the previous time step. Related to our work are dynamic\\nmixed-membership models where a node is probabilistically allocated to a set of latent features. Ex-\\namples of this model include the dynamic mixed-membership block model [5, 12] and the dynamic\\nin\\ufb01nite relational model [14]. However, the critical difference here is that our model uses multi-\\nmemberships where node\\u2019s membership to one group does not limit its membership to other groups.\\nProbably most related to our work here are DRIFT [4] and LFP [11] models. Both of these models\\nconsider Markov switching of latent multi-group memberships over time. DRIFT uses the in\\ufb01nite\\nfactorial HMM [6], while LFP adds \\u201csocial propagation\\u201d to the Markov processes so that network\\nlinks of each node at a given time directly in\\ufb02uence group memberships of the corresponding node\\nat the next time. Compared to these models, we uniquely incorporate the model of group birth and\\ndeath and present a novel and powerful linking function.\\n\\n5 Model Inference via MCMC\\n\\nWe develop a Markov chain Monte Carlo (MCMC) procedure to approximate samples from the\\nposterior distribution of the latent variables in our model. More speci\\ufb01cally, there are \\ufb01ve types\\nof variables that we need to sample: node group memberships Z = {z(t)\\nik }, group states W =\\n{W (t)\\nk }, group membership transitions Q = {Qk}, link af\\ufb01nities \\u0398 = {\\u0398k}, and density parameters\\n\\u01eb = {\\u01ebt}. By sampling each type of variables while \\ufb01xing all the others, we end up with many\\nsamples representing the posterior distribution P (Z, W, Q, \\u0398, \\u01eb|Y, \\u03bb, \\u03b3, \\u03b1, \\u03b2). We shall now explain\\na sampling strategy for each varible type.\\n\\nSampling node group memberships Z. To sample node group membership z(t)\\nik , we use the\\nforward-backward recursion algorithm [26]. The algorithm \\ufb01rst de\\ufb01nes a deterministic forward\\npass which runs down the chain starting at time one, and at each time point t collects information\\nfrom the data and parameters up to time t in a dynamic programming cache. A stochastic backward\\npass starts at time T and samples each z(t)\\nik in backwards order using the information collected dur-\\ning the forward pass. In our case, we only need to sample z(T B\\nk indicate the\\nbirth time and the death time of group k. Due to space constraints, we discuss further details in the\\nextended version of the paper [19].\\n\\nk and T D\\n\\nwhere T B\\n\\nk :T D\\nk )\\n\\nik\\n\\nSampling group states W . To update active groups, we use the Metropolis-Hastings algorithm\\nwith the following proposal distribution P (W \\u2192 W \\u2032): We add a new group, remove an existing\\ngroup, or update the life time of an active group with the same probability 1/3. When adding a new\\ngroup k\\u2032 we select the birth and death time of the group at random such that 1 \\u2264 T B\\nk\\u2032 \\u2264 T D\\nk\\u2032 \\u2264 T .\\nFor removing groups we randomly pick one of existing groups k\\u2032\\u2032 and remove it by setting W (t)\\nk\\u2032\\u2032 = 0\\nfor all t. Finally, to update the birth and death time of an existing group, we select an existing group\\nand propose new birth and death time of the group at random. Once new state vector W \\u2032 is proposed\\nwe accept it with probability\\n\\nmin(cid:18)1,\\n\\nP (Y |W \\u2032)P (W \\u2032|\\u03bb, \\u03b3)P (W \\u2032 \\u2192 W )\\n\\nP (Y |W )P (W |\\u03bb, \\u03b3)P (W \\u2192 W \\u2032) (cid:19) .\\n\\n(4)\\n\\nWe compute P (W |\\u03bb, \\u03b3) and P (W \\u2032 \\u2192 W ) in a closed form, while we approximate the posterior\\nP (Y |W ) by sampling L Gibbs samples while keeping W \\ufb01xed.\\n\\n5\\n\\n\\fSampling group membership transition matrix Q. Beta distribution is a conjugate prior of\\nBernoulli distribution and thus we can sample each ak and bk in Qk directly from the posterior\\ndistribution: ak \\u223c Beta(\\u03b1 + N01,k, \\u03b2 + N00,k) and bk \\u223c Beta(\\u03b1 + N10,k, \\u03b2 + N11,k), where Nrs,k\\nis the number of nodes that transition from state r to s in group k (r, s \\u2208 {0 = non-member, 1 =\\nmember}).\\n\\nSampling link af\\ufb01nities \\u0398. Once node group memberships Z are determined, we update the entries\\nof link af\\ufb01nity matrices \\u0398k. Direct sampling of \\u0398 is intractable because of non-conjugacy of the\\nlogistic link function. An appropriate method in such case would be the Metropolis-Hastings that\\naccepts or rejects the proposal based on the likelihood ratio. However, to avoid low acceptance\\nrates and quickly move toward the mode of the posterior distribution, we develop a method based\\non Hybrid Monte Carlo (HMC) sampling [3]. We guide the sampling using the gradient of log-\\nlikelihood function with respect to each \\u0398k. Because links Y (t)\\nij are generated independently given\\ngroup memberships Z, the gradient with respect to \\u0398k[x, y] can be computed by\\n\\n\\u2212\\n\\n1\\n2\\u03c32 \\u03982\\n\\nk +Xi,j,t(cid:16)Y (t)\\n\\nij \\u2212 p(t)\\n\\nik = x, z(t)\\n\\njk = y} .\\n\\nij (cid:17) 1{z(t)\\n\\n(5)\\n\\nUpdating density parameter \\u01eb. Parameter vector \\u01eb is de\\ufb01ned over a \\ufb01nite dimension T . Therefore,\\nwe can update \\u01eb by maximizing the log-likelihood given all the other variables. We compute the\\ngradient update for each \\u01ebt and directly update \\u01ebt via a gradient step.\\n\\nUpdating hyperparameters. The number of groups over all time periods is given by a Poisson\\ndistribution with parameter \\u03bb (1 + \\u03b3 (T \\u2212 1)). Hence, given \\u03b3 we sample \\u03bb by using a Gamma\\nconjugate prior. Similarly, we can use the Beta conjugate prior for the group death process (i.e.,\\nBernoulli distribution) to sample \\u03b3. However, hyperparameters \\u03b1 and \\u03b2 do not have a conjugate\\nprior, so we update them by using a gradient method based on the sampled values of ak and bk.\\n\\nij\\n\\nTime complexity of model parameter estimation. Last, we brie\\ufb02y comment on the time com-\\nplexity of our model parameter estimation procedure. Each sample z(t)\\nik requires computation of\\nlink probability p(t)\\nfor all j 6= i. Since the expected number of active groups at each time is \\u03bb,\\nthis requires O(\\u03bbN 2T ) computations of p(t)\\nij . By caching the sum of link af\\ufb01nities between every\\npair of nodes sampling Z as well as W requires O(\\u03bbN 2T ) time. Sampling \\u0398 and \\u01eb also requires\\nO(\\u03bbN 2T ) because the gradient of each p(t)\\nij needs to be computed. Overall, our approach takes\\nO(\\u03bbN 2T ) to obtain a single sample, while models that are based on the interaction matrix between\\nall groups [4, 5, 11] require O(K 2N 2T ), where K is the expected number of groups. Furthermore,\\nit has been shown that O(log N ) groups are enough to represent networks [16, 18]. Thus, in practice\\nK (i.e., \\u03bb) is of order log N and the running time for each sample is O(N 2T log N ).\\n\\n6 Experiments\\n\\nWe evaluate our model on three different tasks. For quantitative evaluation, we perform missing link\\nprediction as well as future network forecasting and show our model gives favorable performance\\nwhen compared to current dynamic and static network models. We also analyze the dynamics of\\ngroups in a dynamic social network of characters in a movie \\u201cThe Lord of the Rings: The Two\\nTowers.\\u201d\\n\\nExperimental setup. For the two prediction experiments, we use the following three datasets. First,\\nthe NIPS co-authorships network connects two people if they appear on the same publication in\\nthe NIPS conference in a given year. Network spans T =17 years (1987 to 2003). Following [11]\\nwe focus on a subset of 110 most connected people over all time periods. Second, the DBLP co-\\nauthorship network is obtained from 21 Computer Science conferences from 2000 to 2009 (T =\\n10) [28]. We focus on 209 people by taking 7-core of the aggregated network for the entire time.\\nThird, the INFOCOM dataset represents the physical proximity interactions between 78 students at\\nthe 2006 INFOCOM conference, recorded by wireless detector remotes given to each attendee [25].\\nAs in [11] we use the processed data that removes inactive time slices to have T =50.\\n\\nTo evaluate the predictive performance of our model, we compare it to three baseline models. For\\na naive baseline model, we regard the relationship between each pair of nodes as the instance of\\n\\n6\\n\\n\\fModel\\n\\nNaive\\nLFRM\\nDRIFT\\n\\nDMMG\\n\\nTestLL\\n\\n-2030\\n-880\\n-758\\n\\n\\u2212624\\n\\nNIPS\\nAUC\\n\\n0.808\\n0.777\\n0.866\\n0.916\\n\\nF1\\n\\nTestLL\\n\\n-12051\\n0.177\\n-3783\\n0.195\\n-3108\\n0.296\\n0.434 \\u22122684\\n\\nDBLP\\nAUC\\n\\n0.814\\n0.784\\n0.916\\n0.939\\n\\nINFOCOM\\n\\nF1\\n\\nTestLL\\n\\nAUC\\n\\nF1\\n\\n-17821\\n0.300\\n-8689\\n0.146\\n-6654\\n0.421\\n0.492 \\u22126422\\n\\n0.677\\n0.946\\n0.973\\n0.976\\n\\n0.252\\n0.703\\n0.757\\n0.764\\n\\nTable 1: Missing link prediction. We bold the performance of the best scoring method. Our DMMG performs\\nthe best in all cases. All improvements are statistically signi\\ufb01cant at 0.01 signi\\ufb01cance level.\\n\\nindependent Bernoulli distribution with Beta(1, 1) prior. Thus, for a given pair of nodes, the link\\nprobability at each time equals to the expected probability from the posterior distribution given net-\\nwork data. Second baseline is LFRM [21], a model of static networks. For missing link prediction,\\nwe independently \\ufb01t LFRM to each snapshot of dynamic networks. For network forecasting task,\\nwe \\ufb01t LFRM to the most recent snapshot of a network. Even though LFRM does not capture time\\ndynamics, we consider this to be a strong baseline model. Finally, for the comparison with dynamic\\nnetwork models, we consider two recent state of the art models. The DRIFT model [4] is based\\non an in\\ufb01nite factorial HMM and authors kindly shared their implementation. We also consider the\\nLFP model [11] for which we were not able to obtain the implementation, but since we use the same\\ndatasets, we compare performance numbers directly with those reported in [11].\\n\\nTo evaluate predictive performance, we use various standard evaluation metrics. First, to assess\\ngoodness of inferred probability distributions, we report the log-likelihood of held-out edges. Sec-\\nond, to verify the predictive performance, we compute the area under the ROC curve (AUC). Last,\\nwe also report the maximum F1-score (F1) by scanning over all possible precision/recall thresholds.\\n\\nTask 1: Predicting missing links. To generate the datasets for the task of missing link prediction,\\nwe randomly hold out 20% of node pairs (i.e., either link or non-link) throughout the entire time\\nperiod. We then run each model to obtain 400 samples after 800 burn-in samples for each of 10\\nMCMC chains. Each sample gives a link probability for a given missing entry, so the \\ufb01nal link\\nprobability of a missing entry is computed by averaging the corresponding link probability over all\\nthe samples. This \\ufb01nal link probability provides the evaluation metric for a given missing data entry.\\n\\nTable 1 shows average evaluation metrics for each model and dataset over 10 runs. We also compute\\nthe p-value on the difference between two best results for each dataset and metric. Overall, our\\nDMMG model signi\\ufb01cantly outperforms the other models in every metric and dataset. Particularly\\nin terms of F1-score we gain up to 46.6% improvement over the other models.\\n\\nBy comparing the naive model and LFRM, we observe that LFRM performs especially poorly\\ncompared to the naive model in two networks with few edges (NIPS and DBLP). Intuitively this\\nmakes sense because due to the network sparsity we can obtain more information from the temporal\\ntrajectory of each link than from each snapshot of network. However, both DRIFT and DMMG\\nsuccessfully combine the temporal and the network information which results in better predictive\\nperformance. Furthermore, we note that DMMG outperforms the other models by a larger margin\\nas networks get sparser. DMMG makes better use of temporal information because it can explicitly\\nmodel temporally local links through active groups.\\n\\nLast, we also compare our model to the LFP model. The LFP paper reports AUC ROC score of\\n\\u223c0.85 for NIPS and \\u223c0.95 for INFOCOM on the same task of missing link prediction with 20%\\nheld-out missing data [11]. Performance of our DMMG on these same networks under the same\\nconditions is 0.916 for NIPS and 0.976 for INFOCOM, which is a strong improvement over LFP.\\n\\nTask 2: Future network forecasting. Here we are given a dynamic network up to time Tobs and\\nthe goal is to predict the network at the next time Tobs + 1. We follow the experimental protocol\\ndescribed in [4, 11]: We train the models on \\ufb01rst Tobs networks, \\ufb01x the parameters, and then for\\neach model we run MCMC sampling one time step into the future. For each model and network,\\nwe obtain 400 samples with 10 different MCMC chains, resulting in 400K network samples. These\\nnetwork samples provide a probability distribution over links at time Tobs + 1.\\n\\nTable 2 shows performance averaged over different Tobs values ranging from 3 to T -1. Overall,\\nDMMG generally exhibits the best performance, but performance results seem to depend on the\\ndataset. DMMG performs the best at 0.001 signi\\ufb01cance level in terms of AUC and F1 for the NIPS\\ndataset, and at 0.05 level for the INFOCOM dataset. While DMMG improves performance on AUC\\n\\n7\\n\\n\\fModel\\n\\nNaive\\nLFRM\\nDRIFT\\n\\nTestLL\\n\\n-547\\n-356\\n\\u2212148\\n\\nDMMG\\n\\n-170\\n\\nNIPS\\nAUC\\n\\n0.524\\n0.398\\n0.672\\n0.732\\n\\nF1\\n\\n0.130\\n0.011\\n0.084\\n0.196\\n\\nTestLL\\n\\n-3248\\n-1680\\n\\u22121324\\n\\nDBLP\\nAUC\\n0.668\\n0.492\\n0.650\\n\\n-1347\\n\\n0.652\\n\\nINFOCOM\\n\\nF1\\n\\nTestLL\\n\\nAUC\\n\\nF1\\n\\n0.243\\n0.024\\n0.122\\n0.245\\n\\n-774\\n-760\\n-661\\n\\n\\u2212625\\n\\n0.673\\n0.640\\n0.782\\n0.804\\n\\n0.270\\n0.248\\n0.381\\n0.392\\n\\nTable 2: Future network forecasting. DMMG performs best on NIPS and INFOCOM while results on DBLP\\nare mixed.\\n\\nhaldir\\ngandalf\\nmerry\\nfrodo\\nsam\\ngollum\\npippin\\naragorn\\nlegolas\\ngimli\\nsaruman\\neowyn\\neomer\\ntheoden\\ngrima\\nhama\\nfaramir\\narwen\\nelrond\\ngaladriel\\nmadril\\n\\nhaldir\\ngandalf\\nmerry\\nfrodo\\nsam\\ngollum\\npippin\\naragorn\\nlegolas\\ngimli\\nsaruman\\neowyn\\neomer\\ntheoden\\ngrima\\nhama\\nfaramir\\narwen\\nelrond\\ngaladriel\\nmadril\\n\\nhaldir\\ngandalf\\nmerry\\nfrodo\\nsam\\ngollum\\npippin\\naragorn\\nlegolas\\ngimli\\nsaruman\\neowyn\\neomer\\ntheoden\\ngrima\\nhama\\nfaramir\\narwen\\nelrond\\ngaladriel\\nmadril\\n\\n 1\\n\\n 2\\n\\n 3\\n\\n 4\\n\\n 5\\n\\n 1\\n\\n 2\\n\\n 3\\n\\n 4\\n\\n 5\\n\\n 1\\n\\n 2\\n\\n 3\\n\\n 4\\n\\n 5\\n\\n(a) Group 1\\n\\n(b) Group 2\\n\\n(c) Group 3\\n\\nFigure 3: Group arrival and departure dynamics of different characters in the Lord of the Rings. Dark areas in\\nthe plots correspond to a give node\\u2019s (y-axis) membership to each group over time (x-axis)\\n\\n.\\n\\n(9%) and F1 (133%), DRIFT achieves the best log-likelihood on the NIPS dataset. In light of our\\nprevious observations, we conjecture that this is due to change in network edge density between\\ndifferent snapshots. On the DBLP dataset, DRIFT gives the best log-likelihood, the naive model\\nperforms best in terms of AUC, and DMMG is the best on F1 score. However, in all cases of DBLP\\ndataset, the differences are not statistically signi\\ufb01cant. Overall, DMMG performs the best on NIPS\\nand INFOCOM and provides comparable performance on DBLP.\\n\\nTask 3: Case study of \\u201cThe Lord of the Rings: The Two Towers\\u201d social network. Last, we also\\ninvestigate groups identi\\ufb01ed by our model on a dynamic social network of characters in a movie,\\nThe Lord of the Rings: The Two Towers. Based on the transcript of the movie we created a dynamic\\nsocial network on 21 characters and T =5 time epochs, where we connect a pair of characters if they\\nco-appear inside some time window.\\n\\nWe \\ufb01t our model to this network and examine the results in Figure 3. Our model identi\\ufb01ed three\\ndynamic groups, which all nicely correspond to the Lord of the Rings storyline. For example,\\nthe core of Group 1 corresponds to Aragorn, elf Legolas, dwarf Gimli, and people in Rohan who\\nin the end all \\ufb01ght against the Orcs. Similarly, Group 2 corresponds to hobbits Sam, Frodo and\\nGollum on their mission to destroy the ring in Mordor, and are later joined by Faramir and ranger\\nMadril. Interestingly, Group 3 evolving around Merry and Pippin only forms at t=2 when they start\\ntheir journey with Treebeard and later \\ufb01ght against wizard Saruman. While the \\ufb01ght occurs in two\\nseparate places we \\ufb01nd that some scenes are not distinguishable, so it looks as if Merry and Pippin\\nfought together with Rohan\\u2019s army against Saruman\\u2019s army.\\n\\nAcknowledgments\\n\\nWe thank Creighton Heaukulani and Zoubin Ghahramani for sharing data and code. This research\\nhas been supported in part by NSF IIS-1016909, CNS-1010921, IIS-1149837, IIS-1159679, IARPA\\nAFRL FA8650-10-C-7058, Okawa Foundation, Docomo, Boeing, Allyes, Volkswagen, Intel, Alfred\\nP. Sloan Fellowship and the Microsoft Faculty Fellowship.\\n\\nReferences\\n\\n[1] E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing. Mixed membership stochastic blockmodels.\\n\\nJMLR, 9, 2008.\\n\\n[2] L. Backstrom and J. Leskovec. Supervised random walks: Predicting and recommending links in social\\n\\nnetworks. In WSDM, 2011.\\n\\n8\\n\\n\\f[3] S. Duane, A. Kennedy, B. J. Pendleton, and D. Roweth. Hybrid monte carlo. Physics Letter B,\\n\\n195(2):216\\u2013222, 1987.\\n\\n[4] J. Foulds, A. U. Asuncion, C. DuBois, C. T. Butts, and P. Smyth. A dynamic relational in\\ufb01nite feature\\n\\nmodel for longitudinal social networks. In AISTATS, 2011.\\n\\n[5] W. Fu, L. Song, and E. P. Xing. Dynamic mixed membership blockmodel for evolving networks.\\n\\nIn\\n\\nICML, 2009.\\n\\n[6] J. V. Gael, Y. W. Teh, , and Z. Ghahramani. The in\\ufb01nite factorial hidden markov model. In NIPS, 2009.\\n\\n[7] S. J. Gershman, P. I. Frazier, and D. M. Blei. Distance dependent in\\ufb01nite latent feature models.\\n\\narXiv:1110.5454, 2012.\\n\\n[8] Z. Ghahramani and M. I. Jordan. Factorial hidden markov models. Machine Learning, 29(2-3):245\\u2013273,\\n\\n1997.\\n\\n[9] F. Guo, S. Hanneke, W. Fu, and E. P. Xing. Recovering temporally rewiring networks: a model-based\\n\\napproach. In ICML, 2007.\\n\\n[10] S. Hanneke, W. Fu, and E. P. Xing. Discrete temporal models of social networks. Electron. J. Statist.,\\n\\n4:585\\u2013605, 2010.\\n\\n[11] C. Heaukulani and Z. Ghahramani. Dynamic probabilistic models for latent feature propagation in social\\n\\nnetworks. In ICML, 2013.\\n\\n[12] Q. Ho, L. Song, and E. P. Xing. Evolving cluster mixed-membership blockmodel for time-varying net-\\n\\nworks. In AISTATS, 2011.\\n\\n[13] P. D. Hoff, A. E. Raftery, and M. S. Handcock. Latent space approaches to social network analysis. JASA,\\n\\n97(460):1090 \\u2013 1098, 2002.\\n\\n[14] K. Ishiguro, T. Iwata, N. Ueda, and J. Tenenbaum. Dynamic in\\ufb01nite relational model for time-varying\\n\\nrelational data analysis. In NIPS, 2010.\\n\\n[15] S. Kairam, D. Wang, and J. Leskovec. The life and death of online groups: Predicting group growth and\\n\\nlongevity. In WSDM, 2012.\\n\\n[16] M. Kim and J. Leskovec. Modeling social networks with node attributes using the multiplicative attribute\\n\\ngraph model. In UAI, 2011.\\n\\n[17] M. Kim and J. Leskovec. Latent multi-group membership graph model. In ICML, 2012.\\n\\n[18] M. Kim and J. Leskovec. Multiplicative attribute graph model of real-world networks. Internet Mathe-\\n\\nmatics, 8(1-2):113\\u2013160, 2012.\\n\\n[19] M. Kim and J. Leskovec. Nonparametric multi-group membership model for dynamic networks.\\n\\narXiv:1311.2079, 2013.\\n\\n[20] J. R. Lloyd, P. Orbanz, Z. Ghahramani, and D. M. Roy. Random function priors for exchangeable arrays\\n\\nwith applications to graphs and relational data. In NIPS, 2012.\\n\\n[21] K. T. Miller, T. L. Grifths, and M. I. Jordan. Nonparametric latent feature models for link prediction. In\\n\\nNIPS, 2009.\\n\\n[22] M. M\\u00f8rup, M. N. Schmidt, and L. K. Hansen.\\n\\nIn\\ufb01nite multiple membership relational modeling for\\n\\ncomplex networks. In MLSP, 2011.\\n\\n[23] K. Palla, D. A. Knowles, and Z. Ghahramani. An in\\ufb01nite latent attribute model for network data.\\n\\nIn\\n\\nICML, 2012.\\n\\n[24] P. Sarkar and A. W. Moore. Dynamic social network analysis using latent space models. In NIPS, 2005.\\n\\n[25] J. Scott, R. Gass, J. Crowcroft, P. Hui, C. Diot, and A. Chaintreau. CRAWDAD data set cambridge/haggle\\n\\n(v. 2009-05-29), May 2009.\\n\\n[26] S. L. Scott. Bayesian methods for hidden markov models. JASA, 97(457):337\\u2013351, 2002.\\n\\n[27] T. A. B. Snijders, G. G. van de Bunt, and C. E. G. Steglich. Introduction to stochastic actor-based models\\n\\nfor network dynamics. Social Networks, 32(1):44\\u201360, 2010.\\n\\n[28] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su. Arnetminer: Extraction and mining of academic\\n\\nsocial networks. In KDD\\u201908, 2008.\\n\\n[29] J. Yang and J. Leskovec. Community-af\\ufb01liation graph model for overlapping community detection. In\\n\\nICDM, 2012.\\n\\n9\\n\\n\\f\",\n          \"Tangent Prop - A formalism for specifying \\nselected invariances in an adaptive network \\n\\nPatrice Simard \\n\\nAT&T Bell Laboratories \\n101 Crawford Corner Rd \\n\\nHolmdel, NJ 07733 \\n\\nBernard Victorri \\nUniversite de Caen \\nCaen 14032 Cedex \\n\\nFrance \\n\\nYann Le Cun \\n\\nAT&T Bell Laboratories \\n101 Crawford Corner Rd \\n\\nHolmdel, NJ 07733 \\n\\nJohn Denker \\n\\nAT&T Bell Laboratories \\n101 Crawford Corner Rd \\n\\nHolmdel, NJ 07733 \\n\\nAbstract \\n\\nIn many machine learning applications, one has access, not only to training \\ndata, but also to some high-level a priori knowledge about the desired be(cid:173)\\nhavior of the system. For example, it is known in advance that the output \\nof a character recognizer should be invariant with respect to small spa(cid:173)\\ntial distortions of the input images (translations, rotations, scale changes, \\netcetera). \\nWe have implemented a scheme that allows a network to learn the deriva(cid:173)\\ntive of its outputs with respect to distortion operators of our choosing. \\nThis not only reduces the learning time and the amount of training data, \\nbut also provides a powerful language for specifying what generalizations \\nwe wish the network to perform. \\n\\n1 \\n\\nINTRODUCTION \\n\\nIn machine learning, one very often knows more about the function to be learned \\nthan just the training data. An interesting case is when certain directional deriva(cid:173)\\ntives of the desired function are known at certain points. For example, an image \\n895 \\n\\n\\f896 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\nFigure 1: Top: Small rotations of an original digital image of the digit \\\"3\\\" (center). \\nMiddle: Representation of the effect of the rotation in the input vector space space \\n(assuming there are only 3 pixels). Bottom: Images obtained by moving along the \\ntangent to the transformation curve for the same original digital image (middle). \\n\\nrecognition system might need to be invariant with respect to small distortions of \\nthe input image such as translations, rotations, scalings, etc.; a speech recognition \\nsystem n.ight need to be invariant to time distortions or pitch shifts. \\nIn other \\nwords, the derivative of the system's output should be equal to zero when the input \\nis transformed in certain ways. \\n\\nGiven a large amount of training data and unlimited training time, the system \\ncould learn these invariances from the data alone, but this is often infeasible. The \\nlimitation on data can be overcome by training the system with additional data \\nobtained by distorting (translating, rotating, etc.) \\nthe original patterns (Baird, \\n1990). The top of Fig. 1 shows artificial data generated by rotating a digital image of \\nthe digit \\\"3\\\" (with the original in the center). This procedure, called the \\\"distortion \\nmodel\\\" , has two drawbacks. First, the user must choose the magnitude of distortion \\nand how many instances should be generated. Second, and more importantly, the \\ndistorted data is highly correlated with the original data. This makes traditional \\nlearning algorithms such as back propagation very inefficient. The distorted data \\ncarries only a very small incremental amount of information, since the distorted \\npatterns are not very different from the original ones. It may not be possible to \\nadjust the learning system so that learning the invariances proceeds at a reasonable \\nrate while learning the original points is non-divergent. \\n\\nThe key idea in this paper is that it is possible to directly learn the effect on \\nthe output of distorting the input, independently from learning the undistorted \\n\\n\\fTangent Prop-A formalism for specifying selected invariances in an adaptive network \\n\\n897 \\n\\nF(x) \\n\\nF(x) \\n\\nx1 \\n\\nx2 \\n\\nx3 \\n\\nx4 \\n\\nx \\n\\nx1 \\n\\nx2 \\n\\nx3 \\n\\nx4 \\n\\nx \\n\\nFigure 2: Learning a given function (solid line) from a limited set of example (Xl \\nto X4). The fitted curves are shown in dotted line. Top: The only constraint is that \\nthe fitted curve goes through the examples. Bottom: The fitted curves not only \\ngoes through each examples but also its derivatives evaluated at the examples agree \\nwith the derivatives of the given function. \\n\\npatterns. When a pattern P is transformed (e.g. rotated) with a transformation \\ns that depends on one parameter a (e.g. the angle of the rotation), the set of all \\nthe transformed patterns S(P) = {sea, P) Va} is a one dimensional curve in the \\nvector space of the inputs (see Fig. 1). In certain cases, such as rotations of digital \\nimages, this curve must be made continuous using smoothing techniques, as will be \\nshown below. When the set of transformations is parameterized by n parameters \\nai (rotation, translation, scaling, etc.), S(P) is a manifold of at most n dimensions. \\nThe patterns in S(P) that are obtained through small transformations of P, i.e. \\nthe part of S( P) that is close to P, can be approximated by a plane tangent to \\nthe manifold S(P) at point P. Small transformations of P can be obtained by \\nadding to P a linear combination of vectors that span the tangent plane (tangent \\nvectors). The images at the bottom of Fig. 1 were obtained by that procedure. \\nMore importantly, the tangent vectors can be used to specify high order constraints \\non the function to be learned, as explained below. \\n\\nTo illustrate the method, consider the problem of learning a single-valued function \\nF from a limited set of examples. Fig. 2 (left) represents a simple case where the \\ndesired function F (solid line) is to be approximated by a function G (dotted line) \\nfrom four examples {(Xi, F(Xi))}i=1,2,3,4. As exemplified in the picture, the fitted \\nfunction G largely disagrees with the desired function F between the examples. If \\nthe functions F and G are assumed to be differentiable (which is generally the case), \\nthe approximation G can be greatly improved by requiring that G's derivatives \\nevaluated at the points {xd are equal to the derivatives of F at the same points \\n(Fig. 2 right). This result can be extended to multidimensional inputs. In this case, \\nwe can impose the equality of the derivatives of F and G in certain directions, not \\nnecessarily in all directions of the input space. \\nSuch constraints find immediate use in traditional learning problems. It is often the \\ncase that a priori knowledge is available on how the desired function varies with \\n\\n\\f898 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\npattern P \\n\\npattern P \\nrotated by ex \\n\\n-\\n\\ntangent \\nvector \\n\\n--\\n\\nFigure 3: How to compute a tangent vector for a given transformation (in this case \\na rotation). \\n\\nrespect to some transformations of the input. It is straightforward to derive the \\ncorresponding constraint on the directional derivatives of the fitted function G in \\nthe directions of the transformations (previously named tangent vectors). Typical \\nexamples can be found in pattern recognition where the desired classification func(cid:173)\\ntion is known to be invariant with respect to some transformation of the input such \\nas translation, rotation, scaling, etc., in other words, the directional derivatives of \\nthe classification function in the directions of these transformations is zero. \\n\\n2 \\n\\nIMPLEMENTATION \\n\\nThe implementation can be divided into two parts. The first part consists in com(cid:173)\\nputing the tangent vectors. This part is independent from the learning algorithm \\nused subsequently. The second part consists in modifying the learning algorithm \\n(for instance backprop) to incorporate the information about the tangent vectors. \\nPart I: Let x be an input pattern and s be a transformation operator acting \\non the input space and depending on a parameter a. If s is a rotation operator \\nfor instance, then s( a, x) denotes the input x rotated by the angle a. We will \\nrequire that the transformation operator s be differentiable with respect to a and \\nx, and that s(O, x) = x. The tangent vector is by definition 8s(a, x)/8a. It can be \\napproximated by a finite difference, as shown in Fig. 3. In the figure, the input space \\nis a 16 by 16 pixel image and the patterns are images of handwritten digits. The \\ntransformations considered are rotations of the digit images. The tangent vector \\nis obtained in two steps. First the image is rotated by an infinitesimal amount a. \\nThis is done by computing the rotated coordinates of each pixel and interpolating \\nthe gray level values at the new coordinates. This operation can be advantageously \\ncombined with some smoothing using a convolution. A convolution with a Gaussian \\nprovides an efficient interpolation scheme in O(nm) multiply-adds, where nand m \\nare the (gaussian) kernel and image sizes respectively. The next step is to subtract \\n(pixel by pixel) the rotated image from the original image and to divide the result \\n\\n\\fTangent Prop-A formalism for specifying selected invariances in an adaptive network \\n\\n899 \\n\\nby the scalar 0 (see Fig. 3). If Ie types of transformations are considered, there \\nwill be Ie different tangent vectors per pattern. For most algorithms, these do not \\nrequire any storage space since they can be generated as needed from the original \\npattern at negligible cost. \\nPart IT: Tangent prop is an extension of the backpropagation algorithm, allowing \\nit to learn directional derivatives. Other algorithms such as radial basis functions \\ncan be extended in a similar fashion. \\n\\nTo implement our idea, we will modify the usual weight-update rule: \\nis replaced with ~w = -7] ow (E + J.tEr) \\n\\noE \\n~w = -7] ow \\n\\n0 \\n\\n(1) \\n\\nwhere 7] is the learning rate, E the usual objective function, Er an additional objec(cid:173)\\ntive function (a regularizer) that measures the discrepancy between the actual and \\ndesired directional derivatives in the directions of some selected transformations, \\nand J.t is a weighting coefficient. \\nLet x be an input pattern, y = G(x) be the input-output function of the network. \\nThe regularizer Er is of the form \\n\\nwhere Er(x) is \\n\\nEr(x) \\n\\n:e e trainingset \\n\\n(2) \\n\\nHere, Ki(x) is the desired directional derivative of G in the direction induced by \\ntransformation Si applied to pattern x. The second term in the norm symbol is the \\nactual directional derivative, which can be rewritten as \\n\\n= G'{x). OSi(O, x) \\n\\n00 \\n\\n0=0 \\n\\n0=0 \\n\\nwhere G'(x) is the Jacobian of G for pattern x, and OSi(O, x)Joo is the tangent \\nvector associated to transformation Si as described in Part I. Multiplying the tangent \\nvector by the Jacobian involves one forward propagation through a \\\"linearized\\\" \\nversion of the network. In the special case where local invariance with respect to \\nthe Si'S is desired, Ki(x) is simply set to o. \\nComposition of transformations: The theory of Lie groups (Gilmore, 1974) \\nensures that compositions of local (small) transformations Si correspond to linear \\ncombinations of the corresponding tangent vectors (the local transformations Si \\nhave a structure of Lie algebra). Consequently, if Er{x) = 0 is verified, the network \\nderivative in the direction of a linear combination of the tangent vectors is equal \\nto the same linear combination of the desired derivatives. In other words if the \\nnetwork is successfully trained to be locally invariant with respect to, say, horizontal \\ntranslation and vertical translations, it will be invariant with respect to compositions \\nthereof. \\nWe have derived and implemented an efficient algorithm, \\\"tangent prop\\\" , for per(cid:173)\\nforming the weight update (Eq. 1). It is analogous to ordinary backpropagation, \\n\\n\\f900 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\nW'+l \\n\\nIti \\n\\nW l+1 \\n\\nIti \\n\\ne: l \\n\\nb'.-l , \\n\\nx\\u00b7 , \\n'-I \\n\\nNetwork \\n\\nj3J-1 \\n\\ne;-I \\nJacobian nework \\n\\nFigure 4: forward propagated variables (a, x, a, e), and backward propagated vari(cid:173)\\nables (b, y, p, t/J) in the regular network (roman symbols) and the Jacobian (lin(cid:173)\\nearized) network (greek symbols) \\n\\nbut in addition to propagating neuron activations, it also propagates the tangent \\nvectors. The equations can be easily derived from Fig. 4. \\nForward propagation: \\n\\na~ = ~ wL x'.-l \\nI, , \\n\\u2022 \\n\\nL...J \\ni \\n\\nx~ = u(aD \\n\\nTangent forward propagation: \\n\\n, _ ~ , ~'-1 \\nai - L...J wW\\\"i \\n\\ni \\n\\ne! = u'(a~)a~ \\n\\nTangent gradient backpropagation: \\n\\n(31 - ~ w'+1.I.l+1 \\ni - L...J \\nIt \\n\\nIti \\u00a5lit \\n\\nGradient backpropagation: \\n\\nb' - ~ w1+ 1yl+1 \\ni - L...J \\nIt \\n\\nIti \\n\\nIt \\n\\nWeight update: \\n\\n8[E(W, Up) + I'Er (W, Up, Tp)] _ 1-1 , + ~'-l.I.' \\n\\u00a5Ii \\n\\n- Xi Yi \\n\\nI'\\\\oi \\n\\nw\\u00b7\\u00b7 I, \\n8 ' \\n\\n(3) \\n\\n(4) \\n\\n(5) \\n\\n(6) \\n\\n(7) \\n\\n\\fTangent Prop--A formalism for specifying selected invariances in an adaptive network \\n\\n901 \\n\\n60 \\n\\n50 \\n\\n%Erroron \\nthe test set \\n\\n20 \\n\\n10 \\n\\n160 \\n\\n320 \\n\\nTraining set size \\n\\nFigure 5: Generalization performance curve as a function of the training set size for \\nthe tangent prop and the backprop algorithms \\n\\nThe regularization parameter jJ is tremendously important, because it determines \\nthe tradeoff between minimizing the usual objective function and minimizing the \\ndirectional derivative error. \\n\\n3 RESULTS \\n\\nTwo experiments illustrate the advantages of tangent prop. The first experiment \\nis a classification task, using a small (linearly separable) set of 480 binarized hand(cid:173)\\nwritten digit. The training sets consist of 10, 20, 40, 80, 160 or 320 patterns, and \\nthe training set contains the remaining 160 patterns. The patterns are smoothed \\nusing a gaussian kernel with standard deviation of one half pixel. For each of the \\ntraining set patterns, the tangent vectors for horizontal and vertical translation \\nare computed. The network has two hidden layers with locally connected shared \\nweights, and one output layer with 10 units (5194 connections, 1060 free parame(cid:173)\\nters) (Le Cun, 1989). The generalization performance as a function of the training \\nset size for traditional backprop and tangent prop are compared in Fig. 5. We have \\nconducted additional experiments in which we implemented not only translations \\nbut also rotations, expansions and hyperbolic deformations. This set of 6 gener(cid:173)\\nators is a basis for all linear transformations of coordinates for two dimensional \\nimages. It is straightforward to implement other generators including gray-Ievel(cid:173)\\nshifting, \\\"smooth\\\" segmentation, local continuous coordinate transformations and \\nindependent image segment transformations. \\n\\nThe next experiment is designed to show that in applications where data is highly \\n\\n\\f902 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\nAv\\\"ge NMSE VI 1ge \\n\\nA-. NMSE VI. \\n\\n0.15 \\n\\n0.1 \\n\\n.15 \\n\\n.1 \\n\\no \\no 1000 2000 3000 4000 5000 6000 7000 8000 0000 10000 \\n\\noL-~~==~~=;~==+=~~~ \\n1000 2000 3000 4000 5000 6000 7000 8000 0000 10000 \\n0 \\n\\n-\\n\\n\\\" \\n\\n..... \\n\\n15 \\n\\no \\n\\n-0.5 \\n\\n-1 \\n\\n..... \\n\\n15 -\\n\\n\\\" \\n\\n0 \\n\\n-.5 \\n\\n-1 \\n\\n-1 .5 +--_+_-_--+_-_+_-_-_ \\n\\n-1.5 +--_+_-_--+--_+_-_-__t \\n\\n-1 .5 \\n\\n-1 \\n\\n1.5 \\n\\n-1.5 \\n\\n-1 \\n\\n0 \\n\\n0.5 \\n\\n-0.5 \\nDistortion model \\n\\no \\n\\n.5 \\n\\n- .5 \\nTangent prop \\n\\n1.5 \\n\\nFigure 6: Comparison of the distortion model (left column) and tangent prop (right \\ncolumn). The top row gives the learning curves (error versus number of sweeps \\nthrough the training set). The bottom row gives the final input-output function of \\nthe network; the dashed line is the result for unadorned back prop. \\n\\n\\fTangent Prop-A formalism for specifying selected invariances in an adaptive network \\n\\n903 \\n\\ncorrelated, tangent prop yields a large speed advantage. Since the distortion model \\nimplies adding lots of highly correlated data, the advantage of tangent prop over \\nthe distortion model becomes clear. \\nThe task is to approximate a function that has plateaus at three locations. We want \\nto enforce local invariance near each of the training points (Fig. 6, bottom). The \\nnetwork has one input unit, 20 hidden units and one output unit. Two strategies are \\npossible: either generate a small set of training point covering each of the plateaus \\n(open squares on Fig. 6 bottom), or generate one training point for each plateau \\n(closed squares), and enforce local invariance around them (by setting the desired \\nderivative to 0). The training set of the former method is used as a measure the \\nperformance for both methods. All parameters were adjusted for approximately \\noptimal performance in all cases. The learning curves for both models are shown in \\nFig. 6 (top). Each sweep through the training set for tangent prop is a little faster \\nsince it requires only 6 forward propagations, while it requires 9 in the distortion \\nmodel. As can be seen, stable performance is achieved after 1300 sweeps for the \\ntangent prop, versus 8000 for the distortion model. The overall speedup is therefore \\nabout 10. \\nTangent prop in this example can take advantage of a very large regularization term. \\nThe distortion model is at a disadvantage because the only parameter that effec(cid:173)\\ntively controls the amount of regularization is the magnitude of the distortions, and \\nthis cannot be increased to large values because the right answer is only invariant \\nunder small distortions. \\n\\n4 CONCLUSIONS \\n\\nWhen a priori information about invariances exists, this information must be made \\navailable to the adaptive system. There are several ways of doing this, including the \\ndistortion model and tangent prop. The latter may be much more efficient in some \\napplications, and it permits separate control of the emphasis and learning rate for \\nthe invariances, relative to the original training data points. Training a system to \\nhave zero derivatives in some directions is a powerful tool to express invariances to \\ntransformations of our choosing. Tests of this procedure on large-scale applications \\n(handwritten zipcode recognition) are in progress. \\n\\nReferences \\n\\nBaird, H. S. (1990). Document Image Defect Models. In IAPR 1990 Workshop on \\n\\nSytactic and Structural Pattern Recognition, pages 38-46, Murray Hill, NJ. \\n\\nGilmore, R. (1974). Lie Groups, Lie Algebras and some of their Applications. Wiley, \\n\\nNew York. \\n\\nLe Cun, Y. (1989) . Generalization and Network Design Strategies. In Pfeifer, R., \\nSchreter, Z., Fogelman, F., and Steels, L., editors, Connectionism in Perspec(cid:173)\\ntive, Zurich, Switzerland. Elsevier. an extended version was published as a \\ntechnical report of the University of Toronto. \\n\\n\\f\",\n          \"Minimizing  Statistical Bias with Queries \\n\\nDavid A.  Cohn \\n\\nAdaptive Systems Group \\n\\nHarlequin,  Inc. \\n\\nOne  Cambridge Center \\nCambridge,  MA  02142 \\ncOhnCharlequin.com \\n\\nAbstract \\n\\nI describe  a  querying criterion that attempts to minimize the error \\nof a  learner  by  minimizing its estimated squared  bias.  I  describe \\nexperiments  with  locally-weighted  regression  on  two  simple prob(cid:173)\\nlems,  and observe  that this  \\\"bias-only\\\"  approach  outperforms the \\nmore  common  \\\"variance-only\\\"  exploration  approach,  even  in  the \\npresence  of noise. \\n\\n1 \\n\\nINTRODUCTION \\n\\nIn recent  years, there has been an explosion of interest in \\\"active\\\"  machine learning \\nsystems.  These  are  learning  systems  that  make  queries,  or  perform  experiments \\nto  gather data that  are expected  to maximize performance.  When  compared with \\n\\\"passive\\\"  learning  systems,  which  accept  given,  or  randomly  drawn  data,  active \\nlearners have demonstrated significant decreases  in the amount of data required  to \\nachieve equivalent performance.  In industrial applications,  where  each  experiment \\nmay take  days  to  perform  and  cost  thousands  of dollars,  a  method  for  optimally \\nselecting  these  points would offer enormous savings in time and  money. \\nAn  active  learning system  will  typically attempt to select  data that  will  minimize \\nits  predictive  error.  This  error  can  be  decomposed  into  bias  and  variance  terms. \\nMost  research  in selecting  optimal actions or  queries  has  assumed  that the learner \\nis  approximately unbiased,  and that to minimize learner error,  variance is  the only \\nthing  to  minimize  (e.g.  Fedorov  [1972]'  MacKay  [1992]'  Cohn  [1996],  Cohn  et  al., \\n[1996],  Paass  [1995]).  In  practice,  however,  there  are very  few  problems for  which \\nwe have unbiased learners.  Frequently, bias constitutes a large portion of a learner's \\nerror;  if the learner is deterministic and the data are noise-free, then bias is the  only \\nsource  of error.  Note  that the bias  term here  is  a  statistical bias,  distinct from  the \\ninductive  bias  discussed  in some  machine  learning  research  [Dietterich  and  Kong, \\n1995]. \\n\\n\\f418 \\n\\nD.A. Cohn \\n\\nIn this paper I describe an algorithm which selects actions/ queries designed to mini(cid:173)\\nmize the bias of a locally weighted regression-based  learner.  Empirically, \\\"variance(cid:173)\\nminimizing\\\" strategies which ignore bias seem to perform well, even in cases  where, \\nstrictly speaking,  there is  no  variance  to  minimize.  In  the  tasks  considered  in  this \\npaper,  the  bias-minimizing strategy  consistently  outperforms  variance  minimiza(cid:173)\\ntion, even in  the presence  of noise. \\n\\n1.1  BIAS  AND  VARIANCE \\n\\nLet us  begin  by defining P(x, y)  to be the unknown joint distribution over  x and y, \\nand  P( x)  to  be  the  known  marginal distribution  of x  (commonly called  the  input \\ndistribution).  We  denote  the  learner's  output  on input  x,  given  training set  D  as \\ny(x; D).  We  can  then  write the expected  error of the learner as \\n\\n1 E  [(y(x;D) - y(x))2Ix] P(x)dx, \\n\\n(1) \\n\\nwhere E[\\u00b7] denotes the expectation over P and over training sets D.  The expectation \\ninside the integral may be  decomposed as follows  (Geman et al. , 1992): \\n\\nE  [(y(x;D) - y(x))2Ix] \\n\\nE  [(y(x) - E[ylx]?] \\n\\n(2) \\n\\n+ (Ev [y(x; D)] - E[ylx])2 \\n\\n+Ev [(y(x;D) - Ev[y(x;D)])2] \\n\\nwhere Ev [.] denotes the expectation over training sets.  The first  term in Equation 2 \\nis the variance of y given x - it is the noise in the distribution, and does  not depend \\non our learner or how the training data are chosen.  The second term is the learner's \\nsquared bias, and the third is its variance; these last two terms comprise the expected \\nsquared error of the learner  with  respect  to the regression  function  E[Ylx]. \\nMost  research  in  active  learning  assumes  that  the  second  term  of Equation  2  is \\napproximately zero,  that  is,  that  the  learner  is  unbiased.  If this  is  the  case,  then \\none may concentrate on selecting data so  as to minimize the variance of the learner. \\nAlthough this  \\\"all-variance\\\" approach is optimal when the learner is  unbiased, truly \\nunbiased  learners  are  rare.  Even  when  the  learner's  representation  class  is  able \\nto  match  the  target  function  exactly,  bias is  generally  introduced  by  the  learning \\nalgorithm  and  learning  parameters.  From  the  Bayesian  perspective,  a  learner  is \\nonly unbiased  if its  priors are  exactly  correct. \\nThe optimal choice  of query would,  of course, minimize  both  bias and variance,  but \\nI leave that for future work.  For the purposes of this paper, I will only be concerned \\nwith  selecting  queries  that  are  expected  to  minimize  learner  bias.  This  approach \\nis  justified  in  cases  where  noise  is  believed  to  be  only  a  small  component  of the \\nlearner's  error.  If the  learner  is  deterministic  and  there  is  no  noise,  then  strictly \\nspeaking, there  is  no error  due  to  variance -\\nall  the error  must be  due  to learner \\nbias.  In cases with non-determinism or noise, all-bias minimization, like all-variance \\nminimization, becomes  an approximation of the optimal approach. \\n\\nThe learning model discussed  in this paper is  a  form of locally  weighted  regression \\n(LWR)  [Cleveland et  al.,  1988],  which  has  been  used  in  difficult  machine  learning \\ntasks,  notably  the  \\\"robot  juggler\\\"  of Schaal  and  Atkeson  [1994].  Previous  work \\n[Cohn et al.,  1996]  discussed  all-variance query selection for  LWR; in the remainder \\nof this paper, I describe  a method for  performing all-bias query selection.  Section 2 \\ndescribes the criterion that must be optimized for all-bias query selection.  Section 3 \\ndescribes  the  locally  weighted  regression  learner  used  in  this  paper  and  describes \\n\\n\\fMinimizing Statistical Bias with Queries \\n\\n419 \\n\\nhow  the  all-bias criterion  may be  computed for  it .  Section  4  describes  the  results \\nof experiments using this criterion on several simple domains.  Directions for future \\nwork  are discussed  in  Section 5. \\n\\n2  ALL-BIAS  QUERY  SELECTION \\n\\nLet  us  assume for  the moment that we  have  a source of noise-free examples (Xi, Yi) \\nand  a  deterministic learner  which,  given  input  X,  outputs estimate Y(X).l  Let  us \\nalso  assume  that  we  have  an  accurate estimate of the  bias  of y which  can  be  used \\nto estimate  the  true  function  y(x)  =  y(x)  - bias(x).  We  will  break  these  rather \\nstrong assumptions of noise-free examples and accurate bias estimates in Section 4, \\nbut they  are useful for  deriving  the theoretical  approach described  below. \\n\\nGiven  an  accurate  bias estimate,  we  must force  the  biased  estimator into the  best \\napproximation of y(x)  with  the fewest  number of examples.  This,  in effect,  trans(cid:173)\\nforms  the  query  selection  problem  into  an  example filter  problem  similar  to  that \\nstudied  by  Plutowski  and  White  [1993]  for  neural  networks.  Below,  I  derive  this \\ncriterion for  estimating the change  in error at  X  given  a  new  queried  example at x. \\nSince  we  have  (temporarily)  assumed  a  deterministic  learner  and  noise-free  data, \\nthe expected  error in  Equation 2 simplifies to: \\n\\nE  [(Y( X; 'D)  - y( x))2Ix, 'D] \\n\\n(Y(x; 'D)  - y(x))2 \\n\\n(3) \\n\\nWe  want to select  a new  x such that when we  add (x, f)),  the resulting squared bias \\nis  minimized: \\n\\n(Y'  - y? ==  (y(x; 'D U (x, f)))  - y(x))2 . \\n\\n(4) \\nI will, for the remainder of the paper, use the  \\\"'\\\"  to indicate estimates based on the \\ninitial training set  plus  the  additional example  (x, y).  To  minimize  Expression  4, \\nwe  need  to  compute  how  a  query  at  x will  change  the  learner's  bias  at  x.  If we \\nassume  that  we  know  the  input  distribution,2  then  we  can  integrate  this  change \\nover  the  entire  domain  (using  Monte  Carlo  procedures)  to  estimate  the  resulting \\naverage  change,  and select  a  x such  that  the  expected  squared  bias  is  minimized. \\nDefining bias ==  y - y and f:,.y  ==  y'  - y, we  can  write the new  squared  bias as: \\n\\nbias,2 \\n\\n(y'  - y)2  =  (Y + f:,.y  _ y)2 \\nf:,.y2  + 2f:,.y . bias + bias2 \\n\\n(5) \\nNote  that  since  bias  as  defined  here  is  independent  of x,  minimizing  the  bias  is \\nequivalent to minimizing f:,.y2  + 2f:,.y . bias. \\nThe estimate of bias'  tells  us  how much our bias will change for  a given x. We may \\noptimize this value over x in one of a number of ways.  In low dimensional spaces,  it \\nis often sufficient to consider a set of \\\"candidate\\\" x and select the one promising the \\nsmallest resulting  error.  In  higher  dimensional spaces,  it  is  often  more efficient  to \\nsearch  for  an optimal x with  a  response  surface  technique  [Box  and  Draper, 1987], \\nor hill climb on  abias,2 / ax. \\nEstimates  of bias  and  f:,.y  depend  on  the  specific  learning  model  being  used.  In \\nSection 3, I describe a locally weighted regression model, and show how differentiable \\nestimates of bias  and f:,.y  may be  computed for  it. \\n\\n1 For  clarity,  I  will  drop  the  argument  :z;  except  where  required  for  disambiguation.  I \\n\\nwill  also  denote only  the univariate  case;  the results  apply  in  higher  dimensions  as  well. \\n2This assumption is  contrary to the assumption norma.lly  made in some forms of learn(cid:173)\\n\\ning,  e.g.  PAC-learning,  but it is  appropriate in  many  domains. \\n\\n\\f420 \\n\\nD.  A.  Cohn \\n\\n2.1  AN  ASIDE:  WHY  NOT JUST USE Y - Mas? \\n\\nIf we  have  an accurate  bias estimate, it is  reasonable to ask  why  we  do  not simply \\nuse  the  corrected  y - C;;;S  as  our  predictor.  The  answer  has  two  parts,  the  first \\nof  which  is  that  for  most  learners,  there  are  no  perfect  bias  estimators  -\\nthey \\nintroduce their own  bias and  variance,  which  must  be  addressed  in data selection. \\nSecond,  we  can  define  a  composite learner Ye  ==  Y - C:;;;S.  Given  a random training \\nsample  then,  we  would  expect  Ye  to  outperform  y.  However,  there  is  no  obvious \\nway  to select  data for  this composite learner other than selecting  to maximize the \\nperformance  of its  two  components.  In  our  case,  the  second  component  (the  bias \\nestimate)  is  non-analytic,  which  leaves  us  selecting  data  so  as  to  maximize  the \\nperformance of the  first  component  (the uncorrected  estimator).  We  are  now  back \\nto  our  original  problem:  we  can  select  data so  as  to  minimize either  the  bias  or \\nvariance of the uncorrected  LWR-based learner.  Since the purpose of the correction \\nis to give an unbiased estimator, intuition suggests that variance minimization would \\nbe the more sensible route in this  case.  Empirically, this approach does  not appear \\nto yield  any  benefit  over  uncorrected  variance minimization (see  Figure  1). \\n\\n3  LOCALLY WEIGHTED REGRESSION \\n\\nThe type  of learner  I  consider here  is  a form  of locally weighted  regression  (LWR) \\nthat is  a slight variation on  the  LOESS  model of Cleveland et  al.  [1988]  (see  Cohn \\net al., [1996]  for details).  The LOESS  model performs a linear regression  on points \\nin  the  data set,  weighted  by  a  kernel  centered  at  x.  The kernel  shape  is  a  design \\nparameter:  the original LOESS  model uses  a  \\\"tricubic\\\"  kernel;  in my experiments \\nI  use  the more common Gaussian \\n\\nwhere Ie  is a smoothing parameter.  For brevity, I will drop the argument x for  hi(x), \\nand define  n  = 2:i  hi.  We  can then  write  the weighted  means and  covariances  as: \\n\\n\\\"\\\"  Xi \\n, \\nn \\n. \\n\\nJ.l:r;  = L..J hi - ,  \\nJ.ly  = L h,-, \\n\\nYi \\nn \\n\\n, \\n. \\n\\n\\\"\\\" \\n\\nU:r;y  =  L..J hi \\n\\n, \\n. \\n\\n(Xi  - X)(Yi  - J.ly) \\n\\nn \\n\\n. \\n\\nWe use these means and covariances to produce an estimate Y at the x  around which \\nthe kernel  is  centered,  with  a  confidence  term in  the form of a  variance estimate: \\n\\nIn  all the experiments  discussed  in  this paper,  the smoothing parameter Ie  was  set \\nso  as  to minimize u2. \\nThe  low  cost  of incorporating  new  training  examples  makes  this  form  of locally \\nweighted regression  appealing for  learning systems which must operate in real time, \\nor with time-varying target functions  (e.g.  [Schaal and Atkeson  1994]). \\n\\n\\fMinimizing Statistical Bias with Queries \\n\\n421 \\n\\nI \\n\\nI \\nY \\n\\n) \\n\\nA \\n\\nA \\n\\nA  I \\n\\nA \\n\\n3.1  COMPUTING D..y  FOR LWR \\nIf we  know  what  new  point  (x, y)  we're  going  to  add,  computing D..y  for  LWR  is \\nstraightforward.  Defining h as  the  weight  given to x,  and n as  n + h we  can write \\n~y  =  y  - y  =  J.L  + -\\n\\nx  - J.Lx \\n\\nh (Y  ___ J.Ly)  _  uxy (x _  J.Lx)  + (x _  n~x _  ~x) . nuXY_ + h . ~x -:xKii - J.Ly) \\n\\nU xy ( \\nU/2 \\nx \\n\\nU xy ( \\n-\\nu2 \\nx \\n\\nn \\n\\nnu;+h\\u00b7(x-J.Lx)2 \\nNote  that computing D..y  requires  us  to know both the x and y of the new  point .  In \\npractice,  we only know x.  If we  assume, however,  that we  can estimate the learner's \\nbias  at  any  x,  then  we  can  also estimate  the  unknown  value  y ~ y(x)  - bias(x) . \\nBelow,  I  consider  how  to compute the bias  estimate. \\n\\nn \\n\\nn \\n\\nI  ) \\nx - J.L \\nx \\n\\n- J.L \\ny \\n\\n-\\n\\nu; \\n\\n3.2  ESTIMATING  BIAS  FOR LWR \\n\\nThe most common technique for estimating bias is  cross-validation .  Standard cross(cid:173)\\nvalidation however, only gives estimates of the  bias  at our specific  training points , \\nwhich  are  usually combined  to form  an  average  bias estimate.  This is  sufficient  if \\none  assumes  that the  training distribution is  representative  of the  test  distribution \\n(which  it  isn't  in  query  learning)  and  if one  is  content  to just  estimate  the  bias \\nwhere  one  already has  training data (which  we  can't be). \\nIn the query selection  problem, we  must be  able to estimate the bias  at all possible \\nx.  Box  and  Draper  [1987]  suggest  fitting  a  higher  order  model and measuring the \\ndifference.  For  the  experiments  described  in  this  paper,  this  method yielded  poor \\nresults; two other bias-estimation techniques,  however, performed very  well. \\n\\nOne  method  of estimating  bias  is  by  bootstrapping  the  residuals  of  the  training \\npoints.  One produces a  \\\"bootstrap sample\\\" of the learner's residuals on the training \\ndata, and adds them to the original predictions to create a synthetic training set .  By \\naveraging  predictions  over  a  number of bootstrapped  training sets  and  comparing \\nthe average prediction with that of the original predictor, one arrives at a first-order \\nbootstrap estimate of the predictor's bias [Connor 1993; Efron and Tibshirani, 1993] . \\nIt is  known  that this  estimate is  itself biased  towards  zero;  a  standard heuristic  is \\nto divide the estimate by  0.632  [Efron,  1983]. \\nAnother method of estimating bias of a learner is  by fitting  its own cross-validated \\nresiduals.  We  first  compute the cross-validated residuals  on  the training examples. \\nThese  produce  estimates  of the  learner's  bias  at  each  of the  training  points.  We \\ncan then  use  these  residuals  as  training examples for  another  learner  (again  LWR) \\nto produce estimates of what the cross-validated error would be  in places  where  we \\ndon't have  training data. \\n\\n4  EMPIRICAL  RESULTS \\n\\nIn  the  previous  two  sections,  I  have  explained  how  having  an  estimate of D..y  and \\nbias  for  a  learner  allows  one  to  compute  the  learner's  change  in  bias  given  a  new \\nquery,  and  have  shown  how  these  estimates  may be  computed  for  a  learner  that \\nuses  locally weighted regression.  Here,  I apply these  results to two simple problems \\nand  demonstrate  that  they  may  actually  be  used  to  select  queries  that  minimize \\nthe statistical bias (and the error)  of the learner.  The problems involve learning the \\nkinematics  of a  planar  two-jointed  robot  arm:  given  the  shoulder  and elbow joint \\nangles, the learner must predict  the  tip position. \\n\\n\\f422 \\n\\n4.1  BIAS  ESTIMATES \\n\\nD.A. Cohn \\n\\nI tested the accuracy of the two bias estimators by observing their correlations on 64 \\nreference  inputs, given 100 random training examples from the planar arm problem. \\nThe  bias estimates had  a  correlation  with  actual biases  of 0.852  for  the bootstrap \\nmethod, and 0.871  for  the  cross-validation method. \\n\\n4.2  BIAS  MINIMIZATION \\n\\nI ran two sets of experiments using the bias-minimizing criterion in conjunction with \\nthe  bias  estimation technique  of the  previous  section  on  the  planar arm  problem. \\nThe bias minimization criterion was  used  as follows:  At each time step, the learner \\nwas  given  a  set  of 64  randomly chosen  candidate  queries  and  64  uniformly chosen \\nreference  points.  It evaluated  E' (x)  for  each  reference  point  given  each  candidate \\npoint and selected  for  its next  query  the candidate point with the smallest average \\nE' (x) over the reference  points.  I compared the bias-minimizing strategy (using the \\ncross-validation and bootstrap estimation techniques)  against random sampling and \\nthe  variance-minimizing strategy  discussed  in  Cohn  et  al.  [1996].  On  a  Sparc  10, \\nwith m training examples, the  average evaluation times per candidate per reference \\npoint were  58 + 0.16m J.lseconds  for  the variance criterion, 65 + 0.53m J.lseconds  for \\nthe cross-validation-based bias criterion, and 83 + 3. 7m J.lseconds  for  the bootstrap(cid:173)\\nbased  bias criterion  (with  20x resampling) . \\nTo test  whether the  bias-only assumption was robust  against the presence  of noise, \\n1 % Gaussian  noise  was  added  to  the  input  values  of the  training  data  in  all  ex(cid:173)\\nperiments.  This simulates noisy  position effectors  on  the arm , and  results  in  non(cid:173)\\nGaussian noise  in  the output coordinate  system. \\n\\nIn  the  first  series  of experiments,  the  candidate  shoulder  and  elbow  joint  angles \\nwere  drawn  uniformly over  (U[O, 271\\\"],  U[O,  71\\\")) .  In  unconstrained  domains like  this, \\nrandom sampling is  a fairly good default  strategy.  The bias minimization strategies \\nstill  significantly  outperform  both  random  sampling  and  the  variance  minimizing \\nstrategy in these  experiments (see  Figure  1). \\n\\n-1 \\n\\n10 \\n\\ng \\n'\\\" 'il ,0-2 \\n:a \\n~ \\nc: \\n~10  .  random \\n\\n-3 \\n\\n' '\\\\ \\n\\n\\\".'~ \\n\\nvariance-min \\n-\\no  cross-val-min \\n~ x  bootstrap-min \\n200 \\n\\n100 \\n\\n10  0 \\n\\n300 \\n\\ntrainlno set size \\n\\nI, \\n\\\\\\\\ \\n--\\n\\n1 \\n10 \\n\\ng  0 \\n\\n\\\"'10 \\n\\n}1O-1 \\n~  -2 \\n\\n,- -\\n\\n.:  ~~&e-.!)jni(llIZI~  , \\no \\n\\n10 \\n10-3  ~  ~~~~rmiWngar- iOlmizing \\n400 \\n\\n300 \\n\\n200 \\n\\n1 00 \\n\\ntrainino set size \\n\\nIheta 1 \\n\\n(left)  MSE  as  a  function  of number of noisy  training examples for  the \\nFigure  1: \\nunconstrained  arm  problem.  Errors  are  averaged  over  10  runs  for  the  bootstrap \\nmethod and 15  runs for  all others.  One run with the cross-validation-based method \\nwas  excluded  when  k  failed  to  converge  to  a  reasonable  value.  (center)  MSE  as \\na  function  of number of noisy  training examples for  the  constrained  arm problem . \\nThe bias correction strategy discussed in Section 2.1  does no better than the uncor(cid:173)\\nrected  variance-minimizing strategy,  and  much  worse  than  the  bias-minimization \\nstrategy.  (right)  Sample  exploration  trajectory  in  joint-space  for  the  constrained \\narm problem , explored  according  to the bias minimizing criterion. \\n\\nIn the second series of experiments, candidates were  drawn uniformly from a region \\n\\n\\fMinimizing Statistical Bias with Queries \\n\\n423 \\n\\nlocal to  the previously  selected  query:  (01  \\u00b1 0.217\\\", O2  \\u00b1 0.117\\\").  This corresponds  to \\nrestricting  the  arm  to local  motions.  In  a  constrained  problem such  as  this,  ran(cid:173)\\ndom  sampling  is  a  poor  strategy;  both  the  bias  and  variance-reducing  strategies \\noutperform it at least  an order of magnitude.  Further, the  bias-minimization strat(cid:173)\\negy  outperforms variance minimization by a large  margin (Figure 1).  Figure  1 also \\nshows  an  exploration  trajectory  produced  by  pursuing  the  bias-minimizing crite(cid:173)\\nrion.  It is  noteworthy that, although the implementation in this case  was a  greedy \\n(one-step)  minimization, the trajectory results  in globally good exploration. \\n\\n5  DISCUSSION \\n\\nI  have argued  in  this paper  that, in many situations, selecting  queries  to minimize \\nlearner bias is an appropriate and effective strategy for  active learning.  I have given \\nempirical  evidence  that,  with  a  LWR-based  learner  and  the  examples  considered \\nhere,  the strategy is effective  even  in the presence  of noise. \\n\\nBeyond  minimizing either  bias  or  variance,  an  important next  step  is  to explicitly \\nminimize  them  together .  The  bootstrap-based  estimate should  facilitate  this,  as \\nit produces  a  complementary variance estimate with little additional computation. \\nBy optimizing over both criteria simultaneously, we expect to derive a criterion that \\nthat, in  terms of statistics,  is  truly optimal for  selecting  queries. \\n\\nREFERENCES \\nBox,  G.,  &  Draper, N.  (1987).  Empirical model-building  and  response  surfaces, \\nWiley,  New  York. \\nCleveland,  W.,  Devlin,  S.,  &  Grosse,  E.  (1988) .  Regression  by  local fitting. \\nJournal  of Econometrics,  37, 87-114. \\nCohn,  D.  (1996)  Neural  network  exploration  using  optimal  experiment  design. \\nNeural Networks,  9(6):1071-1083. \\nCohn,  D.,  Ghahramani,  Z.,  &  Jordan,  M.  (1996) .  Active  learning  with sta(cid:173)\\ntistical models.  Journal  of Artificial Inteligence  Research 4:129-145 . \\nConnor, J. (1993).  Bootstrap Methods in Neural Network Time Series  Prediction. \\nIn  J .  Alspector  et  al.,  eds.,  Proc.  of the  Int.  Workshop  on  Applications  of Neural \\nNetworks  to  Telecommunications,  Lawrence  Erlbaum, Hillsdale,  N.J. \\nDietterich,  T.,  &  Kong,  E.  (1995) .  Error-correcting  output  coding  corrects \\nbias  and  variance.  In  S.  Prieditis  and  S.  Russell,  eds.,  Proceedings  of the  12th \\nInternational  Conference  on  Machine  Learning. \\nEfron, B. (1983) Estimating the error rate of a prediction rule:  some improvements \\non cross-validation.  J.  Amer.  Statist.  Assoc.  78:316-331. \\nEfron, B.  &  Tibshirani, R.  (1993).  An introduction  to  the  bootstrap.  Chapman \\n&  Hall,  New  York . \\nFedorov, V.  (1972).  Theory  of Optimal Experiments.  Academic Press,  New  York. \\nGeman, S.,  Bienenstock, E.,  &  Doursat, R.  (1992).  Neural  networks and the \\nbias/variance dilemma.  Neural  Computation,  4,  1-58. \\nMacKay,  D.  (1992).  Information-based objective functions  for  active  data selec(cid:173)\\ntion,  Neural  Computation,  4,  590-604. \\nPaass,  G.,  and Kindermann, J. (1994).  Bayesian  Query Construction for  Neu(cid:173)\\nral  Network  Models.  In  G.  Tesauro  et  al.,  eds.,  Advances  in  Neural  Information \\nProcessing Systems  7,  MIT Press. \\nPlutowski, M.,  &  White,  H.  (1993).  Selecting concise  training sets from  clean \\ndata.  IEEE  Transactions  on  Neural  Networks,  4, 305-318. \\nSchaal,  S.  &  Atkeson,  C.  (1994).  Robot  Juggling:  An  Implementation  of \\nMemory-based Learning.  Control Systems 14, 57-71. \\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["data.dropna(subset=['full_text'], inplace=True)"],"metadata":{"id":"OWTlgMNXiugy","executionInfo":{"status":"ok","timestamp":1747637935638,"user_tz":-540,"elapsed":40,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# 위에서 정의한 함수로 data를 정제해줍니다\n","data['full_text'] = data['full_text'].apply(clean_text)"],"metadata":{"id":"aOQmQ1oBivtb","executionInfo":{"status":"ok","timestamp":1747638003264,"user_tz":-540,"elapsed":67619,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# 정제된 데이터를 확인해봅시다\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ecNq-Z7Tiw2g","outputId":"2eee278f-3daf-463b-b687-db2c29c3c4fc","executionInfo":{"status":"ok","timestamp":1747638006140,"user_tz":-540,"elapsed":2924,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   source_id  year                                              title  \\\n","0         27  1987                         Bit-Serial Neural Networks   \n","1         63  1987                        Connectivity Versus Entropy   \n","2         60  1987        The Hopfield Model with Multi-Level Neurons   \n","3         59  1987                               How Neural Nets Work   \n","4         69  1987  Spatial Organization of Neural Networks: A Pro...   \n","\n","  abstract                                          full_text  \n","0      NaN  573 bit serial neural networks alan f murray a...  \n","1      NaN  1 connectivity versus entropy yaser s abumosta...  \n","2      NaN  278 the hopfield model with mul tilevel neuron...  \n","3      NaN  442 alan lapedes robert farber theoretical div...  \n","4      NaN  740 spatial organization of neural nenorks a p...  "],"text/html":["\n","  <div id=\"df-e4645f41-513c-4230-b8c2-a730f9956768\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_id</th>\n","      <th>year</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>full_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>27</td>\n","      <td>1987</td>\n","      <td>Bit-Serial Neural Networks</td>\n","      <td>NaN</td>\n","      <td>573 bit serial neural networks alan f murray a...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>63</td>\n","      <td>1987</td>\n","      <td>Connectivity Versus Entropy</td>\n","      <td>NaN</td>\n","      <td>1 connectivity versus entropy yaser s abumosta...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>60</td>\n","      <td>1987</td>\n","      <td>The Hopfield Model with Multi-Level Neurons</td>\n","      <td>NaN</td>\n","      <td>278 the hopfield model with mul tilevel neuron...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>59</td>\n","      <td>1987</td>\n","      <td>How Neural Nets Work</td>\n","      <td>NaN</td>\n","      <td>442 alan lapedes robert farber theoretical div...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>69</td>\n","      <td>1987</td>\n","      <td>Spatial Organization of Neural Networks: A Pro...</td>\n","      <td>NaN</td>\n","      <td>740 spatial organization of neural nenorks a p...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4645f41-513c-4230-b8c2-a730f9956768')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e4645f41-513c-4230-b8c2-a730f9956768 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e4645f41-513c-4230-b8c2-a730f9956768');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-15dc87a5-8fa3-4dd6-b565-3158c43e7d65\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15dc87a5-8fa3-4dd6-b565-3158c43e7d65')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-15dc87a5-8fa3-4dd6-b565-3158c43e7d65 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 9677,\n  \"fields\": [\n    {\n      \"column\": \"source_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1825,\n        \"min\": 1,\n        \"max\": 9406,\n        \"num_unique_values\": 4521,\n        \"samples\": [\n          2504,\n          836,\n          2332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1987,\n        \"max\": 2019,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          2018,\n          2002,\n          2013\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9677,\n        \"samples\": [\n          \"Unsupervised Object Segmentation by Redrawing\",\n          \"Spectral Hashing\",\n          \"Deep, complex, invertible  networks for inversion of transmission effects in multimode optical fibres\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6360,\n        \"samples\": [\n          \"Zero-shot learning (ZSL) aims to recognize unseen object classes without any training samples, which can be regarded as a form of transfer learning from seen classes to unseen ones. This is made possible by learning a projection between a feature space and a semantic space (e.g. attribute space). Key to ZSL is thus to learn a projection function that is robust against the often large domain gap between the seen and unseen classes. In this paper, we propose a novel ZSL model termed domain-invariant projection learning (DIPL). Our model has two novel components: (1) A domain-invariant feature self-reconstruction task is introduced to the seen/unseen class data, resulting in a simple linear formulation that casts ZSL into a min-min optimization problem. Solving the problem is non-trivial, and a novel iterative algorithm is formulated as the solver, with rigorous theoretic algorithm analysis provided. (2) To further align the two domains via the learned projection, shared semantic structure among seen and unseen classes is explored via forming superclasses in the semantic space. Extensive experiments show that our model outperforms the state-of-the-art alternatives by significant margins.\",\n          \"In this work, we present new theoretical results on convolutional generative neural networks, in particular their invertibility (i.e., the recovery of input latent code given the network output). The study of network inversion problem is motivated by image inpainting and the mode collapse problem in training GAN. Network inversion is highly non-convex, and thus is typically computationally intractable and without optimality guarantees. However, we rigorously prove that, under some mild technical assumptions, the input of a two-layer convolutional generative network can be deduced from the network output efficiently using simple gradient descent. This new theoretical finding implies that the mapping from the low- dimensional latent space to the high-dimensional image space is bijective (i.e., one-to-one). In addition, the same conclusion holds even when the network output is only partially observed (i.e., with missing pixels). Our theorems hold for 2-layer convolutional generative network with ReLU as the activation function, but we demonstrate empirically that the same conclusion extends to multi-layer networks and networks with other activation functions, including the leaky ReLU, sigmoid and tanh.\",\n          \"Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems. However, only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account. In this paper, we show that it is possible to design efficient inference algorithms for a conditional random field using features that depend on long consecutive label sequences (high-order features), as long as the number of distinct label sequences in the features used is small. This leads to efficient learning algorithms for these conditional random fields. We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9670,\n        \"samples\": [\n          \"statistical analysis of coupled time series with kernel crossspectral density operators mpi for intelligent systems and mpi for biological cybernetics t\\u00a8ubingen germany michelbesservetuebingenmpgde michel besserve nikos k logothetis mpi for biological cybernetics t\\u00a8ubingen nikoslogothetistuebingenmpgde bernhard sch\\u00a8olkopf mpi for intelligent systems t\\u00a8ubingen bstuebingenmpgde abstract many applications require the analysis of complex interactions between time se ries these interactions can be nonlinear and involve vector valued as well as complex data structures such as graphs or strings here we provide a general framework for the statistical analysis of these dependencies when random vari ables are sampled from stationary timeseries of arbitrary objects to achieve this goal we study the properties of the kernel crossspectral density kcsd oper ator induced by positive de\\ufb01nite kernels on arbitrary input domains this frame work enables us to develop an independence test between time series as well as a similarity measure to compare different types of coupling the performance of our test is compared to the hsic test using iid assumptions showing improvements in terms of detection errors as well as the suitability of this approach for testing dependency in complex dynamical systems this similarity measure enables us to identify different types of interactions in electrophysiological neural time series 1 introduction complex dynamical systems can often be observed by monitoring time series of one or more vari ables finding and characterizing dependencies between several of these time series is key to un derstand the underlying mechanisms of these systems this problem can be addressed easily in linear systems 4 however nonlinear systems are much more challenging whereas higher order statistics can provide helpful tools in speci\\ufb01c contexts 15 and have been extensively used in sys tem identi\\ufb01cation causal inference and blind source separation see for example 10 13 5 it is dif\\ufb01cult to derive a general approach with solid theoretical results accounting for a broad range of interactions especially studying the relationships between time series of arbitrary objects such as texts or graphs within a general framework is largely unaddressed on the other hand the dependency between independent identically distributed iid samples of arbitrary objects can be studied elegantly in the framework of positive de\\ufb01nite kernels 19 it relies on de\\ufb01ning crosscovariance operators between variables mapped implicitly to reproducing kernel hilbert spaces rkhs 7 it has been shown that when using a characteristic kernel for the mapping 9 the properties of rkhs operators are related to statistical independence between input variables and allow testing for it in a principled way with the hilbertschmidt independence criterion hsic test 11 however the suitability of this test relies heavily on the assumption that iid samples of random variables are used this assumption is obviously violated in any non trivial setting involving time series and as a consequence trying to use hsic in this context can lead to incorrect conclusions zhang et al established a framework in the context of markov chains 1 22 showing that a structured hsic test still provides good asymptotic properties for absolutely regular processes however this methodology has not been assessed extensively in empirical time series moreover beyond the detection of interactions it is important to be able to characterize the nature of the coupling between time series it was recently suggested that generalizing the concept of crossspectral density to reproducible kernel hilbert spaces rkhs could help formulate non linear dependency measures for time series 2 however no statistical assessment of this measure has been established in this paper after recalling the concept of kernel spectral density operator we characterize its statistical properties in particular we de\\ufb01ne independence tests based on this concept as well as a similarity measure to compare different types of couplings we use these tests in section 4 to compute the statistical dependencies between simulated time series of various types of objects as well as recordings of neural activity in the visual cortex of nonhuman primates we show that our technique reliably detects complex interactions and provides a characterization of these interactions in the frequency domain 2 background and notations to x ki x \\u2208 hi such that \\u2200f \\u2208 hi f x cid10f xcid11 random variables in reproducing kernel hilbert spaces let x1 and x2 be two possibly non vectorial input domains let k1 x1 \\u00d7 x1 \\u2192 c and k2 x2 \\u00d7 x2 \\u2192 c be two positive de\\ufb01nite kernels associated to two separable hilbert spaces of functions h1 and h2 respectively for i \\u2208 1 2 they de\\ufb01ne a canonical mapping from x \\u2208 xi see 19 for more details in the same way this mapping can be extended to random variables so that the random variable xi \\u2208 xi is mapped to the random element xi \\u2208 hi statistical objects extending the classical mean and covariance to random variables in the rkhs are de\\ufb01ned as follows hi \\u2022 the mean element see 1 3 \\u00b5i e xi \\u2022 the crosscovariance operator see 6 cij cov xi xj exi \\u2297 x\\u2217 f \\u2297 g\\u2217 cid10g cid11f following 3 as a consequence the crosscovariance can be seen as an operator j \\u2212 \\u00b5i \\u2297 \\u00b5\\u2217 j where we use the tensor product notation f \\u2297 g\\u2217 to represent the rank one operator de\\ufb01ned by in lhjhi the hilbert space of linear hilbertschmidt operators from hj to hi isomorphic to hi \\u2297 h\\u2217 j interestingly the link between cij and covariance in the input domains is given by the hilbertschmidt scalar product hs cov fixi fjxj \\u2200fi fj \\u2208 hi \\u2297 hj cid10cij fi \\u2297 f\\u2217 j cid11 moreover the hilbertschmidt norm of the operator in this space has been proved to be a measure of independence between two random variables whenever kernels are characteristic 11 extension of this result has been provided in 22 for markov chains if the time series are assumed to be korder markovian then results of the classical hsic can be generalized for a structured hsic using uni versal kernels based on the state vectors x1t x1t k x2t x2t k the statistical performance of this methodology has not been studied extensively in particular its sensitivity to the dimension of the state vector the following sections propose an alternative methodology kernel crossspectral density operator consider a bivariate discrete time random process on x1 \\u00d7 x2 x1t x2tt\\u2208z we assume stationarity of the process and thus use the following translation invariant notations for the mean elements and crosscovariance operators exit \\u00b5i cov xit \\u03c4 xjt cij\\u03c4 the crossspectral density operator was introduced for stationary signals in 2 based on second order cumulants under mild assumptions it is a hilbertschmidt operator de\\ufb01ned for all normalized frequencies \\u03bd \\u2208 0 1 as cid88 k\\u2208z s12\\u03bd cid88 k\\u2208z c12k exp\\u2212k2\\u03c0\\u03bd 2 c12kz\\u2212k for z e2\\u03c0i\\u03bd this object summarizes all the crossspectral properties between the families of processes f x1f\\u2208h1 and gx2g\\u2208h2 in the sense that the crossspectrum between f x1 and gx2 is given by sfg density operator kcsd 12 \\u03bd cid10f s12gcid11 we therefore refer to this object as the kernel crossspectral 3 statistical properties of kcsd measuring independence with the kcsd one interesting characteristic of the kcsd is given by the following theorem 2 theorem 1 assume the kernels k1 and k2 are characteristic 9 the processes x1 and x2 are pairwise independent ie for all integers t and t\\u2019 x1t and x2tcid48 are independent if and only ifcid13cid13s12\\u03bdcid13cid13hs 0 \\u2200\\u03bd \\u2208 0 1 while this theorem states that kcsd can be used to test pairwise independence between time series it does not imply independence between arbitrary sets of random variables taken from each time series in general however if the joint probability distribution of the time series is encoded by a directed acyclic graph dag the following theorem shows that independence in this broader sense is achieved under mild assumptions proposition 2 if the joint probability distribution of time series is encoded by a dag with no confounder under the markov property and faithfulness assumption pairwise independence between time series implies the mutual independence relationship x1tt\\u2208z \\u22a5\\u22a5 x2tt\\u2208z proof the proof uses the fact that the faithfulness and markov property assumptions provide an equivalence between the independence of two sets of random variables and the dseparation of the corresponding sets of nodes in the dag see 17 we start by assuming pairwise independence between the time series for arbitrary times t and tcid48 assume the dag contains an arrow linking the nodes x1t and x2tcid48 this is an unblocked path linking this two nodes thus they are not dseparated as a consequence of faithfulness x1t and x2tcid48 are not independent since this contradicts our initial assumptions there cannot exist any arrow between x1t and x2tcid48 since this holds for all t and tcid48 there is no path linking the nodes of each time series and we have x1tt\\u2208z \\u22a5\\u22a5 x2tt\\u2208z according to the markov property any joint probability distribution on the nodes will factorize in two terms one for each time series as a consequence the use of kcsd to test for independence is justi\\ufb01ed under the widely used faithfulness and markov assumptions of graphical models as a comparison the structured hsic proposed in 22 is theoretically able to capture all dependencies within the range of k samples by assuming korder markovian time series fourth order kernel cumulant operator statistical properties of kcsd require assumptions regarding the higher order statistics of the time series analogously to covariance higher order statistics can be generalized as operators in tensor products of rkhss an important example in our setting is the joint quadricumulant 4th order cumulant see 4 we skip the general expression of this cumulant to focus on its simpli\\ufb01ed form for four centered scalar random variables \\u03bax1 x2 x3 x4 ex1x2x3x4 \\u2212 ex1x2ex3x4 \\u2212 ex1x3ex2x4 \\u2212 ex1x4ex2x3 1 this object can be generalized to the case random variables mapped in two rkhss the quadricu mulant operator k1234 is a linear operator in the hilbert space lh1 \\u2297 h\\u2217 2 such that erties of this operator will be useful in the next sections due to the following lemma lemma 3 property of the tensor quadricumulant let xc the hilbert space h1 and xc de\\ufb01ned by xc 1 xc 3 cid11 for arbitrary elements fi the prop 3 be centered random elements in 4 centered random elements in h2 the centered random element is cid11 cid11 tr c13 tr c24 cid10c14 c32 \\u03baf1x1f2x2f3x3f4x4 cid10f1\\u2297f\\u2217 ecid2cid10xc cid11 cid11 2 xc i xj \\u2212 \\u00b5j then h2 cid3 trk1234 cid10c12 c34 2 k1234f3\\u2297f\\u2217 4 2h1 \\u2297 h\\u2217 cid10xc h1 2 xc 4 1 xc 3 in the case of two jointly stationary time series we de\\ufb01ne the translation invariant quadricumulant between the two stationary time series as k12\\u03c41 \\u03c42 \\u03c43 k1234x1t \\u03c41 x2t \\u03c42 x1t \\u03c43 x2t estimation with the kernel periodogram in the following we address the problem of estimating the properties of crossspectral density oper ators from \\ufb01nite samples the idea for doing this analytically is to select samples from a timeseries with a tapering window function w r cid55\\u2192 r with a support included in 0 1 by scaling this window according to wt k wkt and multiplying it with the time series t samples of the sequence can be selected the windowed periodogram estimate of the kcsd operator for t succes sive samples of the time series is pt 1 t cid107wcid1072ft xc 1\\u03bd\\u2297ft xc 2\\u03bd\\u2217 \\u02c6 12\\u03bd i k xik \\u2212 \\u00b5i and cid107wcid1072 1 with xc w2tdt 0 1 cid80t k1wt kxc where ft xc 1kz\\u2212k for z e2\\u03c0i\\u03bd is the windowed fourier transform of the delayed time series in the rkhs properties of the windowed fourier transform are related to the regularity of the tapering window in particular we will chose a tapering window of bounded variation in such a case the following lemma holds see supplementary material for the proof lemma 4 a property of bounded variation functions let w be a bounded function of bounded using this assumption the above periodogram estimate is asymptotically unbiased as shown in the following theorem k\\u2208z kcid107c12kcid107hs \\u221e t\\u2212\\u221ewt t kwt \\u2212cid80\\u221e variation then for all kcid12cid12cid80\\u221e t\\u2212\\u221ewt t2cid12cid12 \\u2264 ck theorem 5 let w be a bounded function of bounded variation ifcid80 cid12cid12tr k12k i jcid12cid12 \\u221e cid80 k\\u2208z k trciik \\u221e andcid80 2nz\\u2212ncid1\\u2217 1kz\\u2212kcid1\\u2297cid0cid80 12\\u03bd s12\\u03bd \\u03bd cid54\\u2261 0 kij\\u2208z3 e pt proof by de\\ufb01nition 12z 1 mod 12 pt n\\u2208z zn\\u2212kwt kwt nxc n\\u2208z wt nxc 1k\\u2297xc 2n\\u2217 1 1 tcid107wcid1072 tcid107wcid1072 t\\u2192\\u221e then lim k\\u2208z wt kxc cid0cid80 cid80 k\\u2208zcid80 \\u03b4\\u2208z z\\u2212\\u03b4cid80 cid80 cid80 \\u03b4\\u2208z z\\u2212\\u03b4cid80 cid80 1cid107wcid1072 cid80 n\\u2208z wt n2 tcid107wcid1072 t thus using lemma 4 e pt 12z 1 tcid107wcid1072 n\\u2208z wt n \\u03b4wt nxc 1n \\u03b4\\u2297xc 2n\\u2217 using \\u03b4 k \\u2212 n n\\u2208z wt n2 o\\u03b4c12\\u03b4 \\u03b4\\u2208z z\\u2212\\u03b4c12\\u03b4 1 t ocid80 \\u03b4\\u2208z \\u03b4cid13cid13c12\\u03b4cid13cid13hs \\u2192 t\\u2192\\u221e s12 however the squared hilbertschmidt norm of pt population kcsd squared norm according to the following theorem theorem 6 under the assumptions of theorem 5 for \\u03bd cid54\\u2261 0 mod 12 ecid13cid13pt 12\\u03bdcid13cid132 hs cid13cid13s12\\u03bdcid13cid132 lim t\\u2192\\u221e hs trs11\\u03bd trs22\\u03bd 12\\u03bd is an asymptotically biased estimator of the the proof of theorem 5 is based on the decomposition in lemma 3 and is provided in supplementary information this estimate requires speci\\ufb01c bias estimation techniques to develop an independence test we will call it the biased estimate of the kcsd squared norm having the kcsd de\\ufb01ned in an hilbert space also enables to de\\ufb01ne similarity between two kcsd operators so that it is possible to compare quantitatively whether different dynamical systems have similar couplings the following theorem shows how periodograms enable to estimate the scalar product between two kcsd operators which re\\ufb02ects their similarity 4 theorem 7 assume assumptions of theorem 5 hold for two independent samples of bivariate time seriesx1t x2tt\\u2212101 and x3t x4tt\\u2212101 mapped with the same couple of reproducing kernels ecid10pt 34\\u03bdcid11 hs cid10s12\\u03bd s34\\u03bdcid11 then lim t\\u2192\\u221e 12\\u03bd pt hs \\u03bd cid54\\u2261 0 mod 12 the proof of theorem 7 is similar to the one of theorem 6 provided as supplemental information interestingly this estimate of the scalar product between kcsd operators is unbiased this comes from the assumption that the two bivariate series are independent this provides a new opportunity to estimate the hilbertschmidt norm as well in case two independent samples of the same bivariate series are available corollary 8 assume assumptions of theorem 5 hold for the bivariate time series x1t x2tt\\u2208z and assume \\u02dcx1t \\u02dcx2tt\\u2208zan independent copy of the same time series providing the periodogram estimates pt 12\\u03bd and \\u02dcpt ecid10pt 12\\u03bdcid11 hs cid13cid13s12\\u03bdcid13cid132 12\\u03bd respectively hs \\u03bd cid54\\u2261 0 then lim t\\u2192\\u221e 12\\u03bd \\u02dcpt mod 12 in many experimental settings such as in neuroscience it is possible to measure the same time series in several independent trials in such a case corollary 8 states that estimating the hilbertschmidt norm of the kcsd without bias is possible using two intependent trials we will call this estimate the unbiased estimate of the kcsd squared norm these estimate can be computed ef\\ufb01ciently for t equispaced frequency samples using the fast fourier transform of the centered kernel matrices of the two time series in general the choice of the kernel is a tradeoff between the capacity to capture complex dependencies a character istic kernel being better in this respect and the convergence rate of the estimate simpler ker nels related to lower order statistics usually require less samples related theoretical analy sis can be found in 8 12 unless otherwise stated the gaussian rbf kernel with bandwidth parameter \\u03c3 kx y expcid107x \\u2212 ycid1072 2\\u03c32 will be used as a characteristic kernel for vec tor spaces let kij denote the kernel matrix between the ith and jth time series such that kijkl kxik xjl w the windowing matrix such that wkl wt kwt l and m be the centering matrix m i \\u2212 1t 1t t t then we can de\\ufb01ne the windowed centered kernel matrices \\u02dckij mkijm \\u25e6 w de\\ufb01ning the discrete fourier transform matrix f such that \\u221a fkl exp\\u2212i2\\u03c0klt \\u03bd01t\\u22121t cid107wcid107\\u22124 diagcid0f \\u02dck13f\\u22121cid1 \\u25e6 diagcid0f\\u22121 \\u02dck24fcid1 t the estimated scalar product is cid10pt 12 pt 34 cid11 which can be ef\\ufb01ciently computed using the fast fourier transform \\u25e6 is the hadamard product the biased and unbiased squared norm estimates can be trivially retrieved from the above expression shuf\\ufb02ing independence tests according to theorem 1 pairwise independence between time series requires the crossspectral density operator to be zero for all frequencies we can thus test independence by testing whether the hilbertschmidt norm of the operator vanishes for each frequency we rely on theorem 6 and corollary 8 to compute biased and unbiased estimates of this norm to achieve this we generate a distribution of the hilbertschmidt norm statistics under the null hypothesis by cutting the time interval in nonoverlapping blocks and matching the blocks of each time series in pairs at random due to the central limit theorem for a suf\\ufb01ciently large number of time windows the empirical average of the statistics approaches a gaussian distribution we thus test whether the empirical mean differs from the one under the null distribution using a tstatistic to prevent false positive resulting from multiple hypothesis testing we control the familywise error rate fwer of the tests performed for each frequency following 16 we estimate a global maximum distribution on the family of tstatistics across frequencies under the null hypothesis and use the percentile of this distribution to assess the signi\\ufb01cance of the original tstatistics 5 figure 1 results for the phaseamplitude coupling system topleft example time course top middle estimate of the kcsd squared norm with a linear kernel topright estimate of the kcsd squared norm with an rbf kernel bottomleft performance of the biased kcsd test as a function of number of samples bottommiddle performance of the unbiased kcsd test as a function of number of samples bottomright rate of type i and type ii errors for several independence tests 4 experiments in the following we validate the performance of our test called kcsd on several datasets in the biased and unbiased case there is no general time series analysis tool in the literature to compare with our approach on all these datasets so our main source of comparison will be the hsic test of independence assuming data is iid this enables us to compare both approaches using the same kernels for vector data one can compare the performance of our approach with a linear dependency measure we do this by implementing our test using a linear kernel instead of an rbf kernel and we call it linear kscd finally we use the alternative approach of structured hsic 22 by cutting the time series in time windows using the same approach as our independence test and considering each of them as a single multivariate sample this will be called block hsic the bandwidth of the hsic methods is chosen proportional to the median norm of the sample points in the vector space the pvalue for all independence tests will be set to 5 phase amplitude coupling we \\ufb01rst simulate a nonlinear dependency between two time series by generating two oscillations at frequencies f1 and f2 and introducing a modulation of the amplitude of the second oscillation by the phase of the \\ufb01rst one this is achieved using the following discrete time equations cid26 \\u03d51k 1 \\u03d51k 1\\u00011k 2\\u03c0f1ts cid26 x1k cos\\u03d51k \\u03d52k 1 \\u03d52k 1\\u00012k 2\\u03c0f2ts x2k 2 c sin \\u03d51k cos\\u03d52k where the \\u0001i are iid normal a simulation with f1 4hz and f2 20hz for a sampling fre quency 1ts100hz is plotted on figure 1 topleft panel for the parameters of the periodogram we used a window length of 50 samples 5 s we used a gaussian rbf kernel to compute non linear dependencies between the two time series after standardizing each of them divide them by their standard deviation the topmiddle and topright panels of figure 1 plot the mean and stan dard errors of the estimate of the squared hilbertschmidt norm for this system for c 1 for a linear and a gaussian rbf kernel with \\u03c3 1 respectively the bias of the \\ufb01rst estimate appears clearly in both cases at the two power picks of the signals for the biased estimate in the second unbiased estimate the spectrum exhibits a zero mean for all but one peak at 4hz for the rbf kernel which corresponds to the expected frequency of nonlinear interaction between the time series the observed negative values are also a direct consequence of the unbiased property of our estimate corollary 8 the in\\ufb02uence of the bandwidth parameter of the kernel was studied in the case of weakly coupled time series c 4 the bottom left and middle panels of figure 1 show 6 frequency hzbiasedunbiasedsquared norm estimate linear kernelfrequency hzbiasedunbiasedsquared norm estimate rbf kernel005115\\u22124\\u2212202420406080100block hsichsiclinear kcsdkcsd020406080100type i c0type ii c4type ii c2error rate time snumber of samplesnumber of dependencies detected detection probability for biased kcsdnumber of samples1021030020406081detection probability for unbiased kcsdnumber of dependencies detected 1021030020406081linearrbf\\u03c31263153910051015202530\\u2212010010203051015202530\\u2212005000501015 figure 2 markov chain dynamical system upper left markov transition probabilities \\ufb02uctuating between the values indicated in both graphs upper right example of simulated time series bottom left the biased and unbiased kcsd norm estimates in the frequency domain bottom right type i and type ii errors for hsic and kcsd tests the in\\ufb02uence of this parameter on the number of samples required to actually reject the null hypoth esis and detect the dependency for biased and unbiased estimates respectively it was observed that choosing an hyperparameter close to the standard deviation of the signal here 15 was an optimal strategy and that the test relying on the unbiased estimate outperformed the biased estimate we thus used the unbiased estimate in our subsequent analysis the coupling parameter c was further varied to test the performance of independence tests both in case the null hypothesis of indepen dence is true c0 and when it should be rejected c 4 for weak coupling c 2 for strong coupling these two settings enable to quantify the type i and type ii error of the tests respectively the bottomright panel of figure 1 reports these errors for several independence tests showing the superiority of our method especially for type ii errors in particular methods based on hsic fail to detect weak dependencies in the time series time varying markov chain we now illustrate the use of our test in an hybrid setting we generate a symbolic time series x2 using the alphabet s 1 2 3 controlled by a scalar time series x1 the coupling is achieved by modulating across time the transition probabilities of the markov transition matrix generating the symbolic time series x2 using the current value of the scalar time series x1 this model is described by the following equations with f1 1hz cid40 \\u03d51k 1\\u00011k 2\\u03c0f1ts px2k 1 six2k sj \\u03d51k 1 x1k 1 sin\\u03d51k 1 mij \\u2206mijx1k since x1 is bounded between 1 and 1 the markov transition matrix \\ufb02uctuates across time between two models represented figure 2 topleft panel a model without these \\ufb02uctuations \\u2206m 0 was simulated as well to measure type i error the time course of such an hybrid system is illustrated on the topright panel of the same \\ufb01gure in order to measure the dependency between these two time series we use a kspectrum kernel 14 for x2 and a rbf kernel for x1 for the kspectrum kernel we use k2 using k1 ie counting occurrences of single symbols was less ef\\ufb01cient and we computed the kernel between words of 3 successive symbols of the time series we used an rbf kernel with \\u03c3 1 decimated the signals by a factor 2 and signals were cut in time windows of 100 samples the biased and unbiased estimates of the kcsd norm are represented at the bottomleft of figure 2 and show a clear peak at the modulating frequency 1hz the independence test results shown at the bottomright of figure 2 illustrate again the superiority of kcsd for type ii error whereas type i error stays in an acceptable range 7 12311124757212311126013789transition probabilities01234\\u221205005state 1state 2state 3time sblock hsichsickcsd020406080100error rate type i errortype ii errorbiasedunbiasedfrequency hzkcsd norm estimate010205125102005101520 figure 3 left experimental setup of lfp recordings in anesthetized monkey during visual stim ulation with a movie right proportion of detected dependencies for the unbiased kcsd test of interactions between gamma band and wide band lfp for different kernels neural data local \\ufb01eld potentials from monkey visual cortex we analyzed dependencies between local \\ufb01eld potential lfp time series recorded in the primary visual cortex of one anesthetized monkey during visual stimulation by a commercial movie see figure 3 for a scheme of the experiment lfp activity re\\ufb02ects the nonlinear interplay between a large variety of underlying mechanisms here we investigate this interplay by extracting lfp activity in two frequency bands within the same electrode and quantify the nonlinear interactions between them with our approach lfps were \\ufb01ltered into two frequency bands 1 a wide band ranging from 1 to 100hz which contains a rich variety of rhythms and 2 a high gamma band ranging from 60 to 100hz which as been shown to play a role in the processing of visual information both of these time series were sampled at 1000hz using nonoverlapping time windows of 1s points we computed the hilbertschmidt norm of the kcsd operator between gamma and large band time series originating from the same electrode we performed statistical testing for all fre quencies between 1 and 500hz using a fourier transform on 2048 points the results of the test averaged over all recording sites is plotted on figure 3 we observe a highly reliable detection of interactions in the gamma band using either a linear or nonlinear kernel this is due to the fact that the gamma band lfp is a \\ufb01ltered version of the wide band lfp making these signals highly correlated in the gamma band however in addition to this obvious linear dependency we observe signi\\ufb01cant interactions in the lowest frequencies 052hz which can not be explained by linear in teraction and is thus not detected by the linear kernel this characteristic illustrates the nonlinear interaction between the high frequency gamma rhythm and other lower frequencies of the brain elec trical activity which has been reported in other studies 21 this also shows the interpretability of our approach as a test of nonlinear dependency in the frequency domain 5 conclusion an independence test for time series based on the concept of kernel cross spectral density estima tion was introduced in this paper it generalizes the linear approach based on the fourier transform in several respects first it allows quanti\\ufb01cation of nonlinear interactions for time series living in vector spaces moreover it can measure dependencies between more complex objects includ ing sequences in an arbitrary alphabet or graphs as long as an appropriate positive de\\ufb01nite kernel can be de\\ufb01ned in the space of each time series this paper provides asymptotic properties of the kcsd estimates as well as an ef\\ufb01cient approach to compute them on real data the space of kcsd operators constitutes a very general framework to analyze dependencies in multivariate and highly structured dynamical systems following 13 18 our independence test can further be combined to recent developments in kernel time series prediction techniques 20 to de\\ufb01ne general and reliable multivariate causal inference techniques acknowledgments mb is grateful to dominik janzing for fruitful discussions and advice 8 references 1 a berlinet and c thomasagnan reproducing kernel hilbert spaces in probability and statistics kluwer academic boston 2004 2 m besserve d janzing n logothetis and b sch\\u00a8olkopf finding dependencies between frequencies with the kernel crossspectral density in ieee international conference on acoustics speech and signal processing pages 2080\\u20132083 2011 3 g blanchard o bousquet and l zwald statistical properties of kernel principal component analysis machine learning 6623259\\u2013294 2007 4 d brillinger time series data analysis and theory holt rinehart and winston new york 1974 5 jf cardoso highorder contrasts for independent component analysis neural computation 111157\\u2013 192 1999 6 k fukumizu f bach and a gretton statistical convergence of kernel cca in advances in neural information processing systems 18 pages 387\\u2013394 2006 7 k fukumizu f bach and m jordan dimensionality reduction for supervised learning with reproducing kernel hilbert spaces j mach learn res 573\\u201399 2004 8 k fukumizu a gretton g r lanckriet b sch\\u00a8olkopf and b k sriperumbudur kernel choice and in advances in neural information classi\\ufb01ability for rkhs embeddings of probability distributions processing systems 21 pages 1750\\u20131758 2009 9 k fukumizu a gretton x sun and b sch\\u00a8olkopf kernel measures of conditional dependence in advances in neural information processing systems 20 pages 489\\u2013496 2008 10 g b giannakis and j m mendel identi\\ufb01cation of nonminimum phase systems using higher order statistics acoustics speech and signal processing ieee transactions on 373360\\u2013377 1989 11 a gretton k fukumizu c teo l song b sch\\u00a8olkopf and a smola a kernel statistical test of independence in advances in neural information processing systems 20 pages 585\\u2013592 2008 12 a gretton d sejdinovic h strathmann s balakrishnan m pontil k fukumizu and b k sripe rumbudur optimal kernel choice for largescale twosample tests in advances in neural information processing systems 25 pages 1214\\u20131222 2012 13 a hyv\\u00a8arinen s shimizu and p o hoyer causal modelling combining instantaneous and lagged effects an identi\\ufb01able model based on nongaussianity in proceedings of the 25th international conference on machine learning pages 424\\u2013431 acm 2008 14 c leslie e eskin and w noble the spectrum kernel a string kernel for svm protein classi\\ufb01cation in pac symp biocomput 2002 15 c nikias and a petropulu higherorder spectra analysis a nonlinear signal processing framework prenticehall ptr englewood cliffs nj 1993 16 d pantazis t nichols s baillet and r leahy a comparison of random \\ufb01eld theory and permutation methods for the statistical analysis of meg data neuroimage 25383 \\u2013 394 2005 17 j pearl causality models reasoning and inference cambridge university press cambridge uk 2000 18 j peters d janzing and b sch\\u00a8olkopf causal inference on time series using structural equation models in advances in neural information processing systems 26 2013 19 b sch\\u00a8olkopf and a j smola learning with kernels mit press cambridge ma 2002 20 v sindhwani h q minh and a c lozano scalable matrixvalued kernel learning for highdimensional nonlinear multivariate regression and granger causality in proceedings of the 29th conference on uncer tainty in arti\\ufb01cial intelligence 2013 21 k whittingstall and n k logothetis frequencyband coupling in surface eeg re\\ufb02ects spiking activity in monkey visual cortex neuron 64281\\u20139 2009 22 x zhang l song a gretton and a smola kernel measures of independence for noniid data in advances in neural information processing systems 21 pages 1937\\u20131944 2009 9\",\n          \"tangent prop a formalism for specifying selected invariances in an adaptive network patrice simard att bell laboratories 101 crawford corner rd holmdel nj 07733 bernard victorri universite de caen caen 14032 cedex france yann le cun att bell laboratories 101 crawford corner rd holmdel nj 07733 john denker att bell laboratories 101 crawford corner rd holmdel nj 07733 abstract in many machine learning applications one has access not only to training data but also to some highlevel a priori knowledge about the desired becid173 havior of the system for example it is known in advance that the output of a character recognizer should be invariant with respect to small spacid173 tial distortions of the input images translations rotations scale changes etcetera we have implemented a scheme that allows a network to learn the derivacid173 tive of its outputs with respect to distortion operators of our choosing this not only reduces the learning time and the amount of training data but also provides a powerful language for specifying what generalizations we wish the network to perform 1 introduction in machine learning one very often knows more about the function to be learned than just the training data an interesting case is when certain directional derivacid173 tives of the desired function are known at certain points for example an image 895 896 simard victorri le cun and denker figure 1 top small rotations of an original digital image of the digit 3 center middle representation of the effect of the rotation in the input vector space space assuming there are only 3 pixels bottom images obtained by moving along the tangent to the transformation curve for the same original digital image middle recognition system might need to be invariant with respect to small distortions of the input image such as translations rotations scalings etc a speech recognition system night need to be invariant to time distortions or pitch shifts in other words the derivative of the systems output should be equal to zero when the input is transformed in certain ways given a large amount of training data and unlimited training time the system could learn these invariances from the data alone but this is often infeasible the limitation on data can be overcome by training the system with additional data obtained by distorting translating rotating etc the original patterns baird 1990 the top of fig 1 shows artificial data generated by rotating a digital image of the digit 3 with the original in the center this procedure called the distortion model has two drawbacks first the user must choose the magnitude of distortion and how many instances should be generated second and more importantly the distorted data is highly correlated with the original data this makes traditional learning algorithms such as back propagation very inefficient the distorted data carries only a very small incremental amount of information since the distorted patterns are not very different from the original ones it may not be possible to adjust the learning system so that learning the invariances proceeds at a reasonable rate while learning the original points is nondivergent the key idea in this paper is that it is possible to directly learn the effect on the output of distorting the input independently from learning the undistorted tangent propa formalism for specifying selected invariances in an adaptive network 897 fx fx x1 x2 x3 x4 x x1 x2 x3 x4 x figure 2 learning a given function solid line from a limited set of example xl to x4 the fitted curves are shown in dotted line top the only constraint is that the fitted curve goes through the examples bottom the fitted curves not only goes through each examples but also its derivatives evaluated at the examples agree with the derivatives of the given function patterns when a pattern p is transformed eg rotated with a transformation s that depends on one parameter a eg the angle of the rotation the set of all the transformed patterns sp sea p va is a one dimensional curve in the vector space of the inputs see fig 1 in certain cases such as rotations of digital images this curve must be made continuous using smoothing techniques as will be shown below when the set of transformations is parameterized by n parameters ai rotation translation scaling etc sp is a manifold of at most n dimensions the patterns in sp that are obtained through small transformations of p ie the part of s p that is close to p can be approximated by a plane tangent to the manifold sp at point p small transformations of p can be obtained by adding to p a linear combination of vectors that span the tangent plane tangent vectors the images at the bottom of fig 1 were obtained by that procedure more importantly the tangent vectors can be used to specify high order constraints on the function to be learned as explained below to illustrate the method consider the problem of learning a singlevalued function f from a limited set of examples fig 2 left represents a simple case where the desired function f solid line is to be approximated by a function g dotted line from four examples xi fxii1234 as exemplified in the picture the fitted function g largely disagrees with the desired function f between the examples if the functions f and g are assumed to be differentiable which is generally the case the approximation g can be greatly improved by requiring that gs derivatives evaluated at the points xd are equal to the derivatives of f at the same points fig 2 right this result can be extended to multidimensional inputs in this case we can impose the equality of the derivatives of f and g in certain directions not necessarily in all directions of the input space such constraints find immediate use in traditional learning problems it is often the case that a priori knowledge is available on how the desired function varies with 898 simard victorri le cun and denker pattern p pattern p rotated by ex tangent vector figure 3 how to compute a tangent vector for a given transformation in this case a rotation respect to some transformations of the input it is straightforward to derive the corresponding constraint on the directional derivatives of the fitted function g in the directions of the transformations previously named tangent vectors typical examples can be found in pattern recognition where the desired classification funccid173 tion is known to be invariant with respect to some transformation of the input such as translation rotation scaling etc in other words the directional derivatives of the classification function in the directions of these transformations is zero 2 implementation the implementation can be divided into two parts the first part consists in comcid173 puting the tangent vectors this part is independent from the learning algorithm used subsequently the second part consists in modifying the learning algorithm for instance backprop to incorporate the information about the tangent vectors part i let x be an input pattern and s be a transformation operator acting on the input space and depending on a parameter a if s is a rotation operator for instance then s a x denotes the input x rotated by the angle a we will require that the transformation operator s be differentiable with respect to a and x and that so x x the tangent vector is by definition 8sa x8a it can be approximated by a finite difference as shown in fig 3 in the figure the input space is a 16 by 16 pixel image and the patterns are images of handwritten digits the transformations considered are rotations of the digit images the tangent vector is obtained in two steps first the image is rotated by an infinitesimal amount a this is done by computing the rotated coordinates of each pixel and interpolating the gray level values at the new coordinates this operation can be advantageously combined with some smoothing using a convolution a convolution with a gaussian provides an efficient interpolation scheme in onm multiplyadds where nand m are the gaussian kernel and image sizes respectively the next step is to subtract pixel by pixel the rotated image from the original image and to divide the result tangent propa formalism for specifying selected invariances in an adaptive network 899 by the scalar 0 see fig 3 if ie types of transformations are considered there will be ie different tangent vectors per pattern for most algorithms these do not require any storage space since they can be generated as needed from the original pattern at negligible cost part it tangent prop is an extension of the backpropagation algorithm allowing it to learn directional derivatives other algorithms such as radial basis functions can be extended in a similar fashion to implement our idea we will modify the usual weightupdate rule is replaced with w 7 ow e jter oe w 7 ow 0 1 where 7 is the learning rate e the usual objective function er an additional objeccid173 tive function a regularizer that measures the discrepancy between the actual and desired directional derivatives in the directions of some selected transformations and jt is a weighting coefficient let x be an input pattern y gx be the inputoutput function of the network the regularizer er is of the form where erx is erx e e trainingset 2 here kix is the desired directional derivative of g in the direction induced by transformation si applied to pattern x the second term in the norm symbol is the actual directional derivative which can be rewritten as gx osio x 00 00 00 where gx is the jacobian of g for pattern x and osio xjoo is the tangent vector associated to transformation si as described in part i multiplying the tangent vector by the jacobian involves one forward propagation through a linearized version of the network in the special case where local invariance with respect to the sis is desired kix is simply set to o composition of transformations the theory of lie groups gilmore 1974 ensures that compositions of local small transformations si correspond to linear combinations of the corresponding tangent vectors the local transformations si have a structure of lie algebra consequently if erx 0 is verified the network derivative in the direction of a linear combination of the tangent vectors is equal to the same linear combination of the desired derivatives in other words if the network is successfully trained to be locally invariant with respect to say horizontal translation and vertical translations it will be invariant with respect to compositions thereof we have derived and implemented an efficient algorithm tangent prop for percid173 forming the weight update eq 1 it is analogous to ordinary backpropagation 900 simard victorri le cun and denker wl iti w l1 iti e l bl x\\u00b7 i network j3j1 ei jacobian nework figure 4 forward propagated variables a x a e and backward propagated varicid173 ables b y p tj in the regular network roman symbols and the jacobian lincid173 earized network greek symbols but in addition to propagating neuron activations it also propagates the tangent vectors the equations can be easily derived from fig 4 forward propagation a wl xl i \\u2022 lj i x uad tangent forward propagation 1 ai lj wwi i e uaa tangent gradient backpropagation 31 w1il1 i lj it iti \\u00a5lit gradient backpropagation b w1 1yl1 i lj it iti it weight update 8ew up ier w up tp 11 li \\u00a5ii xi yi ioi w\\u00b7\\u00b7 i 8 3 4 5 6 7 tangent propa formalism for specifying selected invariances in an adaptive network 901 60 50 erroron the test set 20 10 160 320 training set size figure 5 generalization performance curve as a function of the training set size for the tangent prop and the backprop algorithms the regularization parameter jj is tremendously important because it determines the tradeoff between minimizing the usual objective function and minimizing the directional derivative error 3 results two experiments illustrate the advantages of tangent prop the first experiment is a classification task using a small linearly separable set of 480 binarized handcid173 written digit the training sets consist of 10 20 40 80 160 or 320 patterns and the training set contains the remaining 160 patterns the patterns are smoothed using a gaussian kernel with standard deviation of one half pixel for each of the training set patterns the tangent vectors for horizontal and vertical translation are computed the network has two hidden layers with locally connected shared weights and one output layer with 10 units 5194 connections 1060 free paramecid173 ters le cun 1989 the generalization performance as a function of the training set size for traditional backprop and tangent prop are compared in fig 5 we have conducted additional experiments in which we implemented not only translations but also rotations expansions and hyperbolic deformations this set of 6 genercid173 ators is a basis for all linear transformations of coordinates for two dimensional images it is straightforward to implement other generators including grayievelcid173 shifting smooth segmentation local continuous coordinate transformations and independent image segment transformations the next experiment is designed to show that in applications where data is highly 902 simard victorri le cun and denker avge nmse vi 1ge a nmse vi 015 01 15 1 o o 1000 2000 3000 4000 5000 6000 7000 8000 0000 10000 ol 1000 2000 3000 4000 5000 6000 7000 8000 0000 10000 0 15 o 05 1 15 0 5 1 1 5 15 t 1 5 1 15 15 1 0 05 05 distortion model o 5 5 tangent prop 15 figure 6 comparison of the distortion model left column and tangent prop right column the top row gives the learning curves error versus number of sweeps through the training set the bottom row gives the final inputoutput function of the network the dashed line is the result for unadorned back prop tangent propa formalism for specifying selected invariances in an adaptive network 903 correlated tangent prop yields a large speed advantage since the distortion model implies adding lots of highly correlated data the advantage of tangent prop over the distortion model becomes clear the task is to approximate a function that has plateaus at three locations we want to enforce local invariance near each of the training points fig 6 bottom the network has one input unit 20 hidden units and one output unit two strategies are possible either generate a small set of training point covering each of the plateaus open squares on fig 6 bottom or generate one training point for each plateau closed squares and enforce local invariance around them by setting the desired derivative to 0 the training set of the former method is used as a measure the performance for both methods all parameters were adjusted for approximately optimal performance in all cases the learning curves for both models are shown in fig 6 top each sweep through the training set for tangent prop is a little faster since it requires only 6 forward propagations while it requires 9 in the distortion model as can be seen stable performance is achieved after 1300 sweeps for the tangent prop versus 8000 for the distortion model the overall speedup is therefore about 10 tangent prop in this example can take advantage of a very large regularization term the distortion model is at a disadvantage because the only parameter that effeccid173 tively controls the amount of regularization is the magnitude of the distortions and this cannot be increased to large values because the right answer is only invariant under small distortions 4 conclusions when a priori information about invariances exists this information must be made available to the adaptive system there are several ways of doing this including the distortion model and tangent prop the latter may be much more efficient in some applications and it permits separate control of the emphasis and learning rate for the invariances relative to the original training data points training a system to have zero derivatives in some directions is a powerful tool to express invariances to transformations of our choosing tests of this procedure on largescale applications handwritten zipcode recognition are in progress references baird h s 1990 document image defect models in iapr 1990 workshop on sytactic and structural pattern recognition pages 3846 murray hill nj gilmore r 1974 lie groups lie algebras and some of their applications wiley new york le cun y 1989 generalization and network design strategies in pfeifer r schreter z fogelman f and steels l editors connectionism in perspeccid173 tive zurich switzerland elsevier an extended version was published as a technical report of the university of toronto\",\n          \"minimizing statistical bias with queries david a cohn adaptive systems group harlequin inc one cambridge center cambridge ma 02142 cohncharlequincom abstract i describe a querying criterion that attempts to minimize the error of a learner by minimizing its estimated squared bias i describe experiments with locallyweighted regression on two simple probcid173 lems and observe that this biasonly approach outperforms the more common varianceonly exploration approach even in the presence of noise 1 introduction in recent years there has been an explosion of interest in active machine learning systems these are learning systems that make queries or perform experiments to gather data that are expected to maximize performance when compared with passive learning systems which accept given or randomly drawn data active learners have demonstrated significant decreases in the amount of data required to achieve equivalent performance in industrial applications where each experiment may take days to perform and cost thousands of dollars a method for optimally selecting these points would offer enormous savings in time and money an active learning system will typically attempt to select data that will minimize its predictive error this error can be decomposed into bias and variance terms most research in selecting optimal actions or queries has assumed that the learner is approximately unbiased and that to minimize learner error variance is the only thing to minimize eg fedorov 1972 mackay 1992 cohn 1996 cohn et al 1996 paass 1995 in practice however there are very few problems for which we have unbiased learners frequently bias constitutes a large portion of a learners error if the learner is deterministic and the data are noisefree then bias is the only source of error note that the bias term here is a statistical bias distinct from the inductive bias discussed in some machine learning research dietterich and kong 1995 418 da cohn in this paper i describe an algorithm which selects actions queries designed to minicid173 mize the bias of a locally weighted regressionbased learner empirically variancecid173 minimizing strategies which ignore bias seem to perform well even in cases where strictly speaking there is no variance to minimize in the tasks considered in this paper the biasminimizing strategy consistently outperforms variance minimizacid173 tion even in the presence of noise 11 bias and variance let us begin by defining px y to be the unknown joint distribution over x and y and p x to be the known marginal distribution of x commonly called the input distribution we denote the learners output on input x given training set d as yx d we can then write the expected error of the learner as 1 e yxd yx2ix pxdx 1 where e\\u00b7 denotes the expectation over p and over training sets d the expectation inside the integral may be decomposed as follows geman et al 1992 e yxd yx2ix e yx eylx 2 ev yx d eylx2 ev yxd evyxd2 where ev denotes the expectation over training sets the first term in equation 2 is the variance of y given x it is the noise in the distribution and does not depend on our learner or how the training data are chosen the second term is the learners squared bias and the third is its variance these last two terms comprise the expected squared error of the learner with respect to the regression function eylx most research in active learning assumes that the second term of equation 2 is approximately zero that is that the learner is unbiased if this is the case then one may concentrate on selecting data so as to minimize the variance of the learner although this allvariance approach is optimal when the learner is unbiased truly unbiased learners are rare even when the learners representation class is able to match the target function exactly bias is generally introduced by the learning algorithm and learning parameters from the bayesian perspective a learner is only unbiased if its priors are exactly correct the optimal choice of query would of course minimize both bias and variance but i leave that for future work for the purposes of this paper i will only be concerned with selecting queries that are expected to minimize learner bias this approach is justified in cases where noise is believed to be only a small component of the learners error if the learner is deterministic and there is no noise then strictly speaking there is no error due to variance all the error must be due to learner bias in cases with nondeterminism or noise allbias minimization like allvariance minimization becomes an approximation of the optimal approach the learning model discussed in this paper is a form of locally weighted regression lwr cleveland et al 1988 which has been used in difficult machine learning tasks notably the robot juggler of schaal and atkeson 1994 previous work cohn et al 1996 discussed allvariance query selection for lwr in the remainder of this paper i describe a method for performing allbias query selection section 2 describes the criterion that must be optimized for allbias query selection section 3 describes the locally weighted regression learner used in this paper and describes minimizing statistical bias with queries 419 how the allbias criterion may be computed for it section 4 describes the results of experiments using this criterion on several simple domains directions for future work are discussed in section 5 2 allbias query selection let us assume for the moment that we have a source of noisefree examples xi yi and a deterministic learner which given input x outputs estimate yxl let us also assume that we have an accurate estimate of the bias of y which can be used to estimate the true function yx yx biasx we will break these rather strong assumptions of noisefree examples and accurate bias estimates in section 4 but they are useful for deriving the theoretical approach described below given an accurate bias estimate we must force the biased estimator into the best approximation of yx with the fewest number of examples this in effect transcid173 forms the query selection problem into an example filter problem similar to that studied by plutowski and white 1993 for neural networks below i derive this criterion for estimating the change in error at x given a new queried example at x since we have temporarily assumed a deterministic learner and noisefree data the expected error in equation 2 simplifies to e y x d y x2ix d yx d yx2 3 we want to select a new x such that when we add x f the resulting squared bias is minimized y y yx d u x f yx2 4 i will for the remainder of the paper use the to indicate estimates based on the initial training set plus the additional example x y to minimize expression 4 we need to compute how a query at x will change the learners bias at x if we assume that we know the input distribution2 then we can integrate this change over the entire domain using monte carlo procedures to estimate the resulting average change and select a x such that the expected squared bias is minimized defining bias y y and fy y y we can write the new squared bias as bias2 y y2 y fy y2 fy2 2fy bias bias2 5 note that since bias as defined here is independent of x minimizing the bias is equivalent to minimizing fy2 2fy bias the estimate of bias tells us how much our bias will change for a given x we may optimize this value over x in one of a number of ways in low dimensional spaces it is often sufficient to consider a set of candidate x and select the one promising the smallest resulting error in higher dimensional spaces it is often more efficient to search for an optimal x with a response surface technique box and draper 1987 or hill climb on abias2 ax estimates of bias and fy depend on the specific learning model being used in section 3 i describe a locally weighted regression model and show how differentiable estimates of bias and fy may be computed for it 1 for clarity i will drop the argument z except where required for disambiguation i will also denote only the univariate case the results apply in higher dimensions as well 2this assumption is contrary to the assumption normally made in some forms of learncid173 ing eg paclearning but it is appropriate in many domains 420 d a cohn 21 an aside why not just use y mas if we have an accurate bias estimate it is reasonable to ask why we do not simply use the corrected y cs as our predictor the answer has two parts the first of which is that for most learners there are no perfect bias estimators they introduce their own bias and variance which must be addressed in data selection second we can define a composite learner ye y cs given a random training sample then we would expect ye to outperform y however there is no obvious way to select data for this composite learner other than selecting to maximize the performance of its two components in our case the second component the bias estimate is nonanalytic which leaves us selecting data so as to maximize the performance of the first component the uncorrected estimator we are now back to our original problem we can select data so as to minimize either the bias or variance of the uncorrected lwrbased learner since the purpose of the correction is to give an unbiased estimator intuition suggests that variance minimization would be the more sensible route in this case empirically this approach does not appear to yield any benefit over uncorrected variance minimization see figure 1 3 locally weighted regression the type of learner i consider here is a form of locally weighted regression lwr that is a slight variation on the loess model of cleveland et al 1988 see cohn et al 1996 for details the loess model performs a linear regression on points in the data set weighted by a kernel centered at x the kernel shape is a design parameter the original loess model uses a tricubic kernel in my experiments i use the more common gaussian where ie is a smoothing parameter for brevity i will drop the argument x for hix and define n 2i hi we can then write the weighted means and covariances as xi n jlr lj hi jly l h yi n ury lj hi xi xyi jly n we use these means and covariances to produce an estimate y at the x around which the kernel is centered with a confidence term in the form of a variance estimate in all the experiments discussed in this paper the smoothing parameter ie was set so as to minimize u2 the low cost of incorporating new training examples makes this form of locally weighted regression appealing for learning systems which must operate in real time or with timevarying target functions eg schaal and atkeson 1994 minimizing statistical bias with queries 421 i i y a a a i a 31 computing dy for lwr if we know what new point x y were going to add computing dy for lwr is straightforward defining h as the weight given to x and n as n h we can write y y y jl x jlx h y jly uxy x jlx x nx x nuxy h x xkii jly u xy u2 x u xy u2 x n nuh\\u00b7xjlx2 note that computing dy requires us to know both the x and y of the new point in practice we only know x if we assume however that we can estimate the learners bias at any x then we can also estimate the unknown value y yx biasx below i consider how to compute the bias estimate n n i x jl x jl y u 32 estimating bias for lwr the most common technique for estimating bias is crossvalidation standard crosscid173 validation however only gives estimates of the bias at our specific training points which are usually combined to form an average bias estimate this is sufficient if one assumes that the training distribution is representative of the test distribution which it isnt in query learning and if one is content to just estimate the bias where one already has training data which we cant be in the query selection problem we must be able to estimate the bias at all possible x box and draper 1987 suggest fitting a higher order model and measuring the difference for the experiments described in this paper this method yielded poor results two other biasestimation techniques however performed very well one method of estimating bias is by bootstrapping the residuals of the training points one produces a bootstrap sample of the learners residuals on the training data and adds them to the original predictions to create a synthetic training set by averaging predictions over a number of bootstrapped training sets and comparing the average prediction with that of the original predictor one arrives at a firstorder bootstrap estimate of the predictors bias connor 1993 efron and tibshirani 1993 it is known that this estimate is itself biased towards zero a standard heuristic is to divide the estimate by 0632 efron 1983 another method of estimating bias of a learner is by fitting its own crossvalidated residuals we first compute the crossvalidated residuals on the training examples these produce estimates of the learners bias at each of the training points we can then use these residuals as training examples for another learner again lwr to produce estimates of what the crossvalidated error would be in places where we dont have training data 4 empirical results in the previous two sections i have explained how having an estimate of dy and bias for a learner allows one to compute the learners change in bias given a new query and have shown how these estimates may be computed for a learner that uses locally weighted regression here i apply these results to two simple problems and demonstrate that they may actually be used to select queries that minimize the statistical bias and the error of the learner the problems involve learning the kinematics of a planar twojointed robot arm given the shoulder and elbow joint angles the learner must predict the tip position 422 41 bias estimates da cohn i tested the accuracy of the two bias estimators by observing their correlations on 64 reference inputs given 100 random training examples from the planar arm problem the bias estimates had a correlation with actual biases of 0852 for the bootstrap method and 0871 for the crossvalidation method 42 bias minimization i ran two sets of experiments using the biasminimizing criterion in conjunction with the bias estimation technique of the previous section on the planar arm problem the bias minimization criterion was used as follows at each time step the learner was given a set of 64 randomly chosen candidate queries and 64 uniformly chosen reference points it evaluated e x for each reference point given each candidate point and selected for its next query the candidate point with the smallest average e x over the reference points i compared the biasminimizing strategy using the crossvalidation and bootstrap estimation techniques against random sampling and the varianceminimizing strategy discussed in cohn et al 1996 on a sparc 10 with m training examples the average evaluation times per candidate per reference point were 58 016m jlseconds for the variance criterion 65 053m jlseconds for the crossvalidationbased bias criterion and 83 3 7m jlseconds for the bootstrapcid173 based bias criterion with 20x resampling to test whether the biasonly assumption was robust against the presence of noise 1 gaussian noise was added to the input values of the training data in all excid173 periments this simulates noisy position effectors on the arm and results in noncid173 gaussian noise in the output coordinate system in the first series of experiments the candidate shoulder and elbow joint angles were drawn uniformly over uo 271 uo 71 in unconstrained domains like this random sampling is a fairly good default strategy the bias minimization strategies still significantly outperform both random sampling and the variance minimizing strategy in these experiments see figure 1 1 10 g il 02 a c 10 random 3 variancemin o crossvalmin x bootstrapmin 200 100 10 0 300 trainlno set size i 1 10 g 0 10 1o1 2 ejnillizi o 10 103 rmiwngar iolmizing 400 300 200 1 00 trainino set size iheta 1 left mse as a function of number of noisy training examples for the figure 1 unconstrained arm problem errors are averaged over 10 runs for the bootstrap method and 15 runs for all others one run with the crossvalidationbased method was excluded when k failed to converge to a reasonable value center mse as a function of number of noisy training examples for the constrained arm problem the bias correction strategy discussed in section 21 does no better than the uncorcid173 rected varianceminimizing strategy and much worse than the biasminimization strategy right sample exploration trajectory in jointspace for the constrained arm problem explored according to the bias minimizing criterion in the second series of experiments candidates were drawn uniformly from a region minimizing statistical bias with queries 423 local to the previously selected query 01 \\u00b1 0217 o2 \\u00b1 0117 this corresponds to restricting the arm to local motions in a constrained problem such as this rancid173 dom sampling is a poor strategy both the bias and variancereducing strategies outperform it at least an order of magnitude further the biasminimization stratcid173 egy outperforms variance minimization by a large margin figure 1 figure 1 also shows an exploration trajectory produced by pursuing the biasminimizing critecid173 rion it is noteworthy that although the implementation in this case was a greedy onestep minimization the trajectory results in globally good exploration 5 discussion i have argued in this paper that in many situations selecting queries to minimize learner bias is an appropriate and effective strategy for active learning i have given empirical evidence that with a lwrbased learner and the examples considered here the strategy is effective even in the presence of noise beyond minimizing either bias or variance an important next step is to explicitly minimize them together the bootstrapbased estimate should facilitate this as it produces a complementary variance estimate with little additional computation by optimizing over both criteria simultaneously we expect to derive a criterion that that in terms of statistics is truly optimal for selecting queries references box g draper n 1987 empirical modelbuilding and response surfaces wiley new york cleveland w devlin s grosse e 1988 regression by local fitting journal of econometrics 37 87114 cohn d 1996 neural network exploration using optimal experiment design neural networks 9610711083 cohn d ghahramani z jordan m 1996 active learning with stacid173 tistical models journal of artificial inteligence research 4129145 connor j 1993 bootstrap methods in neural network time series prediction in j alspector et al eds proc of the int workshop on applications of neural networks to telecommunications lawrence erlbaum hillsdale nj dietterich t kong e 1995 errorcorrecting output coding corrects bias and variance in s prieditis and s russell eds proceedings of the 12th international conference on machine learning efron b 1983 estimating the error rate of a prediction rule some improvements on crossvalidation j amer statist assoc 78316331 efron b tibshirani r 1993 an introduction to the bootstrap chapman hall new york fedorov v 1972 theory of optimal experiments academic press new york geman s bienenstock e doursat r 1992 neural networks and the biasvariance dilemma neural computation 4 158 mackay d 1992 informationbased objective functions for active data seleccid173 tion neural computation 4 590604 paass g and kindermann j 1994 bayesian query construction for neucid173 ral network models in g tesauro et al eds advances in neural information processing systems 7 mit press plutowski m white h 1993 selecting concise training sets from clean data ieee transactions on neural networks 4 305318 schaal s atkeson c 1994 robot juggling an implementation of memorybased learning control systems 14 5771\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# 키워드를 추출하기 위해 full text를 list 형태로 corpora(말뭉치)에 적용해줍시다\n","corpora = data['full_text'].to_list()"],"metadata":{"id":"sqB_HZb_iyYX","executionInfo":{"status":"ok","timestamp":1747638006151,"user_tz":-540,"elapsed":4,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# TF-IDF을 이용한 키워드 추출 ✅\n","# 불용어(stop words) 리스트 불러오기\n","stopwords=get_stopwords_list(STOPWORD_PATH)"],"metadata":{"id":"5n5hZ3LjoAzc","executionInfo":{"status":"ok","timestamp":1747638006195,"user_tz":-540,"elapsed":38,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# 불용어를 포함하여 TF-IDF Vectorizer 초기화하기\n","# smooth_idf=True는 log(IDF) 계산 시 1을 더해 0으로 나누는 것 방지해주세요!\n","vectorizer = TfidfVectorizer(stop_words=stopwords, smooth_idf=True)\n","\n","# 말뭉치(corpora)로부터 단어 사전(vocabulary) 생성하기\n","# 앞의 10개 문서는 테스트용으로 제외하고 학습에 사용하기\n","vectorizer.fit(corpora[10:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"G-psgpG3i2p1","outputId":"9a1c28af-7559-46b8-c368-ac8c229a15c9","executionInfo":{"status":"ok","timestamp":1747638085974,"user_tz":-540,"elapsed":50459,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TfidfVectorizer(stop_words=['ain', 'hadst', 'stopped', 'outs', 'latterest',\n","                            'yond', 'since', 'abover', 'sometimes', 'uponed',\n","                            'tilled', 'whosoever', 'username', 'inwarder',\n","                            'woulding', 'downs', 'how', 'hither', 'ups', 'till',\n","                            'because', 'doing', 'four', 'everybody', 'my',\n","                            'get', 'hoo', 'whereby', 'frae', 'provides', ...])"],"text/html":["<style>#sk-container-id-1 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: #000;\n","  --sklearn-color-text-muted: #666;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-1 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-1 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-1 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-1 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-1 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-1 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-1 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-1 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: flex;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","  align-items: start;\n","  justify-content: space-between;\n","  gap: 0.5em;\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label .caption {\n","  font-size: 0.6rem;\n","  font-weight: lighter;\n","  color: var(--sklearn-color-text-muted);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-1 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-1 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-1 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-1 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-1 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-1 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 0.5em;\n","  text-align: center;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-1 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-1 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(stop_words=[&#x27;ain&#x27;, &#x27;hadst&#x27;, &#x27;stopped&#x27;, &#x27;outs&#x27;, &#x27;latterest&#x27;,\n","                            &#x27;yond&#x27;, &#x27;since&#x27;, &#x27;abover&#x27;, &#x27;sometimes&#x27;, &#x27;uponed&#x27;,\n","                            &#x27;tilled&#x27;, &#x27;whosoever&#x27;, &#x27;username&#x27;, &#x27;inwarder&#x27;,\n","                            &#x27;woulding&#x27;, &#x27;downs&#x27;, &#x27;how&#x27;, &#x27;hither&#x27;, &#x27;ups&#x27;, &#x27;till&#x27;,\n","                            &#x27;because&#x27;, &#x27;doing&#x27;, &#x27;four&#x27;, &#x27;everybody&#x27;, &#x27;my&#x27;,\n","                            &#x27;get&#x27;, &#x27;hoo&#x27;, &#x27;whereby&#x27;, &#x27;frae&#x27;, &#x27;provides&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(stop_words=[&#x27;ain&#x27;, &#x27;hadst&#x27;, &#x27;stopped&#x27;, &#x27;outs&#x27;, &#x27;latterest&#x27;,\n","                            &#x27;yond&#x27;, &#x27;since&#x27;, &#x27;abover&#x27;, &#x27;sometimes&#x27;, &#x27;uponed&#x27;,\n","                            &#x27;tilled&#x27;, &#x27;whosoever&#x27;, &#x27;username&#x27;, &#x27;inwarder&#x27;,\n","                            &#x27;woulding&#x27;, &#x27;downs&#x27;, &#x27;how&#x27;, &#x27;hither&#x27;, &#x27;ups&#x27;, &#x27;till&#x27;,\n","                            &#x27;because&#x27;, &#x27;doing&#x27;, &#x27;four&#x27;, &#x27;everybody&#x27;, &#x27;my&#x27;,\n","                            &#x27;get&#x27;, &#x27;hoo&#x27;, &#x27;whereby&#x27;, &#x27;frae&#x27;, &#x27;provides&#x27;, ...])</pre></div> </div></div></div></div>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# 생성된 단어 사전을 feature_names에 저장하기\n","feature_names = vectorizer.get_feature_names_out()"],"metadata":{"id":"VDQge5-PoHyS","executionInfo":{"status":"ok","timestamp":1747638092887,"user_tz":-540,"elapsed":537,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["result = []\n","# 앞의 10개 문서를 대상으로 반복하기\n","for doc in corpora[0:10]:\n","    df = {} # 하나의 문서 결과를 담을 딕셔너리 생성하기\n","    df['full_text'] = doc # 원본 문서 저장하기\n","    df['top_keywords'] = get_keywords(vectorizer, feature_names, doc) ## 상위 키워드 추출 후 저장하기\n","    result.append(df)"],"metadata":{"id":"BThX5Elei5Eb","executionInfo":{"status":"ok","timestamp":1747638094074,"user_tz":-540,"elapsed":89,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["final = pd.DataFrame(result)\n","final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"FcwRVmgcoT0_","outputId":"81f82eb4-472d-477b-895a-cff8cf8e858e","executionInfo":{"status":"ok","timestamp":1747638095848,"user_tz":-540,"elapsed":115,"user":{"displayName":"‎팽소원(자연과학대학 화학생명분자과학부)","userId":"08641470013950608952"}}},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           full_text  \\\n","0  573 bit serial neural networks alan f murray a...   \n","1  1 connectivity versus entropy yaser s abumosta...   \n","2  278 the hopfield model with mul tilevel neuron...   \n","3  442 alan lapedes robert farber theoretical div...   \n","4  740 spatial organization of neural nenorks a p...   \n","5  775 a neuralnetwork solution to the concentrat...   \n","6  642 learning by st ate recurrence detecfion br...   \n","7  554 stability results for neural networks a n ...   \n","8  804 introduction to a system for implementing ...   \n","9  474 optimiza non with artificial neural networ...   \n","\n","                                        top_keywords  \n","0  [synaptic, bit, vlsi, activation, state, array...  \n","1  [v2, h2k, 2n, en2, environment, neuron, h2, ed...  \n","2  [qnn, neurons, hopfields, neuron, hopfield, ca...  \n","3  [bumps, net, bump, eqn, layer, hidden, output,...  \n","4  [queueing, network, stimulations, cells, nodes...  \n","5  [sites, neurons, assignment, subarray, site, a...  \n","6  [recurrence, aseace, failure, state, pole, ase...  \n","7  [equilibrium, stability, attraction, subsystem...  \n","8  [processors, processor, simd, connections, tim...  \n","9  [dipole, settling, eq, comer, dt, method, extr...  "],"text/html":["\n","  <div id=\"df-f111126b-5ccb-4da5-b970-d949a04be16a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>full_text</th>\n","      <th>top_keywords</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>573 bit serial neural networks alan f murray a...</td>\n","      <td>[synaptic, bit, vlsi, activation, state, array...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1 connectivity versus entropy yaser s abumosta...</td>\n","      <td>[v2, h2k, 2n, en2, environment, neuron, h2, ed...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>278 the hopfield model with mul tilevel neuron...</td>\n","      <td>[qnn, neurons, hopfields, neuron, hopfield, ca...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>442 alan lapedes robert farber theoretical div...</td>\n","      <td>[bumps, net, bump, eqn, layer, hidden, output,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>740 spatial organization of neural nenorks a p...</td>\n","      <td>[queueing, network, stimulations, cells, nodes...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>775 a neuralnetwork solution to the concentrat...</td>\n","      <td>[sites, neurons, assignment, subarray, site, a...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>642 learning by st ate recurrence detecfion br...</td>\n","      <td>[recurrence, aseace, failure, state, pole, ase...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>554 stability results for neural networks a n ...</td>\n","      <td>[equilibrium, stability, attraction, subsystem...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>804 introduction to a system for implementing ...</td>\n","      <td>[processors, processor, simd, connections, tim...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>474 optimiza non with artificial neural networ...</td>\n","      <td>[dipole, settling, eq, comer, dt, method, extr...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f111126b-5ccb-4da5-b970-d949a04be16a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f111126b-5ccb-4da5-b970-d949a04be16a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f111126b-5ccb-4da5-b970-d949a04be16a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-af2dc878-6327-444c-9db4-34d550bd0704\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af2dc878-6327-444c-9db4-34d550bd0704')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-af2dc878-6327-444c-9db4-34d550bd0704 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_0286d069-7cfc-4715-9549-19ccbfaf0aaf\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_0286d069-7cfc-4715-9549-19ccbfaf0aaf button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('final');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"final","summary":"{\n  \"name\": \"final\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"804 introduction to a system for implementing neural net connections on simd architectures sherryl tomboulian institute for computer applications in science and engineering nasa langley research center hampton va 23665 abstract neural networks have attracted much interest recently and using parallel architectures to simulate neural networks is a natural and necessary applicacid173 tion the simd model of parallel computation is chosen because systems of this type can be built with large numbers of processing elements however such systems are not naturally suited to generalized communication a method is proposed that allows an implementation of neural network connections on massively parallel simd architectures the key to this system is an algorithm that allows the formation of arbitrary connections between the neurons a feature is the ability to add new connections quickly it also has error recovcid173 ery ability and is robust over a variety of network topologies simulations of the general connection system and its implementation on the connection macid173 chine indicate that the time and space requirements are proportional to the product of the average number of connections per neuron and the diameter of the interconnection network introduction neural networks hold great promise for biological research artificial intellicid173 gence and even as general computational devices however to study systems in a realistic manner it is highly desirable to be able to simulate a network with tens of thousands or hundreds of thousands of neurons this suggests the use of parallel hardware the most natural method of exploiting parallelism would have each processor simulating a single neuron consider the requirements of such a system there should be a very large number of processing elements which can work in parallel the computation that occurs at these elements is simple and based on local data the processing elements must be able to have connections to other elements all connections in the system must be able to be traversed in parallel connections must be added and deleted dynamically given current technology the only type of parallel model that can be concid173 structed with tens of thousands or hundreds of thousands of processors is an simd architecture in exchange for being able to build a system with so many processors there are some inherent limitations simd stands for single instruccid173 tion multiple datal which means that all processors can work in parallel but they must do exactly the same thing at the same time this machine model is sufficient for the computation required within a neuron however in such a system it is difficult to implement arbitrary connections between neurons the connection machine2 provides such a model but uses a device called the router this work was supported by the national aeronautics and space administration under nasa constract no nasl180107 while the author was in residence at icase \\u00a9 american institute of physics 1988 805 to deliver messages the router is a complex piece of hardware that uses signifcid173 icant chip area and without the additional hardware for the router a machine could be built with significantly more processors since one of the objectives is to maximize the number of neurons it is desirable to eliminate the extra cost of a hardware router and instead use a software method existing software algorithms for forming connections on simd machines are not sufficient for the requirements of a neural networks they restrict the form of graph neural network that can be embedded to permutations\\u00b7\\u00b7 or sorts56combinedwith7 the methods are network specific and adding a new conneccid173 tion is highly time consuming the software routing method presented here is a unique algorithm which alcid173 lows arbitrary neural networks to be embedded in machines with a wide variety of network topologies the advantages of such an approach are numerous a new connection can be added dynamically in the same amount of time that it takes to perform a parallel traversal of all connections the method has error recovery ability in case of network failures this method has relationships with natural neural models when a new connection is to be formed the two neurons being connected are activated and then the system forms the connection withcid173 out any knowledge of the address of the neuronprocessors and without any instruction as to the method of forming the connecting path the connections are entirely distributed a processor only knows that connections pass through it it doesnt know a connections origin or final destination some neural network applications have been implemented on massively parcid173 allel architectures but they have run into restrictions due to communication an implementation on the connection machines discovered that it was more desirable to cluster processors in groups and have each processor in a group represent one connection rather than having one processor per neuron because the router is designed to deliver one message at a time from each processor this approach is contrary with the more natural paradigm of having one processor represent a neuron the mpp 9 a massively parallel architecture with procescid173 sors arranged in a mesh has been used to implement neural nets10 but because of a lack of generalized communication software the method for edge conneccid173 tions is a regular communication pattern with all neurons within a specified distance this is not an unreasonable approach since within the brain neurons are usually locally connected but there is also a need for longer connections between groups of neurons the algorithms presented here can be used on both machines to facilitate arbitrary connections with an irregular number of connections at each processor machine model as mentioned previously since we desire to build a system with an large number of processing elements the only technology currently available for buildcid173 ing such large systems is the simd architecture model in the simd model there is a single control unit and a very large number of slave processors that can execute the same instruction stream simultaneously it is possible to disable some processors so that only some execute an instruction but it is not possible to have two processor performing different instructions at the same time the processors have exclusively local memory which is small only a few thousand bits and they have no facilities for local indirect addressing in this scheme an instruction involves both a particular operation code and the local memory 806 address all processors must do this same thing to the same areas of their local memory at the same time the basic model of computation is bitserial each instruction operates on a bit at a time to perform multiple bit operations such as integer addition requires several instructions this model is chosen because it requires less hardware logic and so would allow a machine to be built with a larger number of processors than could otherwise be achieved with a standard wordoriented approach of course the algorithms presented here will also work for machines with more complex instruction abilities the machine model described satisfies the minimal requirements an important requirement for connection formation is that the processors are connected in some topology for instance the processors might be concid173 nected in a grid so that each processor has a north south east and west neighbor the methods presented here work for a wide variety of network topologies the requirements are 1 there must be some path between any two proeessors 2 every neighbor ink must be bidirectional ie if a is a neighbor of b then b must be a neighbor of a 3 the neighbor relations between processors must have a consistent invertible labeling a more precid173 cise definition of the labeling requirements can be found in 11 it suffices that most networks 12 including grid hypercube cube connected cycles1s shuffle exchange14 and mesh of trees15 are admissible under the scheme additional requirements are that the processors be able to read from or write to their neighbors memories and that at least one of the processors acts as a serial port between the processors and the controller computational requirements the machine model described here is sufficient for the computational recid173 quirements of a neuron adopt the paradigm that each processor represents one neuron while several different models of neural networks exist with slightly different features they are all fairly well characterized by computing a sum or product of the neighbors values and if a certain threshold is exceeded then the processor neuron will fire le activate other neurons the machine model described here is more efficient at boolean computation such as described by mcculloch and pitts16 since it is bit serial neural net models using integers and floating point arithmetic 1718 will also work but will be somewhat slower since the time for computation is proportional to the number of bits of the operands the only computational difficulty lies in the fact that the system is simd which means that the processes are synchronous for some neural net models this is sufficient18 however others require asynchronous behavior 17 this can easily be achieved simply by turning the processors on and off based on a speccid173 ified probability distribution for a survey of some different neural networks see 19 connection assumptions many models of neural networks assume fully connected systems this model is considered unrealistic and the method presented here will work better for models that contain more sparsely connected systems while the method will work for dense connections the time and space required is proportional to 807 the number of edges and becomes prohibitively expensive other than the sparse assumptions there are no restrictions to the topocid173 logical form of the network being simulated for example multiple layered systems slightly irregular structures and completely random connections are all handled easily the system does function better if there is locality in the neural network these assumptions seem to fit the biological model of neurons the connection formation method a fundamental part of a neural network implementation is the realization of the connections between neurons this is done using a software scheme first precid173 sented in 1120 the original method was intended for realizing directed graphs in simd architectures since a neural network is a graph with the neurons being vertices and the connections being arcs the method maps perfectly to this system henceforth the terms neuron and vertex and the terms arc and connection will be used interchangeably the software system presented here for implementing the connections has several parts each processor will be assigned exactly one neuron of course some processors may be free or unallocated but even free processor parcid173 ticipate in the routing process each connection will be realized as a path in the topology of processors a labeling of these paths in time and space is introduced which allows efficient routing algorithms and a setup strategy is introduced that allows new connections to be added quickly the standard computer science approach to forming the connection would be to store the addresses of the processors to which a given neuron is connected then using a routing algorithm messages could be passed to the processors with the specified destination however the simd architecture does not lend itself to standard message passing schemes because processors cannot do indicid173 rect addressing so buffering of values is difficult and costly instead a scheme is introduced which is closer to the natural neuronsynapse structures instead of having an address for each connection the connection is actually represented as a fixed path between the processors using time as a virtual dimension the path a connection takes through the network of procid173 cessors is statically encoded in the local memories of the neurons that it passes through to achieve this the following data structures will be resident at each processor allocated boolean flag indicating whether this processor is assigned a vertex neuron in the graph vertex label label of graph vertex hasneighborl neighborlimit flag indicating the existence of neighbors arc path information slotsl t of neuron startnew arc starts here directiondirection to send l neighborlimitfree endarc ends here arc labellabel of arc 808 the allocated and vertex label field indicates that the processor has been assigned a vertex in the graph neuron the has neighbor field is used to indicate whether a physical wire exists in the particular direction it allows irregular network topologies and boundary conditions to be supported the slots data structure is the key to realizing the connections it is used to instruct the processor where to send a message and to insure that paths are constructed in such a way that no collisions will occur slots is an array with t elements the value t is called the time quantum traversing all the edges of the embedded graph in parallel will take a certain amount of time since messages must be passed along through a sequence of neighboring processors forming these parallel connections will be considered an uninterruptable operation which will take t steps the slots array is used to tell the processors what they should do on each relative time position within the time quantum one of the characteristics of this algorithm is that a fixed path is chosen to represent the connection between two processors and once chosen it is never changed for example consider the grid below abcde fghij i i i i i i i i i i i i i i i fig 1 grid example if there is an arc between a and h there are several possible paths eastcid173 eastsouth eastsoutheast and southeasteast only one of these paths will be chosen between a and h and that same path will always be used besides being invariant in space paths are also invariant in time as stated above traversal is done within a time quantum t paths do no have to start on time 1 but can be scheduled to start at some relative offset within the time quantum once the starting time for the path has been fixed it is never changed another requirement is that a message can not be buffered it must proceed along the specified directions without interruption for example if the path is of length 3 and it starts at time 1 then it will arrive at time 4 alternatively if it starts at time 2 it will arrive at time 5 further it is necessary to place the paths so that no collisions occur that is no two paths can be at the same processor at the same instant in time essentially time adds an extra dimension to the topology of the network and within this spacecid173 time network all data paths must be nonconflicting the rules for constructing paths that fulfill these requirements are listed below \\u2022 at most one connection can enter a processor at a given time and at most one connection can leave a processor at a given time it is possible to have both one coming and one going at the same time note that this does not mean that a processor can have only one connection it means that it can have only one connection during anyone of the t time steps it can have as many as t connections going through it \\u2022 any path between two processors uv reprsenting a connection must consist of steps at contiguous times for example if the path from procid173 cessor u to processor v is ufghv then if the arc from uf is assigned time 1 fg must have time 2 gh time 3 and hv time 4 likewise if uf occurs at time 5 then arc hv will occur time 8 809 when these rules are used when forming paths the slots structure can be used to mark the paths each path goes through neighboring processors at successive time steps for each of these time steps the dffiection field of the slots structure is marked telling the processor which direction it should pass a message if it receives it on that time slots serves both to instruct the processors how to send messages and to indicate that a processor is busy at a certain time slot so that when new paths are constructed it can be guaranteed that they wont conflict with current paths consider the following example suppose we are given the directed graph with vertices abcd and edges a c b cb d and d a this is to be done where abc and d have been assigned to successive elements of a linear array a linear array in not a good network for this scheme but is a convenient source of examples loical connections faa 2 giapb example abcd are successive members in a linear array 1234 abcd first a c can be completed with the map easteast so slotsa1direction e slotsb2directione slotsc2end 1 bc can be done with the map east it can start at time 1 since slotsb 1 direction and slotsc 1end are free bd goes through c then to d its map is easteast b is occupied at time 1 and 2 it is free at time 3 so slotsb 3direction e slotsc 4direction e slotsd 4end 1 da must go through cba using map westwestwest d is free on time 1 c is free on time 2 but b is occupied on time 3 d is free on time 2 but c is occupied on time 3 it can start from d at time 3 slotsd 3direction w slotsc 4 direction w slotsb 5direction w slots a 5end1 810 every processor acts as a conduit for its neighbors messages no processor knows where any message is going to or coming from but each processor knows what it must do to establish the local connections the use of contiguous time slots is vital to the correct operation of the system if all edgepaths are established according to the above rules there is a simple method for making the connections the paths have been restricted so that there will be no collisions and paths directions use consecutive time slots hence if all arcs at time i send a message to their neighbors then each processor is guaranteed no more than 1 message coming to it the end of a path is specified by setting a separate bit that is tested after each message is received a separate start bit indicates when a path starts the start bit is needed because the slots array just tells the processors where to send a message regardless of how that message arrived the start array indicates when a message originates as opposed to arriving from a neighbor the following algorithm is basic to the routing system for i time 1 to t forall processors if an arc starts or is passing through at this time if sloti start 1 or active 1 for j1 to neighborlimit if slotidirection j write message bit to inbox of neighbor j set active 0 forall processor that just received a message if endi move inbox to messagedestination else move inbox to outbox set active bit 1 this code follows the method mentioned above the time slots are looped through and the messages are passed in the appropriate directions as specified in the slots array two bits inbox and outbox are used for message passing so that an outgoing message wont be overwritten by an incoming message before it gets transferred the inner loop lor j 1 to neighbor limit checks each of the possible neighbor directions and sends the message to the correct neighbor for instance in a grid the neighbor limit is 4 for north south east and west neighbors the time complexity of data movement is ot times neighborlimi t setting up connections one of the goals in developing this system was to have a method for adding new connections quickly paths are added so that they dont conflict with any previously constructed path once a path is placed it will not be rerouted 811 by the basic placement algorithm it will always start at the same spot at the same time the basic idea of the method for placing a connection is to start from the source processor and in parallel examine all possible paths outward from it that do not conflict with preestablished paths and which adhere to the sequential time constraint as the trial paths are flooding the system they are recorded in temporary storage at the end of this deluge of trial paths all possible paths will have been examined if the destination processor has been reached then a path exists under the current timespace restrictions using the stored information a path can be backtraced and recorded in the slots structure this is similar to the leemoore routing algorithm21 \\u202222 for finding a path in a system but with the sequential time restriction for example suppose that the connection uv is to be added first it is assumed that processors for u and v have already been determined otherwise as a simplification assume a random allocation from a pool of free procescid173 sors a parallel breadthfirst search will be performed starting from the source processor during the propagation phase a processor which receives a message checks its slots array to see if they are busy on that time step if not it will propagate to its neighbors on the next time step for instance suppose a trial path starts at time 1 and moves to a neighboring processor but that neighbor is already busy at time 1 as can be seen by examining the directionslot since a path that would go through this neighbor at this time is not legal the trial path would commit suicide that is it stops propagating itself if the procid173 cessor slot for time 2 was free the trial path would attempt to propagate to all of its neighbors at time 3 using this technique paths can be constructed with essentially no knowlcid173 edge of the relative locations of the neurons being connected or the underlycid173 ing topology variations on the outlined method such as choosing the shortest path can improve the choice of paths with very little overhead if the entire netcid173 work were known ahead of time an offline method could be used to construct the paths more efficiently work on offline methods is underway however the simple elegance of this basic method holds great appeal for systems that change slowly over time in unpredictable ways performance adding an edge assuming one can be added deleting any set of edges or traversing all the edges in parallel all have time complexity ot x neighborcid173 limit if it is assumed that neighbor limit is a small constant then the comcid173 plexity is ot since t is related both to the time and space needed it is a crucial factor in determining the value of the algorithms presented some analytic bounds on t were presented inll but it is difficult to get a tight bound on t for general interconnection networks and dynamically changing graphs a simulator was constructed to examine the behavior of the algorithms besides the simulated data the algorithms mentioned were actually implemented for the connection machine the data produced by the simulator is consistent with that produced by the real machine the major result is that the size of t appears proportional to the average degree of the graph times the diameter of the interconnection network20 \\u2022 812 further research this paper has been largely concerned with a system that can realize the connections in a neural network when the two neurons to be joined have been activated the tests conducted have been concerned with the validity of the method for implementing connections rather than with a full simulation of a neural network clearly this is the next step a natural extension of this method is a system which can form its own connections based solely on the activity of certain neurons without having to explicitly activate the source and destination neurons this is an exciting avenue and further results should be forthcoming another area of research involves the formation of branching paths the current method takes an arc in the neural network and realizes it as a unique path in spacetime a variation that has similarities to dendritic structure would allow a path coming from a neuron to branch and go to several target neurons this extension would allow for a much more economical embedding system simulations are currently underway conclusions a method has been outlined which allows the implementation of neural nets connections on a class of parallel architectures which can be constructed with very large numbers of processing elements to economize on hardware so as to maximize the number of processing element buildable it was assumed that the processors only have local connections no hardware is provided for communicid173 cation some simple algorithms have been presented which allow neural nets with arbitrary connections to be embedded in simd architectures having a vacid173 riety of topologies the time for performing a parallel traversal and for adding a new connection appears to be proportional to the diameter of the topology times the average number of arcs in the graph being embedded in a system where the topology has diameter ologn and where the degree of the graph being embedded is bounded by a constant the time is apparently ologn this makes it competitive with existing methods for simd routing with the advantages that there are no apriori requirements for the form of the data and the topological requirements are extremely general also with our approach new arcs can be added without reconfiguring the entire system the simplicity of the implementation and the flexibility of the method suggest that it could be an important tool for using simd architectures for neural network simulation bibliography 1 mj flynn some computer organizations and their effectiveness ieee trans comput vol c21 no9 pp 948960 2 w hillis the connection machine mit press cambridge mass 1985 3 d nassimi s sahni parallel algorithms to setup the benes permutation network proc workshop on interconnection networks for parallel and discid173 tributed processing april 1980 4 d nassimi s sahni benes network and parallel permutation algorithms ieee transactions on computers vol c30 no 5 may 1981 5 d nassimi s sahni parallel permutation and sorting algorithms and a 813 new generalized connection network jacm vol 29 no3 july 1982 pp 642667 6 ke batcher sorting networks and their applications the proceedings of afips 1968 sjcc 1968 pp 307314 7 c thompson generalized connection networks for parallel processor intercid173 communication ieee tran computers vol c no 27 dec 78 pp 11191125 8 nathan h brown jr neural network implementation approaches for the connection machine presented at the 1987 conference on neural information processing systems natural and synthetic 9 ke batcher design of a massively parallel processor ieee trans on computers sept 1980 pp 836840 10 hm hastings s waner neural nets on the mpp frontiers of massively parallel scientific computation nasa conference publication 2478 nasa goddard space flight center greenbelt maryland 1986 11 s tomboulian a system for routing arbitrary communication graphs on simd architectures doctoral dissertation dept of computer science duke university durham nc 12 t feng a survey of interconnection networks computer dec 1981 pp1227 13 f preparata and j vuillemin the cube connected cycles a versatile network for parallel computation comm acm vol 24 no 5 may 1981 pp 300309 14 h stone parallel processing with the perfect shuffle ieee trans comcid173 puters vol c no 20 feb 1971 pp 153161 15 t leighton parallel computation using meshes of trees proc intercid173 national workshop on graph theory concepts in computer science 1983 16 ws mcculloch and w pitts a logical calculus of the ideas imminent in nervous activity bulletin of mathematical biophysics vol 5 1943 pp115 133 17 jj hopfield neural networks and physical systems with emergent colcid173 lective computational abilities prot natl aca sci vol 79 april 1982 pp 25542558 18 t kohonen selforganization and associative memory springerverlag berlin 1984 19 rp lippmann an introduction to computing with neural nets ieee aasp apri11987 pp 422 20 s tomboulian a system for routing directed graphs on simd architeccid173 tures icase report no 8714 nasa langley research center hampton va 21 cy lee an algorithm for path connections and its applications ire trans elec comput vol eci0 sept 1961 pp 346365 22 e f moore shortest path through a maze a nnals of computation laboratory vol 30 cambridge ma harvard univ press 1959 pp285292\",\n          \"1 connectivity versus entropy yaser s abumostafa california institute of technology pasadena ca 91125 abstract how does the connectivity of a neural network number of synapses per neuron relate to the complexity of the problems it can handle measured by the entropy switching theory would suggest no relation at all since all boolean functions can be implemented using a circuit with very low connectivity eg using twoinput nand gates however for a network that learns a problem from examples using a local learning rule we prove that the entropy of the problem becomes a lower bound for the connectivity of the network introduction the most distinguishing feature of neural networks is their ability to sponcid173 taneously learn the desired function from training samples ie their ability to program themselves clearly a given neural network cannot just learn any function there must be some restrictions on which networks can learn which functions one obvious restriction which is independent of the learning aspect is that the network must be big enough to accommodate the circuit complexcid173 ity of the function it will eventually simulate are there restrictions that arise merely from the fact that the network is expected to learn the function rather than being purposely designed for the function this paper reports a restriction of this kind the result imposes a lower bound on the connectivity of the network numcid173 ber of synapses per neuron this lower bound can only be a consequence of the learning aspect since switching theory provides purposely designed circuits of low connectivity eg using only twoinput nand gates capable of implecid173 menting any boolean function 12 it also follows that the learning mechanism must be restricted for this lower bound to hold a powerful mechanism can be \\u00a9 american institute of physics 1988 2 designed that will find one of the lowconnectivity circuits perhaps byexhauscid173 tive search and hence the lower bound on connectivity cannot hold in general indeed we restrict the learning mechanism to be local when a training sample is loaded into the network each neuron has access only to those bits carried by itself and the neurons it is directly connected to this is a strong assumption that excludes sophisticated learning mechanisms used in neuralnetwork models but may be more plausible from a biological point of view the lower bound on the connectivity of the network is given in terms of the entropy of the environment that provides the training samples entropy is a quantitative measure of the disorder or randomness in an environment or equivcid173 alently the amount of information needed to specify the environment there are many different ways to define entropy and many technical variations of this concept 3 in the next section we shall introduce the formal definitions and results but we start here with an informal exposition of the ideas involved the environment in our model produces patterns represented by n bits x xl \\u2022\\u2022\\u2022 x n pixels in the picture of a visual scene if you will only h different patterns can be generated by a given environment where h 2n the entropy is essentially log2 h no knowledge is assumed about which patterns the encid173 vironment is likely to generate only that there are h of them in the learning process a huge number of sample patterns are generated at random from the environment and input to the network one bit per neuron the network uses this information to set its internal parameters and gradually tune itself to this particular environment because of the network architecture each neuron knows only its own bit and at best the bits of the neurons it is directly connected to by a synapse hence the learning rules are local a neuron does not have the benefit of the entire global pattern that is being learned after the learning process has taken place each neuron is ready to perform a function defined by what it has learned the collective interaction of the functions of the neurons is what defines the overall function of the network the main result of this paper is that roughly speaking if the connectivity of the network is less than the entropy of the environment the network cannot learn about the environment the idea of the proof is to show that if the connectivity is small the final function of each neuron is independent of the environment and hence to conclude that the overall network has accumulated no information about the environment it is supposed to learn about formal result a neural network is an undirected graph the vertices are the neurons and the edges are the synapses label the neurons 1 n and define kn c i n to be the set of neurons connected by a synapse to neuron n together with neuron n itself an environment is a subset e c oin each x e e is a sample 3 from the environment during learning xl xn the bits of x are loaded into the neurons 1 n respectively consider an arbitrary neuron nand relabel everything to make kn become i k thus the neuron sees the first k coordinates of each x since our result is asymptotic in n we will specify k as a function of n k an where a an satifies limnoo an 00 0 00 1 since the result is also statistical we will consider the ensemble of environments e eenecoin i lelh where h 2n and 3 3n satifies limnoo 3n 30 0 30 1 the probability distribution on e is uniform any environment e e e is as likely to occur as any other the neuron sees only the first k coordinates of each x generated by the environment e for each e we define the function n oik o 12\\u00b7\\u00b7 where nal ak ix eel xle ale for k 1 ki and the normalized version the function v describes the relative frequency of occurrence for each of the 2k binary vectors xl xk as x xl \\u2022\\u2022\\u2022 xn runs through all h vectors in e in other words v specifies the projection of e as seen by the neuron clearly veal 0 for all a e olk and laeolk veal 1 corresponding to two environments el and e2 we will have two functions vi and v2 it vi is not distinguishable from v2 the neuron cannot tell the difference between el and e2 the distinguishability between vi and v2 can be measured by iv1a v2a i 1 dvlv2 2 2 aeolk the range of dvb v2 is 0 dvl v2 1 where 0 corresponds to complete indistinguishability while 1 corresponds to maximum distinguishability we are now in a position to state the main result let el and e2 be independently selected environments from e according to the uniform probability distribution dvl v2 is now a random variable and we are interested in the expected value edvl v2 the case where edvb v2 0 corresponds to the neuron getting no information about the environment while the case where edvb v2 1 corresponds to the neuron getting maximum information the theorem predicts in the limit one of these extremes depending on how the connectivity 00 compares to the entropy 30 4 theorem 1 h q o po then limn co e dvi v2 1 2 h q o po then limn co e dv v2 o the proof is given in the appendix but the idea is easy to illustrate inforcid173 mally suppose h 2k 10 corresponding to part 2 of the theorem for most environments e e e the first k bits of x e e go through all 2k possible valcid173 ues approximately 210 times each as x goes through all h possible values once therefore the patterns seen by the neuron are drawn from the fixed ensemble of all binary vectors of length k with essentially uniform probability distribution ie v is the same for most environments this means that statistically the neuron will end up doing the same function regardless of the environment at hand what about the opposite case where h 2k 10 corresponding to part lof the theorem now with only 2k 10 patterns available from the environment the first k bits of x can assume at most 2k 10 values out of the possible 2k values a binary vector of length k can assume in principle furthermore which values can be assumed depends on the particular environment at hand ie v does depend on the environment therefore although the neuron still does not have the global picture the information it has says something about the environment acknowledgement this work was supported by the air force office of scientific research under grant afosr860296 appendix in this appendix we prove the main theorem we start by discussing some basic properties about the ensemble of environments e since the probability distribution on e is uniform and since ie i e we have pre 2n1 h which is equivalent to generating e by choosing h elements x e oln with uniform probability without replacement it follows that h prx e e 2n 5 h hl prxl e e x2 e e 2n x 2n 1 and so on the functions n and v are defined on kbit vectors the statistics of na a random variable for fixed a is independent of a prnat m prna2 m which follows from the symmetry with respect to each bit of a the same holds for the statistics of va the expected value ena h2k h objects going into 2k cells hence eva 2 k we now restate and prove the theorem theorem 1 if ao po then limnoo e dvt v2 1 2 if ao po then limnoo e dvt v2 0 proof we expand e dvt v2 as follows where nl and n2 denote nlo \\u00b7\\u00b70 and n20\\u00b7\\u00b7 \\u00b70 respectively and the last step follows from the fact that the statistics of nla and n2a is independent of a therefore to prove the theorem we evaluate elnl n21 for large n 1 assume ao po let n denote no\\u00b7\\u00b7\\u00b7 0 and consider prn 0 for n to be zero all 2n k strings x of n bits starting with k os must not be in the environment e hence prn 0 1 1 h 2n h 2n 1 1 h 2n 2n k 1 where the first term is the probability that 0\\u00b7 \\u00b700 f e the second term is the 6 probability that o\\u00b7 01 f given that o\\u00b7 00 f and so on 1 2n h2n k nk 1 h2 n1 2k1 2n k 1 2h2n2n k 1 2h2n 2n k 1 2h2k hence prnl 0 prn2 0 prn 0 1 2h2k \\u2022 however enl e n2 h2k therefore elnl n2 llprnl in2 jli jl ioo l l prnl iprn2 j ii jl ioo l prnl 0prn2 jj 0 l prnl iprn2 oi io which follows by throwing away all the terms where neither i nor j is zero the term where both i an j are zero appears twice for convenience but this term is zero anyway prnl 0en2 prn2 oenl 21 2h2k h2k substituting this estimate in the expression for edvb v2 we get edvl v2 2h elnl n21 2k x 21 2h2 k h2k 2k 2h 1 2h2 k 1 2 x 28an since a o 130 by assumption this lower bound goes to 1 as n goes to infinity since 1 is also an upper bound for d vi v2 and hence an upper bound for the expected value edvl v2 limnoo edvl v2 must be 1 7 2 assume a o po consider elnl n21 e inl h2k n2 h2 k i enl h2 k in2 h2ki enl h2 k i eln2 h2k i 2eln h2ki to evaluate eln h2 k i we estimate the variance of n and use the fact that eln h2 k i jvarn recall that h2k en\\u00bb since varn en2 en2 we need an estimate for en2 we write n eeolnk 6 where 6 \\u2022 if 0 \\u00b7oa e e\\u00b7 1 0 otherwise in this notation en2 can be written as en2 e i i 66t eolnk beolnk i l e66t eolnk beolnk for the diagonal terms a b e66 pr6 1 h2n there are 2n k such diagonal terms hence a total contribution of 2n k x h2 n h2 k to the sum for the offdiagonal terms a b e66b pr 6 16b 1 pr6 1pr6b 116 1 h hl x 2n 2n1 there are 2n k 2n k 1 such offdiagonal terms hence a total contribution of 2n k2 n k 1 x 2n1 h2k2 21 to the sum putting the contributions 8 from the diagonal and offdiagonal terms together we get en2 h2k h2k2 2n 1 varn en2 en2 2n h2 k h2 k 2 1 h2 k h2k h2 k2 2n 1 1 h2 k h2k 1 2n 1 2h2k the last step follows since h2k is much smaller than 2n 1 therefore eln h2 k i vvarn 2h2 ki substituting this estimate in the expression for e d vb v2 we get 1 edvb v2 2h elnl n21 2k 2k 2h x 2eln h2 ki 2k 1 2h x 2 x 2h2ki 2k 2 h v2 x 2qn since a o po by assumption this upper bound goes to 0 as n goes to infinity since 0 is also a lower bound for dvb v2 and hence a lower bound for the expected value edvb v2 limnoo edvb v2 must be o \\u2022 references 1 y abumostafa neural networks for computing alp conference procid173 ceedings 151 neural networks for computing j denker ed pp 16 1986 2 z kohavi switching and finite automata theory mcgrawhill 1978 3 y abumostafa the complexity of information extraction ieee trans on information theory vol it32 pp 513525 july 1986 4 y abumostafa complexity in neural systems in analog vlsi and neural systems by c mead addisonwesley 1988\",\n          \"775 a neuralnetwork solution to the concentrator assignnlent problem gene a tagliarini edward w page department of computer science clemson university clemson sc 296341906 abstract networks of simple analog processors having neuronlike properties have been employed to compute good solutions to a variety of optimization probcid173 lems this paper presents a neuralnet solution to a resource allocation probcid173 lem that arises in providing local access to the backbone of a widearea comcid173 munication network the problem is described in terms of an energy function that can be mapped onto an analog computational network simulation results characterizing the performance of the neural computation are also presented introduction this paper presents a neuralnetwork solution to a resource allocation problem that arises in providing access to the backbone of a communication network 1 in the field of operations research this problem was first known as the warehouse location problem and heuristics for finding feasible suboptimal solutions have been developed previously2 3 more recently it has been known as the multifacility location problem4 and as the concentrator assignment probcid173 lem1 the hopfield neural network model the general structure of the hopfield neural network model5 \\u2022 67 is illuscid173 trated in fig 1 neurons are modeled as amplifiers that have a sigmoid input output curve as shown in fig 2 synapses are modeled by permitting the outcid173 put of any neuron to be connected to the input of any other neuron the strength of the synapse is modeled by a resistive connection between the output of a neuron and the input to another the amplifiers provide integrative analog summation of the currents that result from the connections to other neurons as well as connection to external inputs to model both excitatory and inhibitory synaptic links each amplifier provides both a normal output v and an inverted output v the normal outputs range between 0 and 1 while the inverting amcid173 plifier produces corresponding values between 0 and 1 the synaptic link becid173 tween the output of one amplifier and the input of another is defined by a conductance tij which connects one of the outputs of amplifier j to the input of amplifier i in the hopfield model the connection between neurons i and j is made with a resistor having a value rij 1rrij to provide an excitatory synapcid173 tic connection positive tij the resistor is connected to the normal output of this research was supported by the us army strategic defense command \\u00a9 american institute of physics 1988 776 13 14 inputs vi v4 v3 v2 outputs fig 1 schematic for a simplified hopfield network with four neurons 1 v o u o u fig 2 amplifier inputoutput relationship amplifier j to provide an inhibitory connection negative tij the resistor is connected to the inverted output of amplifier j the connections among the neurons are defined by a matrix t consisting of the conductances tij hop field has shown that a symmetric t matrix tij tji whose diagonal entries are all zeros causes convergence to a stable state in which the output of each amplifier is either 0 or 1 additionally when the amplifiers are operated in the highgain mode the stable states of a network of n neurons correspond to the local minima of the quantity n n e 112 l l jl il t\\u00b7vv\\u00b7 ij 1 j n l vi\\u00b7 i 1 1 where vi is the output of the ith neuron and ii is the externally supplied input to the ph neuron hopfield refers to e as the computational energy of the syscid173 tem the concentrator assignment problem consider a collection of n sites that are to be connected to m concentracid173 tors as illustrated in fig 3a the sites are indicated by the shaded circles and the concentrators are indicated by squares the problem is to find an assignment of sites to concentrators that minimizes the total cost of the assigncid173 ment and does not exceed the capacity of any concentrator the constraints that must be met can be summarized as follows a each site i i 1 2 n is connected to exactly one concentrator and 777 b each concentrator j j 1 2 m is connected to no more than kj sites where kj is the capacity of concentrator d figure 3b illustrates a possible solution to the problem represented in fig 3a 0 \\u2022 \\u2022 \\u2022 \\u2022 \\u2022 \\u2022 \\u2022 \\u2022 0 \\u2022 \\u2022 0 \\u2022 \\u2022 0 o concentrators \\u2022 sites a siteconcentrator map b possible assignment fig 3 example concentrator assignment problem if the cost of assigning site i to concentrator j is cij then the total cost of a particular assignment is total cost n m l l jl il x \\u00b7\\u00b7 c\\u00b7\\u00b7 ij ij 2 where xij 1 only if we actually decide to assign site i to concentrator j and is 0 otherwise there are mn possible assignments of sites to concentrators that satisfy constraint a exhaustive search techniques are therefore impractical except for relatively small values of m and n the neural network solution this problem is amenable to solution using the hopfield neural network model the hopfield model is used to represent a matrix of possible assigncid173 ments of sites to concentrators as illustrated in fig 4 each square corresponds 778 s ites \\u2022 concentrators 1 m r r 1 ii 11 iii iii 2 i \\u2022 \\u2022 \\u2022 \\u2022 \\u2022 i the darkly shaded neu i iii 11 ii ii i ron corresponds to the hypothesis that site i n ii \\u2022 ii ii should be asigned to nl ii 1111111 slack n2 iii ii \\u2022 \\u2022 \\u2022 nk j ii 11 iii iii j concentrator j 2 j \\u2022 fig 4 concentrator assignment array to a neuron and a neuron in row i and column j of the upper n rows of the array represents the hypothesis that site i should be connected to concentrator j if the neuron in row i and column j is on then site i should be assigned to concentrator j if it is off site i should not be assigned to concentrator j the neurons in the lower subarray indicated as slack are used to implement individual concentrator capacity constraints the number of slack neurons in a column should equal the capacity expressed as the number sites which can be accommodated of the corresponding concentrator while it is not necessary to assume that the concentrators have equal capacities it was assumed here that they did and that their cumulative capacity is greater than or equal to the number of sites to enale the neurons in the network illustrated above to compute solucid173 tions to the concentrator problem the network must realize an energy function in which the lowest energy states correspond to the least cost assignments the energy function must therefore favor states which satisfy constraints a and b above as well as states that correspond to a minimum cost assignment the energy function is implemented in terms of connection strengths between neucid173 rons the following section details the construction of an appropriate energy function the energy function consider the following energy equation 2 e a l l y 1 m n 1 1 1 j 1j m nk\\u00b7 b l l j y k 2 j1 i1 ij j 779 3 m nkj c l l y 1 yij j1 i1 1j where yij is the output of the amplifier in row i and column j of the neuron matrix m and n are the number of concentrators and the number of sites respectively and kj is the capacity of concentrator j the first term will be minimum when the sum of the outputs in each row of neurons associated with a site equals one notice that this term influences only those rows of neurons which correspond to sites no term is used to coerce the rows of slack neurons into a particular state the second term of the equation will be minimum when the sum of the outputs in each column equals the capacity kj of the corresponding concentracid173 tor the presence of the kj slack neurons in each column allows this term to enforce the concentrator capacity restrictions the effect of this term upon the upper subarray of neurons those which correspond to site assignments is that no more than kj sites will be assigned to concentrator j the number of neurons to be turned on in column j is kj consequently the number of neucid173 rons turned on in column j of the assignment subarray will be less than or equal to kj the third term causes the energy function to favor the zero and one states of the individual neurons by being minimum when all neurons are in one or the other of these states this term influences all neurons in the network in summary the first term enforces constraint a and the second term enforces constraint b above the third term guarantees that a choice is actucid173 ally made it assures that each neuron in the matrix will assume a final state near zero or one corresponding to the xij term of the cost equation eq 2 after some algebraic rearrangement eq 3 can be written in the form of eq 1 where t ij kl c 8ui 18ik\\u00bb if in or kn a 8ik 18ui b 8u1 18ik\\u00bb if in and kn 4 here quadruple subscripts are used for the entries in the matrix t each entry indicates the strength of the connection between the neuron in row i and colcid173 umn j and the neuron in row k and column i of the neuron matrix the funccid173 tion delta is given by 780 8 i j 1 if i j 0 otherwise 5 the a and b terms specify inhibitions within a row or a column of the upper subarray and the c term provides the column inhibitions required for the neurons in the subarray of slack neurons equation 3 specifies the form of a solution but it does not include a term that will cause the network to favor minimum cost assignments to complete the formulation the following term is added to each tijkl d \\u2022 8 j i \\u2022 1 8 i k cost i j cost k i where cost i j is the cost of assigning site i to concentrator j the effect of this term is to reduce the inhibitions among the neurons that correspond to low cost assignments the sum of the costs of assigning both site i to concentrator j and site k to concentrator i was used in order to maintain the symmetry of t the external input currents were derived from the energy equation eq3 and are given by i 2 k j if i n ij 2 \\u2022 k j 1 otherwise 6 this exemplifies a technique for combining external input currents which arise from combinations of certain basic types of constraints an example the neural network solution for a concentrator assignment problem concid173 sisting of twelve sites and five concentrators was simulated all sites and concid173 centrators were located within the unit square on a randomly generated map for this problem it was assumed that no more than three sites could be assigned to a concentrator the assignment cost matrix and a typical assigncid173 ment resulting from the simulation are shown in fig 5 it is interesting to notice that the network proposed an assignment which made no use of concencid173 trator 2 because the capacity of each concentrator kj was assumed to be three sites the external input current for each neuron in the upper subarray was i ij 6 while in the subarray of slack neurons it was i ij 5 the other parameter values used in the simulation were and a b c 2 d 01 781 concentrators 1 2 3 4 5 sites a b c d e f g 31 62 25 51 17 39 h 81 67 84 33 i j k l 60 42 47 28 72 75 55 46 40 63 95 88 71 39 78 38 92 82 81 77 76 54 56 46 g 41 g 44 g 51 55 b 38 76 66 48 52 56 60 105 71 18 fig 5 the concentrator assignment cost matrix with choices circled since this choice of parameters results in a t matrix that is symmetric and whose diagonal entries are all zeros the network will converge to the minima of eq 3 furthermore inclusion of the term which is weighted by the parameter d causes the network to favor minimum cost assignments to evaluate the performance of the simulated network an exhaustive search of all solutions to the problem was conducted using a backtracking algocid173 rithm a frequency distribution of the solution costs associated with the assigncid173 ments generated by the exhaustive search is shown in fig 6 for comparison a histogram of the results of one hundred consecutive runs of the neuralnet simulation is shown in fig 7 although the neuralnet simulation did not find a global minimum ninetytwo of the one hundred assignments which it did find were among the best 001 of all solutions and the remaining eight were among the best 03 neural networks can be used to find good though not necessarily opticid173 mal solutions to combinatorial optimization problems like the concentrator conclusion 782 frequency 4000000 3500000 3000000 250000 1500000 100000 500000 ol 32 42 52 62 72 cost 82 fig 6 distribution of assignment costs resulting from an exhaustive search of all possible solutions frequency 25 20 15 10 5 o fig 7 distribution of assignment costs resulting from 100 consecucid173 tive executions of the neural net simulation assignment problem in order to use a neural network to solve such problems it is necessary to be able to represent a solution to the problem as a state of the network here the concentrator assignment problem was successfully mapped onto a hopfield network by associating each neuron with the hypothesis that a given site should be assigned to a particular concentrator an energy function was constructed to determine the connections that were needed and the result ing neural network was simulated while the neural network solution to the concentrator assignment probcid173 lem did not find a globally minimum cost assignment it very effectively recid173 jected poor solutions the network was even able to suggest assignments which would allow concentrators to be removed from the communication network references 1 a s tanenbaum computer networks prenticehall englewood cliffs new jersey 1981 p 83 2 e feldman f a lehner and t l ray manag sci v12 670 1966 3 a kuehn and m hamburger manag sci v9 643 1966 4 t aykin and a 1 g babu 1 of the oper res soc v38 n3 241 1987 5 j 1 hopfield proc natl acad sci u s a v79 2554 1982 6 j 1 hopfield and d w tank bio cyber v52 141 1985 7 d w tank and 1 1 hopfield ieee trans on cir and sys cas33 n5 533 1986\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top_keywords\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":20}]}]}